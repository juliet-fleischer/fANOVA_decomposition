

\subsubsection*{Scenario: Quadratic}
Next we consider two-degree polynomials, which contain only quadratic terms. They take the form: $$g_2(x_1, x_2) = a_{11} x_1^2 + a_{22} x_2^2.$$
From \autoref{eq:fanova_components_2D_polynomial} we can derive the fANOVA components for $g_2$:
\begin{align*}
    y_{\emptyset} &= a_{11} + a_{22}, \\
    y_1(x_1) &= a_{11}(x_1^2 - 1), \\
    y_2(x_2) &= a_{22}(x_2^2 - 1).
\end{align*}
In \autoref{fig:quadratic_main_effects}, we vary the coefficients $a_{11}$ and $a_{22}$, while the interaction term is again absent.
Here we deal with two parabolas for the main effect and know that the sign of the coefficients determines their direction, while the magnitudes influence how stretched or compressed they are. The constant fANOVA component $y_{\emptyset}$ is present here, but as it only shifts the decomposition along the y-axis, it does not affect the form of the effect functions, therefore we do not visualize it.

\begin{figure}[htpb]
    \centering
    \begin{subfigure}[t]{0.49\textwidth}
        \includegraphics[width=\textwidth]{images/experiment_section/quadratic_a1p00_a2p00_a11m10_a22m04_a12p00_rhop00_main.png}
        \caption{$a_{11} = -1$, $a_{22} = -0.4$}
    \end{subfigure}%
    \hfill
    \begin{subfigure}[t]{0.49\textwidth}
        \includegraphics[width=\textwidth]{images/experiment_section/quadratic_a1p00_a2p00_a11p20_a22m05_a12p00_rhop00_main.png}
        \caption{$a_{11} = 2$, $a_{22} = -0.5$}
    \end{subfigure}
    \caption{Main effects for quadratic terms with different coefficients. The fANOVA components are given by: $y_1(x_1) = a_{11}(x_1^2 - 1)$, $y_2(x_2) = a_{22}(x_2^2 - 1)$.}
    \label{fig:quadratic_main_effects}
\end{figure}

\subsubsection*{Analytical Example Functions for fANOVA}

We present a selection of analytically tractable functions that highlight different behaviors of the fANOVA decomposition.

\paragraph{Sparse additive + interaction (low effective dimensionality).}
These functions illustrate cases where only a few variables or low-order interactions dominate the variance, allowing fANOVA to compress the functional complexity:
\[
f_1(x) = x_1 + x_2 \cdot x_3
\]


\paragraph{Smooth localized function.}
This function is smooth but has variance concentrated in a small region of the input space. It can be used to explore how fANOVA captures global variance, not localized effects:
\[
f_3(x, y) = \exp\left(-100(x^2 + y^2)\right)
\]
Each of these functions can be used to stress-test specific characteristics of the fANOVA decomposition: sparsity, interaction order, locality, and smoothness.

\section{Further examples}


\paragraph{Identifying interaction clusters}
This example shows that all the cross-terms vanish. So fANOVA correctly identifies that we have interaction pairs and no term is appearing multiple times in two or more interaction groups.
\begin{align*}
f(x) &= (x_1 + x_2)^2 + x_3 x_4 + \sin(x_5 x_6) \\[1em]
y_\emptyset &= \mathbb{E}[f] = \mathbb{E}[(X_1 + X_2)^2] + \mathbb{E}[X_3 X_4] + \mathbb{E}[\sin(X_5 X_6)] = 2 + 0 + 0 = 2 \\[1em]
y_1(x_1) &= \mathbb{E}_{X_{2,3,4,5,6}}[f(x)] - y_\emptyset = x_1^2 + 1 - 2 = x_1^2 - 1 \\
y_2(x_2) &= x_2^2 - 1 \\
y_3(x_3) &= \mathbb{E}[x_3 X_4] - y_\emptyset = 0 \\
y_{12}(x_1, x_2) &= \mathbb{E}[f(x)] - y_\emptyset - y_1(x_1) - y_2(x_2) = (x_1 + x_2)^2 - 2 - (x_1^2 - 1) - (x_2^2 - 1) = 2x_1 x_2 \\
y_{13}(x_1, x_3) &= \mathbb{E}_{X_{2,4,5,6}}[f(x)] - y_\emptyset - y_1(x_1) - y_3(x_3) = x_1^2 + 1 - 2 - (x_1^2 - 1) - 0 = 0 \\
y_5(x_5) &= \mathbb{E}_{X_6}[\sin(x_5 X_6)] - y_\emptyset = 0 \\
y_6(x_6) &= 0 \\
y_{56}(x_5, x_6) &= \sin(x_5 x_6)
\end{align*}


\paragraph{Additive structure and necessity of interaction term}
$f(x_1, x_2, x_3) = x_1 + x_2 + x_3 + \epsilon x_1 x_2 x_3$ is mostly additive and has a minor interaction effect (depending on the value of $\epsilon$), one can for example decide whether to leave in the interaction effect in a surrogate model or if it is negligible.
We assume zero-centered independent inputs, i.e. $X_i \sim \mathcal{N}(0, 1)$ for $i = 1, 2, 3$.

\begin{align*}
y_\emptyset &= \mathbb{E}[f(X)] = 0 \\
y_1(x_1) &= \mathbb{E}_{X_2, X_3}[f(x_1, X_2, X_3)] - y_\emptyset = x_1 \\
y_2(x_2) &= x_2 \\
y_3(x_3) &= x_3 \\
y_{12}(x_1, x_2) &= y_{13}(x_1, x_3) = y_{23}(x_2, x_3) = 0 \\
y_{123}(x_1, x_2, x_3) &= f(x_1, x_2, x_3) - y_1(x_1) - y_2(x_2) - y_3(x_3) = \epsilon x_1 x_2 x_3 \\
\mathrm{Var}[f] &= \mathrm{Var}[x_1] + \mathrm{Var}[x_2] + \mathrm{Var}[x_3] + \mathrm{Var}[\epsilon x_1 x_2 x_3] = 3 + \epsilon^2 \\
\mathrm{Var}[y_1] &= \mathrm{Var}[y_2] = \mathrm{Var}[y_3] = 1 \\
\mathrm{Var}[y_{123}] &= \epsilon^2
\end{align*}



\subsubsection*{Standard MVN, linear function, interaction, non-centred inputs}
Next, instead of a standard MVN distribution assumption for the inputs, we allow for non-centred inputs. This is to confirm that the fANOVA decomposition manages to yield zero-mean components, even when inputs are not centred.
\(g = a + X_1 + 2X_2 + X_1 X_2\)
\[
\begin{pmatrix}
X_1 \\
X_2
\end{pmatrix}
\sim \mathcal{N}\left(
\begin{pmatrix} \mu_1 \\ \mu_2 \end{pmatrix},
\begin{pmatrix}
1 & 0 \\
0 & 1
\end{pmatrix}
\right).
\]
From the properties of the MVN, we know that marginal distributions are standard normal:
\[
X_i \sim \mathcal{N}(0, 1) \quad \text{for } i = 1, 2
\]

We also know that the conditional distributions are given by:
\[
X_1 \mid X_2 = x_2 \sim \mathcal{N}(\mu_1, 1), \quad
X_2 \mid X_1 = x_1 \sim \mathcal{N}(\mu_2, 1)
\]

We can now compute the classical fANOVA components as follows:
\begin{align*}
    y_{\emptyset} &= \mathbb{E}[g(X)] = a + \mu_1 + 2\mu_2 + \mu_1 \mu_2, \\
    y_1 &= \mathbb{E}[g(X) \mid X_2 = x_2] - y_{\emptyset}= a + 2\mu_2 + x_1 + x_1 \mu_2 - y_{\emptyset} \\
    &= x_1 ( 1 + \mu_2) - \mu_1 \mu_2 - \mu_1, \\
    y_2 &= \mathbb{E}[g(X) \mid X_1 = x_1] - y_{\emptyset} = a + \mu_1 + 2x_2 + x_2 \mu_1 - y_{\emptyset} \\
    &= x_2 (2 + \mu_1) - \mu_1 \mu_2 - 2 \mu_2, \\
    y_{12} &= g(x_1, x_2) - y_{\emptyset} = x_1x_2 - \mu_2 x_1 - \mu_1 x_2 + \mu_1 \mu_2.      
\end{align*}
We recognize that each fANOVA components is shifted by constants (that are formed from the conditional and unconditional expected values of the input variables). 

It is easy to verify that nonconstant terms have mean zero:
\begin{align*}
    \mathbb{E}[y_1] &= \mathbb{E}[X_1 (1 + \mu_2) - \mu_1 \mu_2 - \mu_1] = (1 + \mu_2) \mathbb{E}[X_1] - \mu_1 \mu_2 - \mu_1 = 0, \\
    \mathbb{E}[y_2] &= \mathbb{E}[X_2 (2 + \mu_1) - \mu_1 \mu_2 - 2\mu_2] = (2 + \mu_1) \mathbb{E}[X_2] - \mu_1 \mu_2 - 2\mu_2 = 0, \\
    \mathbb{E}[y_{12}] &= \mathbb{E}[X_1X_2] - \mu_2 \mathbb{E}[X_1] - \mu_1 \mathbb{E}[X_2] + \mu_1 \mu_2 = 0.
\end{align*}
Varying the mean of MVN inputs will result in shifted fANOVA components. Varying the variance of intput variables will not change the fANOVA decomposition and is therefore not investigated further.
% Input: Poisson/ Exponential/ Beta/ etc. not centred, independent

\paragraph{Non-additive functions}
These functions demonstrate that fANOVA does not assume additive structure and can identify purely interactive effects. If variables only appear in interaction terms, their main effects vanish:
\[
f_2(x) = x_1 \cdot x_2 \cdot x_3 \cdot x_4
\]


\subsubsection*{Uniform, quadratic, no interaction}
Let us also try out another function $g(x_1, x_2) = a + x_1 + x_2^2$; to see how fANOVA deals with quadratic main effects. 
We will also change the distribution of the inputs. Lets us consider two independent random variables with uniform distribution over the interval \([-1, 1]\), meaning they are already centred. We calculate:
\begin{align*}
y_\emptyset &= \mathbb{E}[g(X_1, X_2)] = a + \mathbb{E}[X_1] + \mathbb{E}[X_2^2] = a + 0 + \tfrac{1}{3} = a + \tfrac{1}{3} \\
y_1(x_1) &= \mathbb{E}[g(x_1, X_2)] - y_\emptyset = a + x_1 + \tfrac{1}{3} - \left(a + \tfrac{1}{3}\right) = x_1 \\
y_2(x_2) &= \mathbb{E}[g(X_1, x_2)] - y_\emptyset = a + 0 + x_2^2 - \left(a + \tfrac{1}{3}\right) = x_2^2 - \tfrac{1}{3} \\
y_{1,2}(x_1, x_2) &= g(x_1, x_2) - y_\emptyset - y_1(x_1) - y_2(x_2) = a + x_1 + x_2^2 - \left(a + \tfrac{1}{3} + x_1 + x_2^2 - \tfrac{1}{3}\right) = 0
\end{align*}



\section*{Square Integrability of \( f_1(x_1) \)}

For now we want to show that the single fANOVA term \( f_1(x_1) \) is square integrable, given that the original function $f(x) \in \mathcal{L}^2$. We need to show that:
\[
\int |f_1(x_1)|^2 \, dx_1 < \infty
\]

The single fANOVA term is defined as:
\[
f_1(x_1) = \int f(x) \, dx_{-1} - f_0
\]

We take the squared norm, and integrate w.r.t. \( x_1 \) to use the Cauchy-Schwarz inequality:
\[
\int |f_1(x_1)|^2 \, dx_1 
= \int \left| \int f(x) \, dx_{-1} - f_0 \right|^2 dx_1
\]

\[
= \int | (\int f(x) \, dx_{-1})^2 
- 2 \int f(x) \, dx_{-1} f_0 
+ f_0^2 | dx_1
\]

Break this into three terms:
\begin{align*}
(1): &\quad \int \left| \int f(x) \, dx_{-1} \right|^2 dx_1 
\leq \int \left( \int 1^2 \, dx_{-1} \right) \left( \int |f(x)|^2 \, dx_{-1} \right) dx_1 
= \int |f(x)|^2 \, dx < \infty \\
\\
(2): &\quad 2 \int \left( \int f(x) \, dx_{-1} \right) f_0 \, dx_1 
= 2 f_0 \int \left( \int f(x) \, dx_{-1} \right) dx_1 
= 2 f_0^2 < \infty \\
\\
(3): &\quad \int f_0^2 \, dx_1 = f_0^2 < \infty
\end{align*}

Since each term (1)â€“(3) is finite, and \( \int |f_1(x_1)|^2 dx_1 \) is a linear combination of them: \(\int |f_1(x_1)|^2 dx_1 < \infty\)



% We want to show that the square integrability of the original function \( f \) implies the square integrability of the fANOVA terms \( f_0, f_1, \ldots, f_k \).
% For simplicity, we restrict ourselves to a fixed number of dimensions and therefore a fixed set of indices $i = 1, 2, 3, 4$.
% To start, we define the cumulative fANOVA decomposition as follows:
% \begin{align}
%     g_1(x) &= \int f(x) dx_{-1} = \int f(x) dx_2 dx_3 dx_4 \\
%     g_2(x) &= \int f(x) dx_{-2} = \int f(x) dx_1 dx_3 dx_4 \\
%     g_{1,2}(x) &= \int f(x) dx_{-1, -2} = \int f(x) dx_3 dx_4 \\
%     g_{1,2,3}(x) &= \int f(x) dx_{-1, -2, -3} = \int f(x) dx_4 \\
%     g_{1,2,3,4}(x) &= \int f(x) dx_{-1, -2, -3, -4} = \int f(x)
% \end{align}
% Further, recall that the Cauchy-Schwarz inequality for two function $f, g$ is given by:
% \begin{align}
%     \left( \int f(x) g(x) dx \right)^2 \leq \left( \int f(x)^2 dx \right) \left( \int g(x)^2 dx \right)
% \end{align}

% Let $f(x) \in L^2(\mathbb{R}^4)$ with $x = (x_1, x_2, x_3, x_4)$
% We want to show that the term $g_{1,2}$ is square integrable, i.e. $\int |g_{1,2}(x)|^2 dx < \infty$. The reasoning for other terms will follow the same principle.\par
% To be able to use Schwarz inequality, we square the norm of $g_{1,2}(x)$:
% \begin{align}
%     |g_{1,2}(x_1, x_2)|^2 
%     &= \left( \int f(x_1, x_2, x_3, x_4) \, dx_3 dx_4 \right)^2 \\
%     &\leq ( \int 1^2 \, dx_3 dx_4) (\int |f(x_1, x_2, x_3, x_4)|^2 \, dx_3 dx_4) \\
%     &= \int |f(x_1, x_2, x_3, x_4)|^2 \, dx_3 dx_4
% \end{align}
% The statement is true for fixed values of $x_1$ and $x_2$. To show that it holds for all $x_1, x_2$, we integrate over $x_1$ and $x_2$:
% \begin{align}
%     \int |g_{1,2}(x_1, x_2)|^2 \, dx_1 dx_2 
%     &\leq \int \left( \int |f(x_1, x_2, x_3, x_4)|^2 \, dx_3 dx_4 \right) \, dx_1 dx_2 \\
%     &= \int |f(x_1, x_2, x_3, x_4)|^2 \, dx \leq \infty
% \end{align}
% We used Fubini's theorem to write the sequential integration as a single integral over the whole space, which is valid under the assumption that $f$ is square integrable.
% As a last step, we use the square integrability of the cumulative fANOVA terms to show square integrability of the single fANOVA terms. We give an example for $f_{1,2}$:
% \begin{align}
%     f_{1,2}(x) &= g_{1,2}(x) - f_0 - f_1(x_1) - f_2(x_2) \\
%     &= g_{1,2}(x) - \int f(x) dx - \int f(x)\, dx_{-1} - \int f(x) dx_{-2} \\
%     &= g_{1,2}(x) - \int f(x) dx - g_1(x) - g_2(x) \leq \infty
% \end{align}
% Since all the terms in the last row are square integrable, we deal with a linear combination of square integrable functions, which is also square integrable.

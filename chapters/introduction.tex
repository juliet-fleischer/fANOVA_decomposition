Interpretability and sensitivity analysis are increasingly important in machine learning (ML) and in the study of complex systems. One of the foundational mathematical tools supporting these goals is the functional ANOVA decomposition (fANOVA).

At its core, the fANOVA decomposition provides a method which allows decomposing integrable functions into a sum of orthogonal components.
It is a foundational method, useful in interpretability of black box models (\cite{hooker2004, molnar2025}), uncertainty quantification of complex systems \cite{rahman2014}, non-parametric statistical modelling (see for example \cite{stone1997}), sensitivity analysis \cite{sobol1993sensitivity}), and many more fields.
Given this wide range of applications, fANOVA is an essential concept worth understanding in depth.\par
% What is the problem?

However, learning about fANOVA is not straightforward.
A problem is the mix of formalizations and definitions around the method, partly due to its long history and the different streams of science that have used it.
This already starts with the name of the method. It has been called decomposition into summands of different order \citep{sobol1993sensitivity}, ANOVA representation \citep{sobol1993sensitivity}, functional ANOVA decomposition \citep{hooker2004}, ANOVA dimensional decomposition \citep{rahman2014} â€“ in this thesis we will refer to it as the fANOVA decomposition.
The diversity does not stop at naming. Different authors formalize the decomposition using different notation, slightly different sets of assumptions, and either interpret fANOVA from a probabilistic perspective using expectations or from a more deterministic mathematical viewpoint using integrals.
While these approaches are mathematically equivalent and can be unified under the concept of orthogonal projections, this connection is often not obvious when first encountering the literature.\par


Given this state of affairs, there is a clear need for a comprehensive overview of fANOVA-related work and for a unification of the various notations and definitions that ultimately express the same concepts.
Bringing clarity into the fANOVA landscape is more relevant than ever as the method has recently attracted renewed attention in interpretable machine learning (IML) literature (see for example \cite{hu2025}).
It is being used to build inherently interpretable models, yet the theoretical foundation is often mentioned only briefly or left implicit.\par

% What is (a possible) solution?
This thesis addresses that gap by providing an accessible and intuitive introduction to the fANOVA decomposition while remaining mathematically rigorous.
It can be viewed as a handbook of the fANOVA decomposition that will help researchers and practitioners to understand the mathematical background of this method as well as its more applied aspects.\par
% The focus is not on developing new theory or novel algorithms but on giving a clear, unified presentation of existing results and their underlying ideas.

This work is organized as follows: It starts with historical context and related work. This is followed by the central part in which we give the formal definition of the classical and generalized fANOVA decomposition.
Next we illustrate characteristics of the method based on analytical examples, before briefly outlining current estimation schemes and concluding with a discussion and possible future research directions.

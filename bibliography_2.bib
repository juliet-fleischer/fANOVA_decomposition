
@article{mehrabi2022a,
	title = {A {Survey} on {Bias} and {Fairness} in {Machine} {Learning}},
	volume = {54},
	issn = {0360-0300, 1557-7341},
	url = {https://dl.acm.org/doi/10.1145/3457607},
	doi = {10.1145/3457607},
	abstract = {With the widespread use of artificial intelligence (AI) systems and applications in our everyday lives, accounting for fairness has gained significant importance in designing and engineering of such systems. AI systems can be used in many sensitive environments to make important and life-changing decisions; thus, it is crucial to ensure that these decisions do not reflect discriminatory behavior toward certain groups or populations. More recently some work has been developed in traditional machine learning and deep learning that address such challenges in different subdomains. With the commercialization of these systems, researchers are becoming more aware of the biases that these applications can contain and are attempting to address them. In this survey, we investigated different real-world applications that have shown biases in various ways, and we listed different sources of biases that can affect AI applications. We then created a taxonomy for fairness definitions that machine learning researchers have defined to avoid the existing bias in AI systems. In addition to that, we examined different domains and subdomains in AI showing what researchers have observed with regard to unfair outcomes in the state-of-the-art methods and ways they have tried to address them. There are still many future directions and solutions that can be taken to mitigate the problem of bias in AI systems. We are hoping that this survey will motivate researchers to tackle these issues in the near future by observing existing work in their respective fields.},
	language = {en},
	number = {6},
	urldate = {2024-11-10},
	journal = {ACM Computing Surveys},
	author = {Mehrabi, Ninareh and Morstatter, Fred and Saxena, Nripsuta and Lerman, Kristina and Galstyan, Aram},
	month = jul,
	year = {2022},
	pages = {1--35},
	file = {Mehrabi et al. - 2022 - A Survey on Bias and Fairness in Machine Learning.pdf:/Users/julietfleischer/Library/Mobile Documents/iCloud~md~obsidian/Documents/Studium/PDFs/Mehrabi et al. - 2022 - A Survey on Bias and Fairness in Machine Learning.pdf:application/pdf},
}

@article{caton,
	title = {Impact of {Imputation} {Strategies} on {Fairness} in {Machine} {Learning}},
	abstract = {Research on Fairness and Bias Mitigation in Machine Learning often uses a set of reference datasets for the design and evaluation of novel approaches or deﬁnitions. While these datasets are well structured and useful for the comparison of various approaches, they do not reﬂect that datasets commonly used in real-world applications can have missing values. When such missing values are encountered, the use of imputation strategies is commonplace. However, as imputation strategies potentially alter the distribution of data they can also affect the performance, and potentially the fairness, of the resulting predictions, a topic not yet well understood in the fairness literature. In this article, we investigate the impact of different imputation strategies on classical performance and fairness in classiﬁcation settings. We ﬁnd that the selected imputation strategy, along with other factors including the type of classiﬁcation algorithm, can signiﬁcantly affect performance and fairness outcomes. The results of our experiments indicate that the choice of imputation strategy is an important factor when considering fairness in Machine Learning. We also provide some insights and guidance for researchers to help navigate imputation approaches for fairness.},
	language = {en},
	author = {Caton, Simon and Caton, Simon and Ie, Ucd and Malisetty, Saiteja and Edu, Unomaha and Haas, Christian and Haas, Christian and At, Wu Ac},
	file = {Caton et al. - Impact of Imputation Strategies on Fairness in Machine Learning.pdf:/Users/julietfleischer/Library/Mobile Documents/iCloud~md~obsidian/Documents/Studium/PDFs/Caton et al. - Impact of Imputation Strategies on Fairness in Machine Learning.pdf:application/pdf},
}

@article{CatonIISFMLa,
	title = {Impact of {Imputation} {Strategies} on {Fairness} in {Machine} {Learning}},
	abstract = {Research on Fairness and Bias Mitigation in Machine Learning often uses a set of reference datasets for the design and evaluation of novel approaches or deﬁnitions. While these datasets are well structured and useful for the comparison of various approaches, they do not reﬂect that datasets commonly used in real-world applications can have missing values. When such missing values are encountered, the use of imputation strategies is commonplace. However, as imputation strategies potentially alter the distribution of data they can also affect the performance, and potentially the fairness, of the resulting predictions, a topic not yet well understood in the fairness literature. In this article, we investigate the impact of different imputation strategies on classical performance and fairness in classiﬁcation settings. We ﬁnd that the selected imputation strategy, along with other factors including the type of classiﬁcation algorithm, can signiﬁcantly affect performance and fairness outcomes. The results of our experiments indicate that the choice of imputation strategy is an important factor when considering fairness in Machine Learning. We also provide some insights and guidance for researchers to help navigate imputation approaches for fairness.},
	language = {en},
	author = {Caton, Simon and Caton, Simon and Ie, Ucd and Malisetty, Saiteja and Edu, Unomaha and Haas, Christian and Haas, Christian and At, Wu Ac},
	file = {Caton et al. - Impact of Imputation Strategies on Fairness in Machine Learning.pdf:/Users/julietfleischer/Library/Mobile Documents/iCloud~md~obsidian/Documents/Studium/PDFs/CatonIISFMLa/Caton et al. - Impact of Imputation Strategies on Fairness in Machine Learning.pdf:application/pdf},
}

@article{farrell2022,
	title = {Use of force during stop and frisks: {Examining} the role of suspect demeanor and race},
	volume = {82},
	issn = {00472352},
	shorttitle = {Use of force during stop and frisks},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0047235222001210},
	doi = {10.1016/j.jcrimjus.2022.102001},
	abstract = {Purpose: This study examines predictors of suspect demeanor, the relationship between demeanor and use of force during stop and frisks, and whether this relationship varies across suspect race.
Methods: Multilevel models using 2018–2020 NYPD Stop, Question, and Frisk data are used to examine demeanor and assess the role of race and demeanor on use of force.
Results: Results demonstrate that race is significantly associated with officer perceptions of suspect demeanor and demeanor impacts use of weapon and non-weapon force. Specifically, calm suspects are less likely to experience both forms of force and upset, angry, and non-compliant/aggressive suspects are more likely to experience both forms of force. Although race was found to significantly predict demeanor, suspect race does not appear to moderate the impact of demeanor on use of force with a few exceptions. For example, non-compliant/aggressive Black and Hispanic suspects are more likely to face non-weapon force compared to non-compliant/aggressive White suspects and calm Black suspects are more likely to face weapon force compared to calm White suspects.
Conclusion: Suspect demeanor is missing from stop and frisk research, but findings suggest that race may shape perceptions of demeanor and demeanor may play an important role in understanding use of force.},
	language = {en},
	urldate = {2024-11-11},
	journal = {Journal of Criminal Justice},
	author = {Farrell, Chelsea},
	month = sep,
	year = {2022},
	pages = {102001},
	file = {Farrell - 2022 - Use of force during stop and frisks Examining the role of suspect demeanor and race.pdf:/Users/julietfleischer/Library/Mobile Documents/iCloud~md~obsidian/Documents/Studium/PDFs/Farrell2022UfsfErsdr/Farrell - 2022 - Use of force during stop and frisks Examining the role of suspect demeanor and race.pdf:application/pdf},
}

@article{milner2016,
	title = {Black and {Hispanic} {Men} {Perceived} to {Be} {Large} {Are} at {Increased} {Risk} for {Police} {Frisk}, {Search}, and {Force}},
	volume = {11},
	issn = {1932-6203},
	url = {https://dx.plos.org/10.1371/journal.pone.0147158},
	doi = {10.1371/journal.pone.0147158},
	abstract = {Social justice issues remain some of the most pressing problems in the United States. One aspect of social justice involves the differential treatment of demographic groups in the criminal justice system. While data consistently show that Blacks and Hispanics are often treated differently than Whites, one understudied aspect of these disparities is how police officers' assessments of suspects' size affects their decisions. Using over 3 million cases from the New York Police Department (NYPD) Stop, Question, and Frisk (SQF) Database, 2006–2013, this study is the first to explore suspects' race, perceived size, and police treatment. Results indicate that tall and heavy black and Hispanic men are at the greatest risk for frisk or search. Tall and heavy suspects are at increased risk for experiencing police force, with black and Hispanic men being more likely to experience force than white men across size categories.},
	language = {en},
	number = {1},
	urldate = {2024-11-11},
	journal = {PLOS ONE},
	author = {Milner, Adrienne N. and George, Brandon J. and Allison, David B.},
	editor = {Maher, Brion},
	month = jan,
	year = {2016},
	pages = {e0147158},
	file = {Milner et al. - 2016 - Black and Hispanic Men Perceived to Be Large Are at Increased Risk for Police Frisk, Search, and For.pdf:/Users/julietfleischer/Library/Mobile Documents/iCloud~md~obsidian/Documents/Studium/PDFs/Milner2016BHMPBLAIRPFSF/Milner et al. - 2016 - Black and Hispanic Men Perceived to Be Large Are at Increased Risk for Police Frisk, Search, and For.pdf:application/pdf},
}

@article{fagan2022,
	title = {No {Runs}, {Few} {Hits}, and {Many} {Errors}: {Street} {Stops}, {Bias}, and {Proactive} {Policing}},
	issn = {1556-5068},
	shorttitle = {No {Runs}, {Few} {Hits}, and {Many} {Errors}},
	url = {https://www.ssrn.com/abstract=4052926},
	doi = {10.2139/ssrn.4052926},
	abstract = {Equilibrium models of racial discrimination in law enforcement encounters suggest that in the absence of racial discrimination, the proportion of searches yielding evidence of illegal activity (the hit rate) will be equal across races. Searches that disproportionately target one racial group, resulting in a relatively low hit rate, are inefficient and suggest bias. An unbiased officer who is seeking to maximize her hit rate would reduce the number of unproductive stops toward a group with the lower hit rate. An unbiased policing regime would generate no differences in hit rates between groups.},
	language = {en},
	urldate = {2024-11-11},
	journal = {SSRN Electronic Journal},
	author = {Fagan, Jeffrey},
	year = {2022},
	file = {Fagan - 2022 - No Runs, Few Hits, and Many Errors Street Stops, Bias, and Proactive Policing.pdf:/Users/julietfleischer/Library/Mobile Documents/iCloud~md~obsidian/Documents/Studium/PDFs/Fagan2022NRFHMESSBPP/Fagan - 2022 - No Runs, Few Hits, and Many Errors Street Stops, Bias, and Proactive Policing.pdf:application/pdf},
}

@article{glaser2024,
	title = {Disrupting the {Effects} of {Implicit} {Bias}: {The} {Case} of {Discretion} \& {Policing}},
	volume = {153},
	issn = {0011-5266, 1548-6192},
	shorttitle = {Disrupting the {Effects} of {Implicit} {Bias}},
	url = {https://direct.mit.edu/daed/article/153/1/151/119935/Disrupting-the-Effects-of-Implicit-Bias-The-Case},
	doi = {10.1162/daed_a_02053},
	abstract = {Abstract
            Police departments tend to address operational challenges with training approaches, and implicit bias in policing is no exception. However, psychological scientists have found that implicit biases are very difficult to reduce in any lasting, meaningful way. Because they are difficult to change, and nearly impossible for the decision-maker to recognize, training to raise awareness or teach corrective strategies is unlikely to succeed. Recent empirical assessments of implicit bias trainings have shown, at best, no effect on racial disparities in officers' actions in the field. In the absence of effective training, a promising near-term approach for reducing racial disparities in policing is to reduce the frequency of actions most vulnerable to the influence of bias. Specifically, actions that allow relatively high discretion are most likely to be subject to bias-driven errors. Several cases across different policing domains reveal that when discretion is constrained in stop-and-search decisions, the impact of racial bias on searches markedly declines.},
	language = {en},
	number = {1},
	urldate = {2024-11-11},
	journal = {Daedalus},
	author = {Glaser, Jack},
	month = mar,
	year = {2024},
	pages = {151--173},
	file = {Glaser - 2024 - Disrupting the Effects of Implicit Bias The Case of Discretion & Policing.pdf:/Users/julietfleischer/Library/Mobile Documents/iCloud~md~obsidian/Documents/Studium/PDFs/Glaser2024DEIBCDP/Glaser - 2024 - Disrupting the Effects of Implicit Bias The Case of Discretion & Policing.pdf:application/pdf},
}

@inproceedings{verma2018,
	address = {Gothenburg Sweden},
	title = {Fairness definitions explained},
	isbn = {978-1-4503-5746-3},
	url = {https://dl.acm.org/doi/10.1145/3194770.3194776},
	doi = {10.1145/3194770.3194776},
	abstract = {Algorithm fairness has started to attract the attention of researchers in AI, Software Engineering and Law communities, with more than twenty different notions of fairness proposed in the last few years. Yet, there is no clear agreement on which definition to apply in each situation. Moreover, the detailed differences between multiple definitions are difficult to grasp. To address this issue, this paper collects the most prominent definitions of fairness for the algorithmic classification problem, explains the rationale behind these definitions, and demonstrates each of them on a single unifying case-study. Our analysis intuitively explains why the same case can be considered fair according to some definitions and unfair according to others.},
	language = {en},
	urldate = {2024-11-16},
	booktitle = {Proceedings of the {International} {Workshop} on {Software} {Fairness}},
	publisher = {ACM},
	author = {Verma, Sahil and Rubin, Julia},
	month = may,
	year = {2018},
	pages = {1--7},
	file = {Verma und Rubin - 2018 - Fairness definitions explained.pdf:/Users/julietfleischer/Library/Mobile Documents/iCloud~md~obsidian/Documents/Studium/PDFs/Verma2018Fde/Verma und Rubin - 2018 - Fairness definitions explained.pdf:application/pdf},
}

@article{grgic-hlaca2018,
	title = {Beyond {Distributive} {Fairness} in {Algorithmic} {Decision} {Making}: {Feature} {Selection} for {Procedurally} {Fair} {Learning}},
	volume = {32},
	issn = {2374-3468, 2159-5399},
	shorttitle = {Beyond {Distributive} {Fairness} in {Algorithmic} {Decision} {Making}},
	url = {https://ojs.aaai.org/index.php/AAAI/article/view/11296},
	doi = {10.1609/aaai.v32i1.11296},
	abstract = {With widespread use of machine learning methods in numerous domains involving humans, several studies have raised questions about the potential for unfairness towards certain individuals or groups. A number of recent works have proposed methods to measure and eliminate unfairness from machine learning models. However, most of this work has focused on only one dimension of fair decision making: distributive fairness, i.e., the fairness of the decision outcomes. In this work, we leverage the rich literature on organizational justice and focus on another dimension of fair decision making: procedural fairness, i.e., the fairness of the decision making process. We propose measures for procedural fairness that consider the input features used in the decision process, and evaluate the moral judgments of humans regarding the use of these features. We operationalize these measures on two real world datasets using human surveys on the Amazon Mechanical Turk (AMT) platform, demonstrating that our measures capture important properties of procedurally fair decision making. We provide fast submodular mechanisms to optimize the tradeoff between procedural fairness and prediction accuracy. On our datasets, we observe empirically that procedural fairness may be achieved with little cost to outcome fairness, but that some loss of accuracy is unavoidable.},
	language = {en},
	number = {1},
	urldate = {2024-11-19},
	journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
	author = {Grgić-Hlača, Nina and Zafar, Muhammad Bilal and Gummadi, Krishna P. and Weller, Adrian},
	month = apr,
	year = {2018},
	file = {Grgić-Hlača et al. - 2018 - Beyond Distributive Fairness in Algorithmic Decision Making Feature Selection for Procedurally Fair.pdf:/Users/julietfleischer/Library/Mobile Documents/iCloud~md~obsidian/Documents/Studium/PDFs/Grgic-Hlaca2018DFADMFSPFL/Grgić-Hlača et al. - 2018 - Beyond Distributive Fairness in Algorithmic Decision Making Feature Selection for Procedurally Fair.pdf:application/pdf},
}

@article{goel2016,
	title = {Precinct or prejudice? {Understanding} racial disparities in {New} {York} {City}’s stop-and-frisk policy},
	volume = {10},
	issn = {1932-6157},
	shorttitle = {Precinct or prejudice?},
	url = {https://projecteuclid.org/journals/annals-of-applied-statistics/volume-10/issue-1/Precinct-or-prejudice-Understanding-racial-disparities-in-New-York-Citys/10.1214/15-AOAS897.full},
	doi = {10.1214/15-AOAS897},
	language = {en},
	number = {1},
	urldate = {2024-11-19},
	journal = {The Annals of Applied Statistics},
	author = {Goel, Sharad and Rao, Justin M. and Shroff, Ravi},
	month = mar,
	year = {2016},
	file = {Goel et al. - 2016 - Precinct or prejudice Understanding racial disparities in New York City’s stop-and-frisk policy.pdf:/Users/julietfleischer/Library/Mobile Documents/iCloud~md~obsidian/Documents/Studium/PDFs/Goel2016PpUrdNYCsp/Goel et al. - 2016 - Precinct or prejudice Understanding racial disparities in New York City’s stop-and-frisk policy.pdf:application/pdf},
}

@article{makhlouf2021,
	title = {On the {Applicability} of {Machine} {Learning} {Fairness} {Notions}},
	volume = {23},
	issn = {1931-0145, 1931-0153},
	url = {https://dl.acm.org/doi/10.1145/3468507.3468511},
	doi = {10.1145/3468507.3468511},
	abstract = {Machine Learning (ML) based predictive systems are increasingly used to support decisions with a critical impact on individuals’ lives such as college admission, job hiring, child custody, criminal risk assessment, etc. As a result, fairness emerged as an important requirement to guarantee that ML predictive systems do not discriminate against speciﬁc individuals or entire sub-populations, in particular, minorities. Given the inherent subjectivity of viewing the concept of fairness, several notions of fairness have been introduced in the literature. This paper is a survey of fairness notions that, unlike other surveys in the literature, addresses the question of “which notion of fairness is most suited to a given real-world scenario and why?”. Our attempt to answer this question consists in (1) identifying the set of fairness-related characteristics of the real-world scenario at hand, (2) analyzing the behavior of each fairness notion, and then (3) ﬁtting these two elements to recommend the most suitable fairness notion in every speciﬁc setup. The results are summarized in a decision diagram that can be used by practitioners and policy makers to navigate the relatively large catalogue of ML fairness notions.},
	language = {en},
	number = {1},
	urldate = {2024-12-01},
	journal = {ACM SIGKDD Explorations Newsletter},
	author = {Makhlouf, Karima and Zhioua, Sami and Palamidessi, Catuscia},
	month = may,
	year = {2021},
	pages = {14--23},
	file = {Makhlouf et al. - 2021 - On the Applicability of Machine Learning Fairness Notions.pdf:/Users/julietfleischer/Library/Mobile Documents/iCloud~md~obsidian/Documents/Studium/PDFs/Makhlouf2021AMLFN/Makhlouf et al. - 2021 - On the Applicability of Machine Learning Fairness Notions.pdf:application/pdf},
}

@article{weisburd2016,
	title = {Do {Stop}, {Question}, and {Frisk} {Practices} {Deter} {Crime}?},
	volume = {15},
	issn = {1745-9133},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/1745-9133.12172},
	doi = {10.1111/1745-9133.12172},
	abstract = {Research Summary Existing studies examining the crime impacts of stop, question, and frisks (SQFs) have focused on large geographic areas. Weisburd, Telep, and Lawton (2014) suggested that SQFs in New York City (NYC) were highly concentrated at crime hot spots, implying that a microlevel unit of analysis may be more appropriate. The current study aims to address the limitations of prior studies by exploring the impact of SQFs on daily and weekly crime incidents in NYC at a microgeographic level. The findings suggest that SQFs produce a significant yet modest deterrent effect on crime. Policy Implications These findings support those who argue that SQFs deter crime. Nonetheless, it is not clear whether other policing strategies may have similar or even stronger crime-control outcomes. In turn, the level of SQFs needed to produce meaningful crime reductions are costly in terms of police time and are potentially harmful to police legitimacy.},
	language = {en},
	number = {1},
	urldate = {2024-12-01},
	journal = {Criminology \& Public Policy},
	author = {Weisburd, David and Wooditch, Alese and Weisburd, Sarit and Yang, Sue-Ming},
	year = {2016},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/1745-9133.12172},
	pages = {31--56},
	file = {Snapshot:/Users/julietfleischer/Zotero/storage/A4RRRHXT/1745-9133.html:text/html},
}

@misc{Hardt2016EOSL,
	title = {Equality of {Opportunity} in {Supervised} {Learning}},
	url = {http://arxiv.org/abs/1610.02413},
	doi = {10.48550/arXiv.1610.02413},
	abstract = {We propose a criterion for discrimination against a specified sensitive attribute in supervised learning, where the goal is to predict some target based on available features. Assuming data about the predictor, target, and membership in the protected group are available, we show how to optimally adjust any learned predictor so as to remove discrimination according to our definition. Our framework also improves incentives by shifting the cost of poor classification from disadvantaged groups to the decision maker, who can respond by improving the classification accuracy. In line with other studies, our notion is oblivious: it depends only on the joint statistics of the predictor, the target and the protected attribute, but not on interpretation of individualfeatures. We study the inherent limits of defining and identifying biases based on such oblivious measures, outlining what can and cannot be inferred from different oblivious tests. We illustrate our notion using a case study of FICO credit scores.},
	urldate = {2024-12-02},
	publisher = {arXiv},
	author = {Hardt, Moritz and Price, Eric and Srebro, Nathan},
	month = oct,
	year = {2016},
	note = {arXiv:1610.02413},
	keywords = {Computer Science - Machine Learning},
	file = {Preprint PDF:/Users/julietfleischer/Zotero/storage/PT59VI7G/Hardt et al. - 2016 - Equality of Opportunity in Supervised Learning.pdf:application/pdf;Snapshot:/Users/julietfleischer/Zotero/storage/7CVTYX9S/1610.html:text/html},
}

@article{kusner,
	title = {Counterfactual {Fairness}},
	abstract = {Machine learning can impact people with legal or ethical consequences when it is used to automate decisions in areas such as insurance, lending, hiring, and predictive policing. In many of these scenarios, previous decisions have been made that are unfairly biased against certain subpopulations, for example those of a particular race, gender, or sexual orientation. Since this past data may be biased, machine learning predictors must account for this to avoid perpetuating or creating discriminatory practices. In this paper, we develop a framework for modeling fairness using tools from causal inference. Our deﬁnition of counterfactual fairness captures the intuition that a decision is fair towards an individual if it the same in (a) the actual world and (b) a counterfactual world where the individual belonged to a different demographic group. We demonstrate our framework on a real-world problem of fair prediction of success in law school.},
	language = {en},
	author = {Kusner, Matt J and Loftus, Joshua and Russell, Chris and Silva, Ricardo},
	file = {Kusner et al. - Counterfactual Fairness.pdf:/Users/julietfleischer/Library/Mobile Documents/iCloud~md~obsidian/Documents/Studium/PDFs/KusnerCF/Kusner et al. - Counterfactual Fairness.pdf:application/pdf},
}

@misc{MarcoScutari[autcre]2020fFMML,
	title = {fairml: {Fair} {Models} in {Machine} {Learning}},
	shorttitle = {fairml},
	url = {https://CRAN.R-project.org/package=fairml},
	doi = {10.32614/CRAN.package.fairml},
	abstract = {Fair machine learning regression models which take sensitive attributes into account in model estimation. Currently implementing Komiyama et al. (2018)  {\textless}http://proceedings.mlr.press/v80/komiyama18a/komiyama18a.pdf{\textgreater}, Zafar et al. (2019) {\textless}https://www.jmlr.org/papers/volume20/18-262/18-262.pdf{\textgreater} and my own approach from Scutari, Panero and Proissl (2022) {\textless}https://link.springer.com/content/pdf/10.1007/s11222-022-10143-w.pdf{\textgreater} that uses ridge regression to enforce fairness.},
	language = {en},
	urldate = {2024-12-09},
	author = {{Marco Scutari [aut, cre]}},
	month = aug,
	year = {2020},
	note = {Institution: Comprehensive R Archive Network
Pages: 0.8},
	file = {Marco Scutari [aut, cre] - 2020 - fairml Fair Models in Machine Learning.pdf:/Users/julietfleischer/Library/Mobile Documents/iCloud~md~obsidian/Documents/Studium/PDFs/MarcoScutari[autcre]2020fFMML/Marco Scutari [aut, cre] - 2020 - fairml Fair Models in Machine Learning.pdf:application/pdf},
}

@article{zafar,
	title = {Fairness {Constraints}: {A} {Flexible} {Approach} for {Fair} {Classiﬁcation}},
	abstract = {Algorithmic decision making is employed in an increasing number of real-world applications to aid human decision making. While it has shown considerable promise in terms of improved decision accuracy, in some scenarios, its outcomes have been also shown to impose an unfair (dis)advantage on people from certain social groups (e.g., women, blacks). In this context, there is a need for computational techniques to limit unfairness in algorithmic decision making. In this work, we take a step forward to fulﬁll that need and introduce a ﬂexible constraint-based framework to enable the design of fair margin-based classiﬁers. The main technical innovation of our framework is a general and intuitive measure of decision boundary unfairness, which serves as a tractable proxy to several of the most popular computational deﬁnitions of unfairness from the literature. Leveraging our measure, we can reduce the design of fair margin-based classiﬁers to adding tractable constraints on their decision boundaries. Experiments on multiple synthetic and real-world datasets show that our framework is able to successfully limit unfairness, often at a small cost in terms of accuracy.},
	language = {en},
	author = {Zafar, Muhammad Bilal and Valera, Isabel and Gomez-Rodriguez, Manuel and Gummadi, Krishna P},
	file = {Zafar et al. - Fairness Constraints A Flexible Approach for Fair Classiﬁcation.pdf:/Users/julietfleischer/Library/Mobile Documents/iCloud~md~obsidian/Documents/Studium/PDFs/ZafarFCFAFC/Zafar et al. - Fairness Constraints A Flexible Approach for Fair Classiﬁcation.pdf:application/pdf},
}

@article{fernando2021,
	title = {Missing the missing values: {The} ugly duckling of fairness in machine learning},
	volume = {36},
	issn = {1098-111X},
	shorttitle = {Missing the missing values},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/int.22415},
	doi = {10.1002/int.22415},
	abstract = {Nowadays, there is an increasing concern in machine learning about the causes underlying unfair decision making, that is, algorithmic decisions discriminating some groups over others, especially with groups that are defined over protected attributes, such as gender, race and nationality. Missing values are one frequent manifestation of all these latent causes: protected groups are more reluctant to give information that could be used against them, sensitive information for some groups can be erased by human operators, or data acquisition may simply be less complete and systematic for minority groups. However, most recent techniques, libraries and experimental results dealing with fairness in machine learning have simply ignored missing data. In this paper, we present the first comprehensive analysis of the relation between missing values and algorithmic fairness for machine learning: (1) we analyse the sources of missing data and bias, mapping the common causes, (2) we find that rows containing missing values are usually fairer than the rest, which should discourage the consideration of missing values as the uncomfortable ugly data that different techniques and libraries for handling algorithmic bias get rid of at the first occasion, (3) we study the trade-off between performance and fairness when the rows with missing values are used (either because the technique deals with them directly or by imputation methods), and (4) we show that the sensitivity of six different machine-learning techniques to missing values is usually low, which reinforces the view that the rows with missing data contribute more to fairness through the other, nonmissing, attributes. We end the paper with a series of recommended procedures about what to do with missing data when aiming for fair decision making.},
	language = {en},
	number = {7},
	urldate = {2024-12-10},
	journal = {International Journal of Intelligent Systems},
	author = {Fernando, Martínez-Plumed and Cèsar, Ferri and David, Nieves and José, Hernández-Orallo},
	year = {2021},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/int.22415},
	keywords = {algorithmic bias, confirmation bias, data imputation, fairness, missing values, sample bias, survey bias},
	pages = {3217--3258},
	file = {Fernando et al. - 2021 - Missing the missing values The ugly duckling of fairness in machine learning.pdf:/Users/julietfleischer/Library/Mobile Documents/iCloud~md~obsidian/Documents/Studium/PDFs/Fernando2021Mmvudfml/Fernando et al. - 2021 - Missing the missing values The ugly duckling of fairness in machine learning.pdf:application/pdf;Snapshot:/Users/julietfleischer/Zotero/storage/WDUPKMWG/int.html:text/html},
}

@article{Stasinopoulos2007GAMLSSGa,
	title = {Generalized {Additive} {Models} for {Location} {Scale} and {Shape} ({GAMLSS}) in \textit{{R}}},
	volume = {23},
	issn = {1548-7660},
	url = {http://www.jstatsoft.org/v23/i07/},
	doi = {10.18637/jss.v023.i07},
	abstract = {GAMLSS is a general framework for ﬁtting regression type models where the distribution of the response variable does not have to belong to the exponential family and includes highly skew and kurtotic continuous and discrete distribution. GAMLSS allows all the parameters of the distribution of the response variable to be modelled as linear/non-linear or smooth functions of the explanatory variables. This paper starts by deﬁning the statistical framework of GAMLSS, then describes the current implementation of GAMLSS in R and ﬁnally gives four diﬀerent data examples to demonstrate how GAMLSS can be used for statistical modelling.},
	language = {en},
	number = {7},
	urldate = {2024-12-11},
	journal = {Journal of Statistical Software},
	author = {Stasinopoulos, D. Mikis and Rigby, Robert A.},
	year = {2007},
	file = {Stasinopoulos und Rigby - 2007 - Generalized Additive Models for Location Scale and Shape (GAMLSS) in R.pdf:/Users/julietfleischer/Library/Mobile Documents/iCloud~md~obsidian/Documents/Studium/PDFs/Stasinopoulos2007GAMLSSGa/Stasinopoulos und Rigby - 2007 - Generalized Additive Models for Location Scale and Shape (GAMLSS) in R.pdf:application/pdf},
}

@article{WoodGAMi,
	title = {Generalized {Additive} {Models}: an introduction with {R}},
	language = {en},
	author = {Wood, Simon N},
	file = {Wood - Generalized Additive Models an introduction with R.pdf:/Users/julietfleischer/Library/Mobile Documents/iCloud~md~obsidian/Documents/Studium/PDFs/WoodGAMi/Wood - Generalized Additive Models an introduction with R.pdf:application/pdf},
}

@article{deng2023,
	title = {{FIFA}: {MAKING} {FAIRNESS} {MORE} {GENERALIZABLE} {IN} {CLASSIFIERS} {TRAINED} {ON} {IMBALANCED} {DATA}},
	abstract = {Algorithmic fairness plays an important role in machine learning and imposing fairness constraints during learning is a common approach. However, many datasets are imbalanced in certain label classes (e.g. "healthy") and sensitive subgroups (e.g. "older patients"). Empirically, this imbalance leads to a lack of generalizability not only of classification, but also of fairness properties, especially in over-parameterized models. For example, fairness-aware training may ensure equalized odds (EO) on the training data, but EO is far from being satisfied on new users. In this paper, we propose a theoretically-principled, yet Flexible approach that is Imbalance-Fairness-Aware (FIFA). Specifically, FIFA encourages both classification and fairness generalization and can be flexibly combined with many existing fair learning methods with logits-based losses. While our main focus is on EO, FIFA can be directly applied to achieve equalized opportunity (EqOpt); and under certain conditions, it can also be applied to other fairness notions. We demonstrate the power of FIFA by combining it with a popular fair classification algorithm, and the resulting algorithm achieves significantly better fairness generalization on several real-world datasets.},
	language = {en},
	author = {Deng, Zhun and Zhang, Jiayao and Zhang, Linjun and Ye, Ting and Coley, Yates and Su, Weijie J and Zou, James},
	year = {2023},
	file = {Deng et al. - 2023 - FIFA MAKING FAIRNESS MORE GENERALIZABLE IN CLASSIFIERS TRAINED ON IMBALANCED DATA.pdf:/Users/julietfleischer/Library/Mobile Documents/iCloud~md~obsidian/Documents/Studium/PDFs/Deng2023FMFMGCTID/Deng et al. - 2023 - FIFA MAKING FAIRNESS MORE GENERALIZABLE IN CLASSIFIERS TRAINED ON IMBALANCED DATA.pdf:application/pdf},
}

@article{Brzezinski2024PFMCVCIPGR,
	title = {Properties of {Fairness} {Measures} in the {Context} of {Varying} {Class} {Imbalance} and {Protected} {Group} {Ratios}},
	volume = {18},
	issn = {1556-4681},
	url = {https://doi.org/10.1145/3654659},
	doi = {10.1145/3654659},
	abstract = {Society is increasingly relying on predictive models in fields like criminal justice, credit risk management, and hiring. To prevent such automated systems from discriminating against people belonging to certain groups, fairness measures have become a crucial component in socially relevant applications of machine learning. However, existing fairness measures have been designed to assess the bias between predictions for protected groups without considering the imbalance in the classes of the target variable. Current research on the potential effect of class imbalance on fairness focuses on practical applications rather than dataset-independent measure properties. In this article, we study the general properties of fairness measures for changing class and protected group proportions. For this purpose, we analyze the probability mass functions of six of the most popular group fairness measures. We also measure how the probability of achieving perfect fairness changes for varying class imbalance ratios. Moreover, we relate the dataset-independent properties of fairness measures described in this work to classifier fairness in real-life tasks. Our results show that measures such as Equal Opportunity and Positive Predictive Parity are more sensitive to changes in class imbalance than Accuracy Equality. These findings can help guide researchers and practitioners in choosing the most appropriate fairness measures for their classification problems.},
	number = {7},
	urldate = {2024-12-23},
	journal = {ACM Trans. Knowl. Discov. Data},
	author = {Brzezinski, Dariusz and Stachowiak, Julia and Stefanowski, Jerzy and Szczech, Izabela and Susmaga, Robert and Aksenyuk, Sofya and Ivashka, Uladzimir and Yasinskyi, Oleksandr},
	month = jun,
	year = {2024},
	pages = {170:1--170:18},
}

@misc{Ahmadzadeh2022MCSDPEM,
	title = {Measuring {Class}-{Imbalance} {Sensitivity} of {Deterministic} {Performance} {Evaluation} {Metrics}},
	url = {http://arxiv.org/abs/2206.09981},
	doi = {10.48550/arXiv.2206.09981},
	abstract = {The class-imbalance issue is intrinsic to many real-world machine learning tasks, particularly to the rare-event classiﬁcation problems. Although the impact and treatment of imbalanced data is widely known, the magnitude of a metric’s sensitivity to class imbalance has attracted little attention. As a result, often the sensitive metrics are dismissed while their sensitivity may only be marginal. In this paper, we introduce an intuitive evaluation framework that quantiﬁes metrics’ sensitivity to the class imbalance. Moreover, we reveal an interesting fact that there is a logarithmic behavior in metrics’ sensitivity meaning that the higher imbalance ratios are associated with the lower sensitivity of metrics. Our framework builds an intuitive understanding of the class-imbalance impact on metrics. We believe this can help avoid many common mistakes, specially the less-emphasized and incorrect assumption that all metrics’ quantities are comparable under different class-imbalance ratios.},
	language = {en},
	urldate = {2024-12-23},
	publisher = {arXiv},
	author = {Ahmadzadeh, Azim and Angryk, Rafal A.},
	month = jun,
	year = {2022},
	note = {arXiv:2206.09981 [cs]},
	keywords = {Computer Science - Machine Learning},
	file = {Ahmadzadeh und Angryk - 2022 - Measuring Class-Imbalance Sensitivity of Deterministic Performance Evaluation Metrics.pdf:/Users/julietfleischer/Library/Mobile Documents/iCloud~md~obsidian/Documents/Studium/PDFs/Ahmadzadeh2022MCSDPEM/Ahmadzadeh und Angryk - 2022 - Measuring Class-Imbalance Sensitivity of Deterministic Performance Evaluation Metrics.pdf:application/pdf},
}

@article{tang2023,
	title = {What-is and {How}-to for {Fairness} in {Machine} {Learning}: {A} {Survey}, {Reflection}, and {Perspective}},
	volume = {55},
	issn = {0360-0300, 1557-7341},
	shorttitle = {What-is and {How}-to for {Fairness} in {Machine} {Learning}},
	url = {https://dl.acm.org/doi/10.1145/3597199},
	doi = {10.1145/3597199},
	abstract = {We review and reflect on fairness notions proposed in machine learning literature and make an attempt to draw connections to arguments in moral and political philosophy, especially theories of justice. We survey dynamic fairness inquiries and further consider the long-term impact induced by current prediction and decision. We present a flowchart that encompasses implicit assumptions and expected outcomes of different fairness inquiries on the data-generating process, the predicted outcome, and the induced impact, respectively. We demonstrate the importance of matching the mission (what kind of fairness to enforce) and the means (which appropriate fairness spectrum to analyze) to fulfill the intended purpose.},
	language = {en},
	number = {13s},
	urldate = {2024-12-23},
	journal = {ACM Computing Surveys},
	author = {Tang, Zeyu and Zhang, Jiji and Zhang, Kun},
	month = dec,
	year = {2023},
	pages = {1--37},
	file = {Tang et al. - 2023 - What-is and How-to for Fairness in Machine Learning A Survey, Reflection, and Perspective.pdf:/Users/julietfleischer/Library/Mobile Documents/iCloud~md~obsidian/Documents/Studium/PDFs/Tang2023WHFMLSRP/Tang et al. - 2023 - What-is and How-to for Fairness in Machine Learning A Survey, Reflection, and Perspective.pdf:application/pdf},
}

@article{caton2024,
	title = {Fairness in {Machine} {Learning}: {A} {Survey}},
	volume = {56},
	issn = {0360-0300, 1557-7341},
	shorttitle = {Fairness in {Machine} {Learning}},
	url = {https://dl.acm.org/doi/10.1145/3616865},
	doi = {10.1145/3616865},
	abstract = {When Machine Learning technologies are used in contexts that affect citizens, companies as well as researchers need to be confident that there will not be any unexpected social implications, such as bias towards gender, ethnicity, and/or people with disabilities. There is significant literature on approaches to mitigate bias and promote fairness, yet the area is complex and hard to penetrate for newcomers to the domain. This article seeks to provide an overview of the different schools of thought and approaches that aim to increase the fairness of Machine Learning. It organizes approaches into the widely accepted framework of pre-processing, in-processing, and post-processing methods, subcategorizing into a further 11 method areas. Although much of the literature emphasizes binary classification, a discussion of fairness in regression, recommender systems, and unsupervised learning is also provided along with a selection of currently available open source libraries. The article concludes by summarizing open challenges articulated as five dilemmas for fairness research.},
	language = {en},
	number = {7},
	urldate = {2024-12-23},
	journal = {ACM Computing Surveys},
	author = {Caton, Simon and Haas, Christian},
	month = jul,
	year = {2024},
	pages = {1--38},
	file = {Caton und Haas - 2024 - Fairness in Machine Learning A Survey.pdf:/Users/julietfleischer/Library/Mobile Documents/iCloud~md~obsidian/Documents/Studium/PDFs/Caton2024FMLSb/Caton und Haas - 2024 - Fairness in Machine Learning A Survey.pdf:application/pdf},
}

@article{castelnovo2022,
	title = {A clarification of the nuances in the fairness metrics landscape},
	volume = {12},
	issn = {2045-2322},
	url = {https://www.nature.com/articles/s41598-022-07939-1},
	doi = {10.1038/s41598-022-07939-1},
	abstract = {Abstract
            In recent years, the problem of addressing fairness in machine learning (ML) and automatic decision making has attracted a lot of attention in the scientific communities dealing with artificial intelligence. A plethora of different definitions of fairness in ML have been proposed, that consider different notions of what is a “fair decision” in situations impacting individuals in the population. The precise differences, implications and “orthogonality” between these notions have not yet been fully analyzed in the literature. In this work, we try to make some order out of this zoo of definitions.},
	language = {en},
	number = {1},
	urldate = {2024-12-23},
	journal = {Scientific Reports},
	author = {Castelnovo, Alessandro and Crupi, Riccardo and Greco, Greta and Regoli, Daniele and Penco, Ilaria Giuseppina and Cosentini, Andrea Claudio},
	month = mar,
	year = {2022},
	pages = {4209},
	file = {Castelnovo et al. - 2022 - A clarification of the nuances in the fairness metrics landscape.pdf:/Users/julietfleischer/Library/Mobile Documents/iCloud~md~obsidian/Documents/Studium/PDFs/Castelnovo2022cnfmlb/Castelnovo et al. - 2022 - A clarification of the nuances in the fairness metrics landscape.pdf:application/pdf},
}

@misc{vaswani2023,
	title = {Attention {Is} {All} {You} {Need}},
	url = {http://arxiv.org/abs/1706.03762},
	doi = {10.48550/arXiv.1706.03762},
	abstract = {The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.},
	urldate = {2024-12-24},
	publisher = {arXiv},
	author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, Lukasz and Polosukhin, Illia},
	month = aug,
	year = {2023},
	note = {arXiv:1706.03762 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Computation and Language},
	file = {Snapshot:/Users/julietfleischer/Zotero/storage/IYR4TQN8/1706.html:text/html;Vaswani et al. - 2023 - Attention Is All You Need.pdf:/Users/julietfleischer/Library/Mobile Documents/iCloud~md~obsidian/Documents/Studium/PDFs/Vaswani2023AAYN/Vaswani et al. - 2023 - Attention Is All You Need.pdf:application/pdf},
}

@inproceedings{kallus2018,
	title = {Residual {Unfairness} in {Fair} {Machine} {Learning} from {Prejudiced} {Data}},
	url = {https://proceedings.mlr.press/v80/kallus18a.html},
	abstract = {Recent work in fairness in machine learning has proposed adjusting for fairness by equalizing accuracy metrics across groups and has also studied how datasets affected by historical prejudices may lead to unfair decision policies. We connect these lines of work and study the residual unfairness that arises when a fairness-adjusted predictor is not actually fair on the target population due to systematic censoring of training data by existing biased policies. This scenario is particularly common in the same applications where fairness is a concern. We characterize theoretically the impact of such censoring on standard fairness metrics for binary classifiers and provide criteria for when residual unfairness may or may not appear. We prove that, under certain conditions, fairness-adjusted classifiers will in fact induce residual unfairness that perpetuates the same injustices, against the same groups, that biased the data to begin with, thus showing that even state-of-the-art fair machine learning can have a "bias in, bias out" property. When certain benchmark data is available, we show how sample reweighting can estimate and adjust fairness metrics while accounting for censoring. We use this to study the case of Stop, Question, and Frisk (SQF) and demonstrate that attempting to adjust for fairness perpetuates the same injustices that the policy is infamous for.},
	language = {en},
	urldate = {2024-12-24},
	booktitle = {Proceedings of the 35th {International} {Conference} on {Machine} {Learning}},
	publisher = {PMLR},
	author = {Kallus, Nathan and Zhou, Angela},
	month = jul,
	year = {2018},
	note = {ISSN: 2640-3498},
	pages = {2439--2448},
	file = {Kallus und Zhou - 2018 - Residual Unfairness in Fair Machine Learning from Prejudiced Data 2.pdf:/Users/julietfleischer/Library/Mobile Documents/iCloud~md~obsidian/Documents/Studium/PDFs/Kallus2018RUFMLPD/Kallus und Zhou - 2018 - Residual Unfairness in Fair Machine Learning from Prejudiced Data 2.pdf:application/pdf;Kallus und Zhou - 2018 - Residual Unfairness in Fair Machine Learning from Prejudiced Data 3.pdf:/Users/julietfleischer/Library/Mobile Documents/iCloud~md~obsidian/Documents/Studium/PDFs/Kallus2018RUFMLPD/Kallus und Zhou - 2018 - Residual Unfairness in Fair Machine Learning from Prejudiced Data 3.pdf:application/pdf},
}

@article{Badr2022DTFANSP,
	title = {Data {Transparency} and {Fairness} {Analysis} of the {NYPD} {Stop}-and-{Frisk} {Program}},
	volume = {14},
	issn = {1936-1955, 1936-1963},
	url = {https://dl.acm.org/doi/10.1145/3460533},
	doi = {10.1145/3460533},
	abstract = {Given the increased concern of racial disparities in the stop-and-frisk programs, the
              New York Police Department
              (
              NYPD
              ) requires publicly displaying detailed data for all the stops conducted by police authorities, including the suspected offense and race of the suspects. By adopting a public data transparency policy, it becomes possible to investigate racial biases in stop-and-frisk data and demonstrate the benefit of data transparency to approve or disapprove social beliefs and police practices. Thus, data transparency becomes a crucial need in the era of
              Artificial Intelligence
              (
              AI
              ), where police and justice increasingly use different AI techniques not only to understand police practices but also to predict recidivism, crimes, and terrorism. In this study, we develop a predictive analytics method, including bias metrics and bias mitigation techniques to analyze the NYPD Stop-and-Frisk datasets and discover whether underline bias patterns are responsible for stops and arrests. In addition, we perform a fairness analysis on two protected attributes, namely, the race and the gender, and investigate their impacts on arrest decisions. We also apply bias mitigation techniques. The experimental results show that the NYPD Stop-and-Frisk dataset is not biased toward colored and Hispanic individuals and thus law enforcement authorities can apply the bias predictive analytics method to inculcate more fair decisions before making any arrests.},
	language = {en},
	number = {2},
	urldate = {2024-12-24},
	journal = {Journal of Data and Information Quality},
	author = {Badr, Youakim and Sharma, Rahul},
	month = jun,
	year = {2022},
	pages = {1--14},
}

@inproceedings{Khademi2019FADMELC,
	address = {San Francisco CA USA},
	title = {Fairness in {Algorithmic} {Decision} {Making}: {An} {Excursion} {Through} the {Lens} of {Causality}},
	isbn = {978-1-4503-6674-8},
	shorttitle = {Fairness in {Algorithmic} {Decision} {Making}},
	url = {https://dl.acm.org/doi/10.1145/3308558.3313559},
	doi = {10.1145/3308558.3313559},
	language = {en},
	urldate = {2024-12-24},
	booktitle = {The {World} {Wide} {Web} {Conference}},
	publisher = {ACM},
	author = {Khademi, Aria and Lee, Sanghack and Foley, David and Honavar, Vasant},
	month = may,
	year = {2019},
	pages = {2907--2914},
	file = {Khademi et al. - 2019 - Fairness in Algorithmic Decision Making An Excursion Through the Lens of Causality.pdf:/Users/julietfleischer/Library/Mobile Documents/iCloud~md~obsidian/Documents/Studium/PDFs/Khademi2019FADMELC/Khademi et al. - 2019 - Fairness in Algorithmic Decision Making An Excursion Through the Lens of Causality.pdf:application/pdf},
}

@article{RambachanBBOEFW,
	title = {Bias {In}, {Bias} {Out}? {Evaluating} the {Folk} {Wisdom}},
	abstract = {We evaluate the folk wisdom that algorithmic decision rules trained on data produced by biased human decision-makers necessarily reﬂect this bias. We consider a setting where training labels are only generated if a biased decision-maker takes a particular action, and so “biased” training data arise due to discriminatory selection into the training data. In our baseline model, the more biased the decision-maker is against a group, the more the algorithmic decision rule favors that group. We refer to this phenomenon as bias reversal. We then clarify the conditions that give rise to bias reversal. Whether a prediction algorithm reverses or inherits bias depends critically on how the decision-maker affects the training data as well as the label used in training. We illustrate our main theoretical results in a simulation study applied to the New York City Stop, Question and Frisk dataset.},
	language = {en},
	author = {Rambachan, Ashesh and Roth, Jonathan},
	file = {Rambachan und Roth - Bias In, Bias Out Evaluating the Folk Wisdom.pdf:/Users/julietfleischer/Library/Mobile Documents/iCloud~md~obsidian/Documents/Studium/PDFs/RambachanBBOEFW/Rambachan und Roth - Bias In, Bias Out Evaluating the Folk Wisdom.pdf:application/pdf},
}

@inproceedings{Lakkaraju2017SLPEAPPU,
	address = {Halifax NS Canada},
	title = {The {Selective} {Labels} {Problem}: {Evaluating} {Algorithmic} {Predictions} in the {Presence} of {Unobservables}},
	isbn = {978-1-4503-4887-4},
	shorttitle = {The {Selective} {Labels} {Problem}},
	url = {https://dl.acm.org/doi/10.1145/3097983.3098066},
	doi = {10.1145/3097983.3098066},
	abstract = {Evaluating whether machines improve on human performance is one of the central questions of machine learning. However, there are many domains where the data is selectively labeled in the sense that the observed outcomes are themselves a consequence of the existing choices of the human decision-makers. For instance, in the context of judicial bail decisions, we observe the outcome of whether a defendant fails to return for their court appearance only if the human judge decides to release the defendant on bail. This selective labeling makes it harder to evaluate predictive models as the instances for which outcomes are observed do not represent a random sample of the population. Here we propose a novel framework for evaluating the performance of predictive models on selectively labeled data. We develop an approach called contraction which allows us to compare the performance of predictive models and human decision-makers without resorting to counterfactual inference. Our methodology harnesses the heterogeneity of human decision-makers and facilitates eﬀective evaluation of predictive models even in the presence of unmeasured confounders (unobservables) which inﬂuence both human decisions and the resulting outcomes. Experimental results on real world datasets spanning diverse domains such as health care, insurance, and criminal justice demonstrate the utility of our evaluation metric in comparing human decisions and machine predictions.},
	language = {en},
	urldate = {2024-12-25},
	booktitle = {Proceedings of the 23rd {ACM} {SIGKDD} {International} {Conference} on {Knowledge} {Discovery} and {Data} {Mining}},
	publisher = {ACM},
	author = {Lakkaraju, Himabindu and Kleinberg, Jon and Leskovec, Jure and Ludwig, Jens and Mullainathan, Sendhil},
	month = aug,
	year = {2017},
	pages = {275--284},
	file = {Lakkaraju et al. - 2017 - The Selective Labels Problem Evaluating Algorithmic Predictions in the Presence of Unobservables.pdf:/Users/julietfleischer/Library/Mobile Documents/iCloud~md~obsidian/Documents/Studium/PDFs/Lakkaraju2017SLPEAPPU/Lakkaraju et al. - 2017 - The Selective Labels Problem Evaluating Algorithmic Predictions in the Presence of Unobservables.pdf:application/pdf},
}

@inproceedings{Zafar2017FDTDILCDM,
	address = {Perth Australia},
	title = {Fairness {Beyond} {Disparate} {Treatment} \& {Disparate} {Impact}: {Learning} {Classification} without {Disparate} {Mistreatment}},
	isbn = {978-1-4503-4913-0},
	shorttitle = {Fairness {Beyond} {Disparate} {Treatment} \& {Disparate} {Impact}},
	url = {https://dl.acm.org/doi/10.1145/3038912.3052660},
	doi = {10.1145/3038912.3052660},
	language = {en},
	urldate = {2024-12-28},
	booktitle = {Proceedings of the 26th {International} {Conference} on {World} {Wide} {Web}},
	publisher = {International World Wide Web Conferences Steering Committee},
	author = {Zafar, Muhammad Bilal and Valera, Isabel and Gomez Rodriguez, Manuel and Gummadi, Krishna P.},
	month = apr,
	year = {2017},
	pages = {1171--1180},
	file = {Zafar et al. - 2017 - Fairness Beyond Disparate Treatment & Disparate Impact Learning Classification without Disparate Mi.pdf:/Users/julietfleischer/Library/Mobile Documents/iCloud~md~obsidian/Documents/Studium/PDFs/Zafar2017FDTDILCDM/Zafar et al. - 2017 - Fairness Beyond Disparate Treatment & Disparate Impact Learning Classification without Disparate Mi.pdf:application/pdf},
}

@article{Hort2024BMMLCCS,
	title = {Bias {Mitigation} for {Machine} {Learning} {Classifiers}: {A} {Comprehensive} {Survey}},
	volume = {1},
	issn = {2832-0565},
	shorttitle = {Bias {Mitigation} for {Machine} {Learning} {Classifiers}},
	url = {https://dl.acm.org/doi/10.1145/3631326},
	doi = {10.1145/3631326},
	abstract = {This article provides a comprehensive survey of bias mitigation methods for achieving fairness in Machine Learning (ML) models. We collect a total of 341 publications concerning bias mitigation for ML classifiers. These methods can be distinguished based on their intervention procedure (i.e., pre-processing, in-processing, post-processing) and the technique they apply. We investigate how existing bias mitigation methods are evaluated in the literature. In particular, we consider datasets, metrics, and benchmarking. Based on the gathered insights (e.g., What is the most popular fairness metric? How many datasets are used for evaluating bias mitigation methods?), we hope to support practitioners in making informed choices when developing and evaluating new bias mitigation methods.},
	language = {en},
	number = {2},
	urldate = {2024-12-28},
	journal = {ACM Journal on Responsible Computing},
	author = {Hort, Max and Chen, Zhenpeng and Zhang, Jie M. and Harman, Mark and Sarro, Federica},
	month = jun,
	year = {2024},
	pages = {1--52},
	file = {Hort et al. - 2024 - Bias Mitigation for Machine Learning Classifiers A Comprehensive Survey.pdf:/Users/julietfleischer/Library/Mobile Documents/iCloud~md~obsidian/Documents/Studium/PDFs/Hort2024BMMLCCS/Hort et al. - 2024 - Bias Mitigation for Machine Learning Classifiers A Comprehensive Survey.pdf:application/pdf},
}

@article{Pessach2023RFML,
	title = {A {Review} on {Fairness} in {Machine} {Learning}},
	volume = {55},
	issn = {0360-0300, 1557-7341},
	url = {https://dl.acm.org/doi/10.1145/3494672},
	doi = {10.1145/3494672},
	abstract = {An increasing number of decisions regarding the daily lives of human beings are being controlled by artificial intelligence and machine learning (ML) algorithms in spheres ranging from healthcare, transportation, and education to college admissions, recruitment, provision of loans, and many more realms. Since they now touch on many aspects of our lives, it is crucial to develop ML algorithms that are not only accurate but also objective and fair. Recent studies have shown that algorithmic decision making may be inherently prone to unfairness, even when there is no intention for it. This article presents an overview of the main concepts of identifying, measuring, and improving algorithmic fairness when using ML algorithms, focusing primarily on classification tasks. The article begins by discussing the causes of algorithmic bias and unfairness and the common definitions and measures for fairness. Fairness-enhancing mechanisms are then reviewed and divided into pre-process, in-process, and post-process mechanisms. A comprehensive comparison of the mechanisms is then conducted, toward a better understanding of which mechanisms should be used in different scenarios. The article ends by reviewing several emerging research sub-fields of algorithmic fairness, beyond classification.},
	language = {en},
	number = {3},
	urldate = {2024-12-28},
	journal = {ACM Computing Surveys},
	author = {Pessach, Dana and Shmueli, Erez},
	month = mar,
	year = {2023},
	pages = {1--44},
}

@inproceedings{Islam2022DMLEAEFC,
	address = {Philadelphia PA USA},
	title = {Through the {Data} {Management} {Lens}: {Experimental} {Analysis} and {Evaluation} of {Fair} {Classification}},
	isbn = {978-1-4503-9249-5},
	shorttitle = {Through the {Data} {Management} {Lens}},
	url = {https://dl.acm.org/doi/10.1145/3514221.3517841},
	doi = {10.1145/3514221.3517841},
	language = {en},
	urldate = {2024-12-28},
	booktitle = {Proceedings of the 2022 {International} {Conference} on {Management} of {Data}},
	publisher = {ACM},
	author = {Islam, Maliha Tashfia and Fariha, Anna and Meliou, Alexandra and Salimi, Babak},
	month = jun,
	year = {2022},
	pages = {232--246},
	file = {Islam et al. - 2022 - Through the Data Management Lens Experimental Analysis and Evaluation of Fair Classification.pdf:/Users/julietfleischer/Library/Mobile Documents/iCloud~md~obsidian/Documents/Studium/PDFs/Islam2022DMLEAEFC/Islam et al. - 2022 - Through the Data Management Lens Experimental Analysis and Evaluation of Fair Classification.pdf:application/pdf},
}

@article{corbett-davies,
	title = {The {Measure} and {Mismeasure} of {Fairness}},
	abstract = {The ﬁeld of fair machine learning aims to ensure that decisions guided by algorithms are equitable. Over the last decade, several formal, mathematical deﬁnitions of fairness have gained prominence. Here we ﬁrst assemble and categorize these deﬁnitions into two broad families: (1) those that constrain the eﬀects of decisions on disparities; and (2) those that constrain the eﬀects of legally protected characteristics, like race and gender, on decisions. We then show, analytically and empirically, that both families of deﬁnitions typically result in strongly Pareto dominated decision policies. For example, in the case of college admissions, adhering to popular formal conceptions of fairness would simultaneously result in lower student-body diversity and a less academically prepared class, relative to what one could achieve by explicitly tailoring admissions policies to achieve desired outcomes. In this sense, requiring that these fairness deﬁnitions hold can, perversely, harm the very groups they were designed to protect. In contrast to axiomatic notions of fairness, we argue that the equitable design of algorithms requires grappling with their context-speciﬁc consequences, akin to the equitable design of policy. We conclude by listing several open challenges in fair machine learning and oﬀering strategies to ensure algorithms are better aligned with policy goals.},
	language = {en},
	author = {Corbett-Davies, Sam and Gaebler, Johann D and Nilforoshan, Hamed and Shroﬀ, Ravi and Goel, Sharad},
	file = {Corbett-Davies et al. - The Measure and Mismeasure of Fairness.pdf:/Users/julietfleischer/Library/Mobile Documents/iCloud~md~obsidian/Documents/Studium/PDFs/Corbett-DaviesMMFa/Corbett-Davies et al. - The Measure and Mismeasure of Fairness.pdf:application/pdf},
}

@article{barocas,
	title = {Fairness and {Machine} {Learning}},
	language = {en},
	author = {Barocas, Solon and Hardt, Moritz and Narayanan, Arvind},
	file = {Barocas et al. - Fairness and Machine Learning.pdf:/Users/julietfleischer/Library/Mobile Documents/iCloud~md~obsidian/Documents/Studium/PDFs/BarocasFML/Barocas et al. - Fairness and Machine Learning.pdf:application/pdf},
}

@inproceedings{dwork2012,
	address = {Cambridge Massachusetts},
	title = {Fairness through awareness},
	isbn = {978-1-4503-1115-1},
	url = {https://dl.acm.org/doi/10.1145/2090236.2090255},
	doi = {10.1145/2090236.2090255},
	abstract = {We study fairness in classiﬁcation, where individuals are classiﬁed, e.g., admitted to a university, and the goal is to prevent discrimination against individuals based on their membership in some group, while maintaining utility for the classiﬁer (the university). The main conceptual contribution of this paper is a framework for fair classiﬁcation comprising (1) a (hypothetical) task-speciﬁc metric for determining the degree to which individuals are similar with respect to the classiﬁcation task at hand; (2) an algorithm for maximizing utility subject to the fairness constraint, that similar individuals are treated similarly. We also present an adaptation of our approach to achieve the complementary goal of “fair aﬃrmative action,” which guarantees statistical parity (i.e., the demographics of the set of individuals receiving any classiﬁcation are the same as the demographics of the underlying population), while treating similar individuals as similarly as possible. Finally, we discuss the relationship of fairness to privacy: when fairness implies privacy, and how tools developed in the context of diﬀerential privacy may be applied to fairness.},
	language = {en},
	urldate = {2024-12-29},
	booktitle = {Proceedings of the 3rd {Innovations} in {Theoretical} {Computer} {Science} {Conference}},
	publisher = {ACM},
	author = {Dwork, Cynthia and Hardt, Moritz and Pitassi, Toniann and Reingold, Omer and Zemel, Richard},
	month = jan,
	year = {2012},
	pages = {214--226},
	file = {Dwork et al. - 2012 - Fairness through awareness.pdf:/Users/julietfleischer/Library/Mobile Documents/iCloud~md~obsidian/Documents/Studium/PDFs/Dwork2012Faa/Dwork et al. - 2012 - Fairness through awareness.pdf:application/pdf},
}

@inproceedings{Zafar2017PPNFC,
	title = {From {Parity} to {Preference}-based {Notions} of {Fairness} in {Classification}},
	volume = {30},
	url = {https://proceedings.neurips.cc/paper_files/paper/2017/hash/82161242827b703e6acf9c726942a1e4-Abstract.html},
	abstract = {The adoption of automated, data-driven decision making in an ever expanding range of applications has raised concerns about its potential unfairness towards certain social groups. In this context, a number of recent studies have focused on defining, detecting, and removing unfairness from data-driven decision systems. However, the existing notions of fairness, based on parity (equality) in treatment or outcomes for different social groups, tend to be quite stringent, limiting the overall decision making accuracy. In this paper, we draw inspiration from the fair-division and envy-freeness literature in economics and game theory and propose preference-based notions of fairness -- given the choice between various sets of decision treatments or outcomes, any group of users would collectively prefer its treatment or outcomes, regardless of the (dis)parity as compared to the other groups. Then, we introduce tractable proxies to design margin-based classifiers that satisfy these preference-based notions of fairness. Finally, we experiment with a variety of synthetic and real-world datasets and show that preference-based fairness allows for greater decision accuracy than parity-based fairness.},
	urldate = {2024-12-29},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Zafar, Muhammad Bilal and Valera, Isabel and Rodriguez, Manuel and Gummadi, Krishna and Weller, Adrian},
	year = {2017},
	file = {Zafar et al. - 2017 - From Parity to Preference-based Notions of Fairness in Classification.pdf:/Users/julietfleischer/Library/Mobile Documents/iCloud~md~obsidian/Documents/Studium/PDFs/Zafar2017PPNFC/Zafar et al. - 2017 - From Parity to Preference-based Notions of Fairness in Classification.pdf:application/pdf},
}

@article{mehrabi2022,
	title = {A {Survey} on {Bias} and {Fairness} in {Machine} {Learning}},
	volume = {54},
	issn = {0360-0300, 1557-7341},
	url = {https://dl.acm.org/doi/10.1145/3457607},
	doi = {10.1145/3457607},
	abstract = {With the widespread use of artificial intelligence (AI) systems and applications in our everyday lives, accounting for fairness has gained significant importance in designing and engineering of such systems. AI systems can be used in many sensitive environments to make important and life-changing decisions; thus, it is crucial to ensure that these decisions do not reflect discriminatory behavior toward certain groups or populations. More recently some work has been developed in traditional machine learning and deep learning that address such challenges in different subdomains. With the commercialization of these systems, researchers are becoming more aware of the biases that these applications can contain and are attempting to address them. In this survey, we investigated different real-world applications that have shown biases in various ways, and we listed different sources of biases that can affect AI applications. We then created a taxonomy for fairness definitions that machine learning researchers have defined to avoid the existing bias in AI systems. In addition to that, we examined different domains and subdomains in AI showing what researchers have observed with regard to unfair outcomes in the state-of-the-art methods and ways they have tried to address them. There are still many future directions and solutions that can be taken to mitigate the problem of bias in AI systems. We are hoping that this survey will motivate researchers to tackle these issues in the near future by observing existing work in their respective fields.},
	language = {en},
	number = {6},
	urldate = {2025-01-07},
	journal = {ACM Computing Surveys},
	author = {Mehrabi, Ninareh and Morstatter, Fred and Saxena, Nripsuta and Lerman, Kristina and Galstyan, Aram},
	month = jul,
	year = {2022},
	pages = {1--35},
	file = {Mehrabi et al. - 2022 - A Survey on Bias and Fairness in Machine Learning.pdf:/Users/julietfleischer/Library/Mobile Documents/iCloud~md~obsidian/Documents/Studium/PDFs/mehrabi2022/Mehrabi et al. - 2022 - A Survey on Bias and Fairness in Machine Learning.pdf:application/pdf},
}

@article{ravishankar2023,
	title = {Provable {Detection} of {Propagating} {Sampling} {Bias} in {Prediction} {Models}},
	volume = {37},
	issn = {2374-3468, 2159-5399},
	url = {https://ojs.aaai.org/index.php/AAAI/article/view/26144},
	doi = {10.1609/aaai.v37i8.26144},
	abstract = {With an increased focus on incorporating fairness in machine learning models, it becomes imperative not only to assess and mitigate bias at each stage of the machine learning pipeline but also to understand the downstream impacts of bias across stages. Here we consider a general, but realistic, scenario in which a predictive model is learned from (potentially biased) training data, and model predictions are assessed post-hoc for fairness by some auditing method. We provide a theoretical analysis of how a specific form of data bias, differential sampling bias, propagates from the data stage to the prediction stage. Unlike prior work, we evaluate the downstream impacts of data biases quantitatively rather than qualitatively and prove theoretical guarantees for detection. Under reasonable assumptions, we quantify how the amount of bias in the model predictions varies as a function of the amount of differential sampling bias in the data, and at what point this bias becomes provably detectable by the auditor. Through experiments on two criminal justice datasets– the well-known COMPAS dataset and historical data from NYPD’s stop and frisk policy– we demonstrate that the theoretical results hold in practice even when our assumptions are relaxed.},
	language = {en},
	number = {8},
	urldate = {2025-01-08},
	journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
	author = {Ravishankar, Pavan and Mo, Qingyu and McFowland Iii, Edward and Neill, Daniel B.},
	month = jun,
	year = {2023},
	pages = {9562--9569},
	file = {Ravishankar et al. - 2023 - Provable Detection of Propagating Sampling Bias in Prediction Models.pdf:/Users/julietfleischer/Library/Mobile Documents/iCloud~md~obsidian/Documents/Studium/PDFs/ravishankar2023/Ravishankar et al. - 2023 - Provable Detection of Propagating Sampling Bias in Prediction Models.pdf:application/pdf},
}

@article{kallus,
	title = {Residual {Unfairness} in {Fair} {Machine} {Learning} from {Prejudiced} {Data}},
	abstract = {Recent work in fairness in machine learning has proposed adjusting for fairness by equalizing accuracy metrics across groups and has also studied how datasets affected by historical prejudices may lead to unfair decision policies. We connect these lines of work and study the residual unfairness that arises when a fairness-adjusted predictor is not actually fair on the target population due to systematic censoring of training data by existing biased policies. This scenario is particularly common in the same applications where fairness is a concern. We characterize theoretically the impact of such censoring on standard fairness metrics for binary classiﬁers and provide criteria for when residual unfairness may or may not appear. We prove that, under certain conditions, fairnessadjusted classiﬁers will in fact induce residual unfairness that perpetuates the same injustices, against the same groups, that biased the data to begin with, thus showing that even state-of-theart fair machine learning can have a “bias in, bias out” property. When certain benchmark data is available, we show how sample reweighting can estimate and adjust fairness metrics while accounting for censoring. We use this to study the case of Stop, Question, and Frisk (SQF) and demonstrate that attempting to adjust for fairness perpetuates the same injustices that the policy is infamous for.},
	language = {en},
	author = {Kallus, Nathan and Zhou, Angela},
	file = {Kallus und Zhou - Residual Unfairness in Fair Machine Learning from Prejudiced Data.pdf:/Users/julietfleischer/Library/Mobile Documents/iCloud~md~obsidian/Documents/Studium/PDFs/kallus/Kallus und Zhou - Residual Unfairness in Fair Machine Learning from Prejudiced Data.pdf:application/pdf},
}

@article{gelman2007,
	title = {An {Analysis} of the {New} {York} {City} {Police} {Department}'s “{Stop}-and-{Frisk}” {Policy} in the {Context} of {Claims} of {Racial} {Bias}},
	volume = {102},
	issn = {0162-1459, 1537-274X},
	url = {http://www.tandfonline.com/doi/abs/10.1198/016214506000001040},
	doi = {10.1198/016214506000001040},
	language = {en},
	number = {479},
	urldate = {2025-01-08},
	journal = {Journal of the American Statistical Association},
	author = {Gelman, Andrew and Fagan, Jeffrey and Kiss, Alex},
	month = sep,
	year = {2007},
	pages = {813--823},
	file = {Gelman et al. - 2007 - An Analysis of the New York City Police Department's “Stop-and-Frisk” Policy in the Context of Claim.pdf:/Users/julietfleischer/Library/Mobile Documents/iCloud~md~obsidian/Documents/Studium/PDFs/gelman2007/Gelman et al. - 2007 - An Analysis of the New York City Police Department's “Stop-and-Frisk” Policy in the Context of Claim.pdf:application/pdf},
}

@article{sewell,
	title = {Crime and {Enforcement} {Activity} in {New} {York} {City}},
	language = {en},
	author = {Sewell, Keechant},
	file = {Sewell - Crime and Enforcement Activity in New York City.pdf:/Users/julietfleischer/Library/Mobile Documents/iCloud~md~obsidian/Documents/Studium/PDFs/sewell/Sewell - Crime and Enforcement Activity in New York City.pdf:application/pdf},
}

@book{lane,
	title = {Chapter 11 {Bias} and {Fairness} {\textbar} {Big} {Data} and {Social} {Science}},
	url = {https://textbook.coleridgeinitiative.org/chap-bias.html},
	abstract = {Chapter 11 Bias and Fairness {\textbar} Big Data and Social Science},
	urldate = {2025-01-15},
	author = {Lane, Rayid Ghani, Ron S. Jarmin, Frauke Kreuter {and} Julia, Ian Foster},
	file = {Snapshot:/Users/julietfleischer/Zotero/storage/IKNVR93L/chap-bias.html:text/html},
}

@inproceedings{ribeiro2016,
	address = {San Francisco California USA},
	title = {"{Why} {Should} {I} {Trust} {You}?": {Explaining} the {Predictions} of {Any} {Classifier}},
	isbn = {978-1-4503-4232-2},
	shorttitle = {"{Why} {Should} {I} {Trust} {You}?},
	url = {https://dl.acm.org/doi/10.1145/2939672.2939778},
	doi = {10.1145/2939672.2939778},
	language = {en},
	urldate = {2025-01-16},
	booktitle = {Proceedings of the 22nd {ACM} {SIGKDD} {International} {Conference} on {Knowledge} {Discovery} and {Data} {Mining}},
	publisher = {ACM},
	author = {Ribeiro, Marco Tulio and Singh, Sameer and Guestrin, Carlos},
	month = aug,
	year = {2016},
	pages = {1135--1144},
}

@inproceedings{hardt2016,
	title = {Equality of {Opportunity} in {Supervised} {Learning}},
	volume = {29},
	url = {https://proceedings.neurips.cc/paper/2016/hash/9d2682367c3935defcb1f9e247a97c0d-Abstract.html},
	abstract = {We propose a criterion for discrimination against a specified sensitive attribute in supervised learning, where the goal is to predict some target based on available features. Assuming data about the predictor, target, and membership in the protected group are available, we show how to optimally adjust any learned predictor so as to remove discrimination according to our definition. Our framework also improves incentives by shifting the cost of poor classification from disadvantaged groups to the decision maker, who can respond by improving the classification accuracy.},
	urldate = {2025-01-27},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Hardt, Moritz and Price, Eric and Price, Eric and Srebro, Nati},
	year = {2016},
	file = {Hardt et al. - 2016 - Equality of Opportunity in Supervised Learning.pdf:/Users/julietfleischer/Library/Mobile Documents/iCloud~md~obsidian/Documents/Studium/PDFs/hardt2016/Hardt et al. - 2016 - Equality of Opportunity in Supervised Learning.pdf:application/pdf},
}

@misc{hardt2016a,
	title = {Equality of {Opportunity} in {Supervised} {Learning}},
	url = {http://arxiv.org/abs/1610.02413},
	doi = {10.48550/arXiv.1610.02413},
	abstract = {We propose a criterion for discrimination against a specified sensitive attribute in supervised learning, where the goal is to predict some target based on available features. Assuming data about the predictor, target, and membership in the protected group are available, we show how to optimally adjust any learned predictor so as to remove discrimination according to our definition. Our framework also improves incentives by shifting the cost of poor classification from disadvantaged groups to the decision maker, who can respond by improving the classification accuracy. In line with other studies, our notion is oblivious: it depends only on the joint statistics of the predictor, the target and the protected attribute, but not on interpretation of individualfeatures. We study the inherent limits of defining and identifying biases based on such oblivious measures, outlining what can and cannot be inferred from different oblivious tests. We illustrate our notion using a case study of FICO credit scores.},
	urldate = {2025-01-27},
	publisher = {arXiv},
	author = {Hardt, Moritz and Price, Eric and Srebro, Nathan},
	month = oct,
	year = {2016},
	note = {arXiv:1610.02413 [cs]},
	keywords = {Computer Science - Machine Learning},
	file = {Hardt et al. - 2016 - Equality of Opportunity in Supervised Learning.pdf:/Users/julietfleischer/Library/Mobile Documents/iCloud~md~obsidian/Documents/Studium/PDFs/hardt2016a/Hardt et al. - 2016 - Equality of Opportunity in Supervised Learning.pdf:application/pdf;Snapshot:/Users/julietfleischer/Zotero/storage/T68QGMWK/1610.html:text/html},
}

@article{wood,
	title = {Generalized {Additive} {Models}: an introduction with {R}},
	language = {en},
	author = {Wood, Simon N},
	file = {Wood - Generalized Additive Models an introduction with R.pdf:/Users/julietfleischer/Library/Mobile Documents/iCloud~md~obsidian/Documents/Studium/PDFs/wood/Wood - Generalized Additive Models an introduction with R.pdf:application/pdf},
}

@book{ridgeway2007,
	address = {Santa Monica, CA},
	series = {Technical report},
	title = {Analysis of racial disparities in the {New} {York} {Police} {Department}'s stop, question, and frisk practices},
	isbn = {978-0-8330-4515-7},
	language = {en},
	number = {TR-534-NYCPF},
	publisher = {RAND Corporation},
	author = {Ridgeway, Greg},
	collaborator = {{Rand Corporation}},
	year = {2007},
	keywords = {Discrimination in law enforcement, New York (N.Y.), New York (State) New York, Police, Police Department, Stop and frisk (Law enforcement)},
	file = {Ridgeway - 2007 - Analysis of racial disparities in the New York Police Department's stop, question, and frisk practic.pdf:/Users/julietfleischer/Library/Mobile Documents/iCloud~md~obsidian/Documents/Studium/PDFs/ridgeway2007/Ridgeway - 2007 - Analysis of racial disparities in the New York Police Department's stop, question, and frisk practic.pdf:application/pdf},
}

@article{favier2023,
	title = {How to be fair? {A} study of label and selection bias},
	volume = {112},
	issn = {0885-6125, 1573-0565},
	shorttitle = {How to be fair?},
	url = {https://link.springer.com/10.1007/s10994-023-06401-1},
	doi = {10.1007/s10994-023-06401-1},
	abstract = {It is widely accepted that biased data leads to biased and thus potentially unfair models. Therefore, several measures for bias in data and model predictions have been proposed, as well as bias mitigation techniques whose aim is to learn models that are fair by design. Despite the myriad of mitigation techniques developed in the past decade, however, it is still poorly understood under what circumstances which methods work. Recently, Wick et al. showed, with experiments on synthetic data, that there exist situations in which bias mitigation techniques lead to more accurate models when measured on unbiased data. Nevertheless, in the absence of a thorough mathematical analysis, it remains unclear which techniques are effective under what circumstances. We propose to address this problem by establishing relationships between the type of bias and the effectiveness of a mitigation technique, where we categorize the mitigation techniques by the bias measure they optimize. In this paper we illustrate this principle for label and selection bias on the one hand, and demographic parity and “We’re All Equal” on the other hand. Our theoretical analysis allows to explain the results of Wick et al. and we also show that there are situations where minimizing fairness measures does not result in the fairest possible distribution.},
	language = {en},
	number = {12},
	urldate = {2025-02-05},
	journal = {Machine Learning},
	author = {Favier, Marco and Calders, Toon and Pinxteren, Sam and Meyer, Jonathan},
	month = dec,
	year = {2023},
	pages = {5081--5104},
	file = {Favier et al. - 2023 - How to be fair A study of label and selection bias.pdf:/Users/julietfleischer/Library/Mobile Documents/iCloud~md~obsidian/Documents/Studium/PDFs/favier2023/Favier et al. - 2023 - How to be fair A study of label and selection bias.pdf:application/pdf},
}

@misc{bothmann2024,
	title = {What {Is} {Fairness}? {On} the {Role} of {Protected} {Attributes} and {Fictitious} {Worlds}},
	shorttitle = {What {Is} {Fairness}?},
	url = {http://arxiv.org/abs/2205.09622},
	doi = {10.48550/arXiv.2205.09622},
	abstract = {A growing body of literature in fairness-aware machine learning (fairML) aims to mitigate machine learning (ML)-related unfairness in automated decision-making (ADM) by defining metrics that measure fairness of an ML model and by proposing methods to ensure that trained ML models achieve low scores on these metrics. However, the underlying concept of fairness, i.e., the question of what fairness is, is rarely discussed, leaving a significant gap between centuries of philosophical discussion and the recent adoption of the concept in the ML community. In this work, we try to bridge this gap by formalizing a consistent concept of fairness and by translating the philosophical considerations into a formal framework for the training and evaluation of ML models in ADM systems. We argue that fairness problems can arise even without the presence of protected attributes (PAs), and point out that fairness and predictive performance are not irreconcilable opposites, but that the latter is necessary to achieve the former. Furthermore, we argue why and how causal considerations are necessary when assessing fairness in the presence of PAs by proposing a fictitious, normatively desired (FiND) world in which PAs have no causal effects. In practice, this FiND world must be approximated by a warped world in which the causal effects of the PAs are removed from the real-world data. Finally, we achieve greater linguistic clarity in the discussion of fairML. We outline algorithms for practical applications and present illustrative experiments on COMPAS data.},
	language = {en},
	urldate = {2025-02-25},
	publisher = {arXiv},
	author = {Bothmann, Ludwig and Peters, Kristina and Bischl, Bernd},
	month = nov,
	year = {2024},
	note = {arXiv:2205.09622 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computers and Society},
	file = {Bothmann et al. - 2024 - What Is Fairness On the Role of Protected Attributes and Fictitious Worlds.pdf:/Users/julietfleischer/Library/Mobile Documents/iCloud~md~obsidian/Documents/Studium/PDFs/bothmann2024/Bothmann et al. - 2024 - What Is Fairness On the Role of Protected Attributes and Fictitious Worlds.pdf:application/pdf},
}

@article{rambachan2016,
	title = {Bias {In}, {Bias} {Out}? {Evaluating} the {Folk} {Wisdom}},
	abstract = {We evaluate the folk wisdom that algorithmic decision rules trained on data produced by biased human decision-makers necessarily reﬂect this bias. We consider a setting where training labels are only generated if a biased decision-maker takes a particular action, and so “biased” training data arise due to discriminatory selection into the training data. In our baseline model, the more biased the decision-maker is against a group, the more the algorithmic decision rule favors that group. We refer to this phenomenon as bias reversal. We then clarify the conditions that give rise to bias reversal. Whether a prediction algorithm reverses or inherits bias depends critically on how the decision-maker aﬀects the training data as well as the label used in training. We illustrate our main theoretical results in a simulation study applied to the New York City Stop, Question and Frisk dataset.},
	language = {en},
	author = {Rambachan, Ashesh and Roth, Jonathan},
	year = {2016},
	file = {Rambachan und Roth - 2016 - Bias In, Bias Out Evaluating the Folk Wisdom.pdf:/Users/julietfleischer/Library/Mobile Documents/iCloud~md~obsidian/Documents/Studium/PDFs/rambachan2016/Rambachan und Roth - 2016 - Bias In, Bias Out Evaluating the Folk Wisdom.pdf:application/pdf},
}

@article{kleinberg2017,
	title = {Inherent {Trade}-{Offs} in the {Fair} {Determination} of {Risk} {Scores}},
	volume = {67},
	copyright = {Creative Commons Attribution 3.0 Unported license, info:eu-repo/semantics/openAccess},
	issn = {1868-8969},
	url = {https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.ITCS.2017.43},
	doi = {10.4230/LIPICS.ITCS.2017.43},
	abstract = {Recent discussion in the public sphere about algorithmic classiﬁcation has involved tension between competing notions of what it means for a probabilistic classiﬁcation to be fair to diﬀerent groups. We formalize three fairness conditions that lie at the heart of these debates, and we prove that except in highly constrained special cases, there is no method that can satisfy these three conditions simultaneously. Moreover, even satisfying all three conditions approximately requires that the data lie in an approximate version of one of the constrained special cases identiﬁed by our theorem. These results suggest some of the ways in which key notions of fairness are incompatible with each other, and hence provide a framework for thinking about the trade-oﬀs between them.},
	language = {en},
	urldate = {2025-02-27},
	journal = {LIPIcs, Volume 67, ITCS 2017},
	author = {Kleinberg, Jon and Mullainathan, Sendhil and Raghavan, Manish},
	collaborator = {Papadimitriou, Christos H.},
	year = {2017},
	note = {Artwork Size: 23 pages, 503645 bytes
ISBN: 9783959770293
Medium: application/pdf
Publisher: Schloss Dagstuhl – Leibniz-Zentrum für Informatik},
	keywords = {algorithmic fairness, calibration, risk tools},
	pages = {43:1--43:23},
	file = {Kleinberg et al. - 2017 - Inherent Trade-Offs in the Fair Determination of Risk Scores.pdf:/Users/julietfleischer/Library/Mobile Documents/iCloud~md~obsidian/Documents/Studium/PDFs/kleinberg2017/Kleinberg et al. - 2017 - Inherent Trade-Offs in the Fair Determination of Risk Scores.pdf:application/pdf},
}

@article{jr,
	title = {A {Decision} {Theoretic} {Approach} {To} {Optimizing} {Machine} {Learning} {Decisions} with {Prediction} {Uncertainty}},
	language = {en},
	author = {Jr, Richard V Field and Darling, Michael C},
	file = {Jr und Darling - A Decision Theoretic Approach To Optimizing Machine Learning Decisions with Prediction Uncertainty.pdf:/Users/julietfleischer/Library/Mobile Documents/iCloud~md~obsidian/Documents/Studium/PDFs/jr/Jr und Darling - A Decision Theoretic Approach To Optimizing Machine Learning Decisions with Prediction Uncertainty.pdf:application/pdf},
}

@phdthesis{akhavizadegan2021,
	address = {Ames (Iowa)},
	type = {Doctor of {Philosophy}},
	title = {Integration of machine learning and optimization for decision making under uncertainties with applications in agriculture and power system},
	url = {https://dr.lib.iastate.edu/handle/20.500.12876/Qr9mDbJr},
	language = {en},
	urldate = {2025-03-08},
	school = {Iowa State University},
	author = {Akhavizadegan, Faezeh},
	year = {2021},
	doi = {10.31274/td-20240329-436},
	file = {Akhavizadegan - 2021 - Integration of machine learning and optimization for decision making under uncertainties with applic.pdf:/Users/julietfleischer/Library/Mobile Documents/iCloud~md~obsidian/Documents/Studium/PDFs/akhavizadegan2021/Akhavizadegan - 2021 - Integration of machine learning and optimization for decision making under uncertainties with applic.pdf:application/pdf},
}

@article{madsen2023,
	title = {A review of {N}‐mixture models},
	volume = {15},
	issn = {1939-5108, 1939-0068},
	url = {https://wires.onlinelibrary.wiley.com/doi/10.1002/wics.1625},
	doi = {10.1002/wics.1625},
	abstract = {N-mixture models were born in 2004 of the necessity to model animal population size from point counts with imperfect detection of individuals, where capture-recapture methods are infeasible. Initially developed for applications where population size was assumed constant, N-mixture models were extended in 2011 to include population dynamics, allowing application to populations whose size fluctuates during the study. A further extension in 2014 accommodates populations with multiple “states” such as age class or sex. More recent extensions model spatial movement of animals among habitat patches or the spatial spread of infectious disease in a human population. The core idea underlying this class of models is a hierarchical structure, where the observation model is defined conditional on the model for true abundance. This hierarchy allows researchers to incorporate information about observation and abundance processes, while permitting distinct inferences about elements affecting detection and those affecting abundance. Another benefit of the hierarchical approach is the ability to accommodate many existing sampling protocols such as removal sampling and distance sampling. One drawback to N-mixture models is that since they estimate both abundance and detection from replicated but unmarked counts, model parameters may not be clearly identifiable. A second drawback is that when observed counts are large, calculating the N-mixture likelihood is computationally infeasible. This difficulty motivated an approximate likelihood based on the normal approximation to the binomial. The normal approximation provides a diagnostic of parameter estimability based on the closed-form expression of the Fisher information matrix for a multivariate normal likelihood.},
	language = {en},
	number = {6},
	urldate = {2025-03-09},
	journal = {WIREs Computational Statistics},
	author = {Madsen, Lisa and Royle, J. Andrew},
	month = nov,
	year = {2023},
	pages = {e1625},
	file = {Madsen und Royle - 2023 - A review of N‐mixture models.pdf:/Users/julietfleischer/Library/Mobile Documents/iCloud~md~obsidian/Documents/Studium/PDFs/madsen2023/Madsen und Royle - 2023 - A review of N‐mixture models.pdf:application/pdf},
}

@article{nikparvar2021,
	title = {Machine {Learning} of {Spatial} {Data}},
	volume = {10},
	copyright = {https://creativecommons.org/licenses/by/4.0/},
	issn = {2220-9964},
	url = {https://www.mdpi.com/2220-9964/10/9/600},
	doi = {10.3390/ijgi10090600},
	abstract = {Properties of spatially explicit data are often ignored or inadequately handled in machine learning for spatial domains of application. At the same time, resources that would identify these properties and investigate their inﬂuence and methods to handle them in machine learning applications are lagging behind. In this survey of the literature, we seek to identify and discuss spatial properties of data that inﬂuence the performance of machine learning. We review some of the best practices in handling such properties in spatial domains and discuss their advantages and disadvantages. We recognize two broad strands in this literature. In the ﬁrst, the properties of spatial data are developed in the spatial observation matrix without amending the substance of the learning algorithm; in the other, spatial data properties are handled in the learning algorithm itself. While the latter have been far less explored, we argue that they offer the most promising prospects for the future of spatial machine learning.},
	language = {en},
	number = {9},
	urldate = {2025-03-10},
	journal = {ISPRS International Journal of Geo-Information},
	author = {Nikparvar, Behnam and Thill, Jean-Claude},
	month = sep,
	year = {2021},
	pages = {600},
	file = {Nikparvar und Thill - 2021 - Machine Learning of Spatial Data.pdf:/Users/julietfleischer/Library/Mobile Documents/iCloud~md~obsidian/Documents/Studium/PDFs/nikparvar2021/Nikparvar und Thill - 2021 - Machine Learning of Spatial Data.pdf:application/pdf},
}

@article{koetke2024,
	title = {Using camera traps and {N}‐mixture models to estimate population abundance: {Model} selection really matters},
	volume = {15},
	issn = {2041-210X, 2041-210X},
	shorttitle = {Using camera traps and {N}‐mixture models to estimate population abundance},
	url = {https://besjournals.onlinelibrary.wiley.com/doi/10.1111/2041-210X.14320},
	doi = {10.1111/2041-210X.14320},
	abstract = {Abstract
            
              
                
                  Estimating the abundance or density of wildlife populations is a critical part of species conservation and management, but estimates can vary greatly in precision and accuracy according to the sampling and statistical methods, sampling and ecological variation, and sample size.
                
                
                  
                    We used images of moose (
                    Alces americanus
                    ) from camera traps to parameterize N‐mixture models and tested the effect of ecological conditions, the spatial scale of measurement, and the criteria used to define independent detections on estimates of population abundance. We compared the model estimates to those generated empirically with aerial survey data, the standard method for many species of ungulate. We explored the sensitivity of estimates to model choice based on the common statistical criterion of parsimony.
                  
                
                
                  
                    The two most parsimonious N‐mixture models (i.e. AIC
                    
                      c
                    
                    ) were considerably biased, producing implausibly large and considerably imprecise estimates of abundance. Most of the other models produced estimates of moose abundance that were ecologically realistic and relatively accurate. The accuracy of population estimates produced by N‐mixture models was not overly sensitive to the formulation of models, the scale at which ecological conditions were measured, or the criteria used to define independent detection and by extension sample size.
                  
                
                
                  Our results suggested that parsimony was a poor measure of the predictive accuracy of the population estimates produced with the N‐mixture model. We recommend using a suite of models to generate predictions of abundance instead of the single top‐ranked model. Collecting and processing data from the aerial survey was less expensive and took less time, but data from camera traps provided a broader set of insights into the behaviour of moose and the co‐occurrence of competitors and predators.},
	language = {en},
	number = {5},
	urldate = {2025-03-10},
	journal = {Methods in Ecology and Evolution},
	author = {Koetke, Lisa Jeanne and Hodder, Dexter P. and Johnson, Chris J.},
	month = may,
	year = {2024},
	pages = {900--915},
	file = {Koetke et al. - 2024 - Using camera traps and N‐mixture models to estimate population abundance Model selection really mat.pdf:/Users/julietfleischer/Library/Mobile Documents/iCloud~md~obsidian/Documents/Studium/PDFs/koetke2024/Koetke et al. - 2024 - Using camera traps and N‐mixture models to estimate population abundance Model selection really mat.pdf:application/pdf},
}

@article{iijima2020,
	title = {A {Review} of {Wildlife} {Abundance} {Estimation} {Models}: {Comparison} of {Models} for {Correct} {Application}},
	volume = {45},
	issn = {1343-4152},
	shorttitle = {A {Review} of {Wildlife} {Abundance} {Estimation} {Models}},
	url = {https://bioone.org/journals/mammal-study/volume-45/issue-3/ms2019-0082/A-Review-of-Wildlife-Abundance-Estimation-Models--Comparison-of/10.3106/ms2019-0082.full},
	doi = {10.3106/ms2019-0082},
	abstract = {In this review, the various models to estimate wildlife abundance are organized for pro moting the correct application of them in animal ecology. If individuals of the target wildlife are distin guishable, the capturerecapture (CR) model and the spatially explicit capturerecapture (SECR) model can be applied to the closed population and the JollySeber (JS) model can be applied to the open population. If not, the distance sampling, Nmixture model, random encounter (RE) model, random encounter and staying time (REST) model, and removal sampling can be applied to the closed pop ulation, and the harvestbased model can be applied to the open population. Recent advances in the hierarchical model and the integrated population model (IPM) make it possible to model the abundance and demographic rate of the wildlife by considering the ecological process of the target wildlife and observation process of them and to utilize the various but fragmented data. Then, the formalization of the abundance estimation model as a hierarchical model and the construction of the IPM by considering the available data and biological characteristics of the target species are useful for future research.},
	language = {en},
	number = {3},
	urldate = {2025-03-10},
	journal = {Mammal Study},
	author = {Iijima, Hayato},
	month = jun,
	year = {2020},
	pages = {177},
	file = {Iijima - 2020 - A Review of Wildlife Abundance Estimation Models Comparison of Models for Correct Application.pdf:/Users/julietfleischer/Library/Mobile Documents/iCloud~md~obsidian/Documents/Studium/PDFs/iijima2020/Iijima - 2020 - A Review of Wildlife Abundance Estimation Models Comparison of Models for Correct Application.pdf:application/pdf},
}

@misc{hornung2023,
	title = {Evaluating machine learning models in non-standard settings: {An} overview and new findings},
	shorttitle = {Evaluating machine learning models in non-standard settings},
	url = {http://arxiv.org/abs/2310.15108},
	doi = {10.48550/arXiv.2310.15108},
	abstract = {Estimating the generalization error (GE) of machine learning models is fundamental, with resampling methods being the most common approach. However, in non-standard settings, particularly those where observations are not independently and identically distributed, resampling using simple random data divisions may lead to biased GE estimates. This paper strives to present well-grounded guidelines for GE estimation in various such non-standard settings: clustered data, spatial data, unequal sampling probabilities, concept drift, and hierarchically structured outcomes. Our overview combines well-established methodologies with other existing methods that, to our knowledge, have not been frequently considered in these particular settings. A unifying principle among these techniques is that the test data used in each iteration of the resampling procedure should reflect the new observations to which the model will be applied, while the training data should be representative of the entire data set used to obtain the final model. Beyond providing an overview, we address literature gaps by conducting simulation studies. These studies assess the necessity of using GE-estimation methods tailored to the respective setting. Our findings corroborate the concern that standard resampling methods often yield biased GE estimates in non-standard settings, underscoring the importance of tailored GE estimation.},
	urldate = {2025-03-10},
	publisher = {arXiv},
	author = {Hornung, Roman and Nalenz, Malte and Schneider, Lennart and Bender, Andreas and Bothmann, Ludwig and Bischl, Bernd and Augustin, Thomas and Boulesteix, Anne-Laure},
	month = oct,
	year = {2023},
	note = {arXiv:2310.15108 [stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Applications, Statistics - Computation, Statistics - Machine Learning, Statistics - Methodology},
	file = {Hornung et al. - 2023 - Evaluating machine learning models in non-standard settings An overview and new findings.pdf:/Users/julietfleischer/Library/Mobile Documents/iCloud~md~obsidian/Documents/Studium/PDFs/hornung2023/Hornung et al. - 2023 - Evaluating machine learning models in non-standard settings An overview and new findings.pdf:application/pdf;Snapshot:/Users/julietfleischer/Zotero/storage/PIYLSVZ6/2310.html:text/html},
}

@article{hooker2007,
	title = {Generalized {Functional} {ANOVA} {Diagnostics} for {High}-{Dimensional} {Functions} of {Dependent} {Variables}},
	volume = {16},
	issn = {1061-8600, 1537-2715},
	url = {http://www.tandfonline.com/doi/abs/10.1198/106186007X237892},
	doi = {10.1198/106186007X237892},
	language = {en},
	number = {3},
	urldate = {2025-03-11},
	journal = {Journal of Computational and Graphical Statistics},
	author = {Hooker, Giles},
	month = sep,
	year = {2007},
	keywords = {\#1 fANOVA ML models},
	pages = {709--732},
	file = {Hooker - 2007 - Generalized Functional ANOVA Diagnostics for High-Dimensional Functions of Dependent Variables.pdf:/Users/julietfleischer/Library/Mobile Documents/iCloud~md~obsidian/Documents/Studium/PDFs/hooker2007/Hooker - 2007 - Generalized Functional ANOVA Diagnostics for High-Dimensional Functions of Dependent Variables.pdf:application/pdf},
}

@article{vanravenzwaaij2018,
	title = {A simple introduction to {Markov} {Chain} {Monte}–{Carlo} sampling},
	volume = {25},
	issn = {1069-9384, 1531-5320},
	url = {http://link.springer.com/10.3758/s13423-016-1015-8},
	doi = {10.3758/s13423-016-1015-8},
	abstract = {Markov Chain Monte–Carlo (MCMC) is an increasingly popular method for obtaining information about distributions, especially for estimating posterior distributions in Bayesian inference. This article provides a very basic introduction to MCMC sampling. It describes what MCMC is, and what it can be used for, with simple illustrative examples. Highlighted are some of the benefits and limitations of MCMC sampling, as well as different approaches to circumventing the limitations most likely to trouble cognitive scientists.},
	language = {en},
	number = {1},
	urldate = {2025-03-17},
	journal = {Psychonomic Bulletin \& Review},
	author = {Van Ravenzwaaij, Don and Cassey, Pete and Brown, Scott D.},
	month = feb,
	year = {2018},
	pages = {143--154},
	file = {Van Ravenzwaaij et al. - 2018 - A simple introduction to Markov Chain Monte–Carlo sampling.pdf:/Users/julietfleischer/Library/Mobile Documents/iCloud~md~obsidian/Documents/Studium/PDFs/vanravenzwaaij2018/Van Ravenzwaaij et al. - 2018 - A simple introduction to Markov Chain Monte–Carlo sampling.pdf:application/pdf},
}

@article{harris2024,
	title = {N-mixture models with camera trap imagery produce accurate abundance estimates of ungulates},
	volume = {14},
	issn = {2045-2322},
	url = {https://www.nature.com/articles/s41598-024-83011-4},
	doi = {10.1038/s41598-024-83011-4},
	abstract = {Abstract
            
              Abundance estimates inform ungulate management and recovery efforts. Yet effective and affordable estimation techniques remain absent for most ungulates lacking identifiable marks and inhabiting rugged or highly vegetated terrain. Methods using N-mixture models with camera trap imagery form an appealing solution but remain unvalidated. We assess this method using populations of desert bighorn sheep (DBS;
              Ovis canadensis
              ) in New Mexico, USA, plus bison (
              Bison bison bison
              ) and Texas longhorn cattle (
              Bos taurus taurus
              ) in Oklahoma, USA, by calculating and comparing abundance estimates to censused values. We parsed data by 3 and 7-day intervals, using images filtered or unfiltered, and collected with motion detection or timed camera settings. We employed priors informed by subject matter experts (SME) and calculated using detection-nondetection methods. Abundance estimates from filtered images captured by motion detection in 3-day intervals included the censused value across all seasons for adult DBS, rams and ewes, indicating “best practices”. This “best practices” method also captured censused values for population estimates of bison (detection-nondetection) and cattle with both priors. Our assessment validates the use of N-mixture with camera trap imagery, while presenting sampling approaches, data handling procedures and model calibration to estimate wildlife population sizes more appropriately and accurately.},
	language = {en},
	number = {1},
	urldate = {2025-03-17},
	journal = {Scientific Reports},
	author = {Harris, Grant M. and Stewart, David R. and Butler, Matthew J. and Rominger, Eric M. and Ruhl, Caitlin Q. and McDonald, Daniel T. and Schmidt, Paige M.},
	month = dec,
	year = {2024},
	pages = {31421},
	file = {Harris et al. - 2024 - N-mixture models with camera trap imagery produce accurate abundance estimates of ungulates.pdf:/Users/julietfleischer/Library/Mobile Documents/iCloud~md~obsidian/Documents/Studium/PDFs/harris2024/Harris et al. - 2024 - N-mixture models with camera trap imagery produce accurate abundance estimates of ungulates.pdf:application/pdf},
}

@article{harris2024a,
	title = {N-mixture models with camera trap imagery produce accurate abundance estimates of ungulates},
	volume = {14},
	issn = {2045-2322},
	url = {https://www.nature.com/articles/s41598-024-83011-4},
	doi = {10.1038/s41598-024-83011-4},
	abstract = {Abstract
            
              Abundance estimates inform ungulate management and recovery efforts. Yet effective and affordable estimation techniques remain absent for most ungulates lacking identifiable marks and inhabiting rugged or highly vegetated terrain. Methods using N-mixture models with camera trap imagery form an appealing solution but remain unvalidated. We assess this method using populations of desert bighorn sheep (DBS;
              Ovis canadensis
              ) in New Mexico, USA, plus bison (
              Bison bison bison
              ) and Texas longhorn cattle (
              Bos taurus taurus
              ) in Oklahoma, USA, by calculating and comparing abundance estimates to censused values. We parsed data by 3 and 7-day intervals, using images filtered or unfiltered, and collected with motion detection or timed camera settings. We employed priors informed by subject matter experts (SME) and calculated using detection-nondetection methods. Abundance estimates from filtered images captured by motion detection in 3-day intervals included the censused value across all seasons for adult DBS, rams and ewes, indicating “best practices”. This “best practices” method also captured censused values for population estimates of bison (detection-nondetection) and cattle with both priors. Our assessment validates the use of N-mixture with camera trap imagery, while presenting sampling approaches, data handling procedures and model calibration to estimate wildlife population sizes more appropriately and accurately.},
	language = {en},
	number = {1},
	urldate = {2025-03-17},
	journal = {Scientific Reports},
	author = {Harris, Grant M. and Stewart, David R. and Butler, Matthew J. and Rominger, Eric M. and Ruhl, Caitlin Q. and McDonald, Daniel T. and Schmidt, Paige M.},
	month = dec,
	year = {2024},
	pages = {31421},
	file = {Harris et al. - 2024 - N-mixture models with camera trap imagery produce accurate abundance estimates of ungulates.pdf:/Users/julietfleischer/Library/Mobile Documents/iCloud~md~obsidian/Documents/Studium/PDFs/harris2024a/Harris et al. - 2024 - N-mixture models with camera trap imagery produce accurate abundance estimates of ungulates.pdf:application/pdf},
}

@article{acemoglu,
	title = {Can we {Have} {Pro}-{Worker} {AI}?},
	language = {en},
	author = {Acemoglu, Daron and Autor, David and Johnson, Simon},
	file = {Acemoglu et al. - Can we Have Pro-Worker AI.pdf:/Users/julietfleischer/Library/Mobile Documents/iCloud~md~obsidian/Documents/Studium/PDFs/acemoglu/Acemoglu et al. - Can we Have Pro-Worker AI.pdf:application/pdf},
}

@book{oecd2024,
	title = {{OECD} {Artificial} {Intelligence} {Review} of {Germany}},
	isbn = {978-92-64-88673-5 978-92-64-40455-7 978-92-64-62650-8},
	url = {https://www.oecd.org/en/publications/oecd-artificial-intelligence-review-of-germany_609808d6-en.html},
	language = {en},
	urldate = {2025-03-22},
	publisher = {OECD},
	author = {{OECD}},
	month = jun,
	year = {2024},
	doi = {10.1787/609808d6-en},
	file = {OECD - 2024 - OECD Artificial Intelligence Review of Germany.pdf:/Users/julietfleischer/Library/Mobile Documents/iCloud~md~obsidian/Documents/Studium/PDFs/oecd2024/OECD - 2024 - OECD Artificial Intelligence Review of Germany.pdf:application/pdf},
}

@article{cazzaniga,
	title = {Gen-{AI}: {Artificial} {Intelligence} and the {Future} of {Work}},
	abstract = {Artificial intelligence (AI) has the potential to reshape the global economy, especially in the realm of labor markets. Advanced economies will experience the benefits and pitfalls of AI sooner than emerging market and developing economies, largely because their employment structure is focused on cognitiveintensive roles. There are some consistent patterns concerning AI exposure: women and college-educated individuals are more exposed but also better poised to reap AI benefits, and older workers are potentially less able to adapt to the new technology. Labor income inequality may increase if the complementarity between AI and high-income workers is strong, and capital returns will increase wealth inequality. However, if productivity gains are sufficiently large, income levels could surge for most workers. In this evolving landscape, advanced economies and more developed emerging market economies need to focus on upgrading regulatory frameworks and supporting labor reallocation while safeguarding those adversely affected. Emerging market and developing economies should prioritize the development of digital infrastructure and digital skills.},
	language = {en},
	author = {Cazzaniga, Prepared Mauro and Jaumotte, Florence and Li, Longji and Melina, Giovanni and Panton, Augustus J and Pizzinelli, Carlo and Tavares, Marina M},
	file = {Cazzaniga et al. - Gen-AI Artificial Intelligence and the Future of Work.pdf:/Users/julietfleischer/Library/Mobile Documents/iCloud~md~obsidian/Documents/Studium/PDFs/cazzaniga/Cazzaniga et al. - Gen-AI Artificial Intelligence and the Future of Work.pdf:application/pdf},
}

@article{wesner,
	title = {Choosing priors in {Bayesian} ecological models by simulating from the prior predictive distribution},
	language = {en},
	author = {Wesner, Jeﬀ S and Pomeranz, Justin P F},
	file = {Wesner und Pomeranz - Choosing priors in Bayesian ecological models by simulating from the prior predictive distribution.pdf:/Users/julietfleischer/Library/Mobile Documents/iCloud~md~obsidian/Documents/Studium/PDFs/wesner/Wesner und Pomeranz - Choosing priors in Bayesian ecological models by simulating from the prior predictive distribution.pdf:application/pdf},
}

@article{kellner2023,
	title = {The unmarked {R} package: {Twelve} years of advances in occurrence and abundance modelling in ecology},
	volume = {14},
	issn = {2041-210X, 2041-210X},
	shorttitle = {The unmarked {R} package},
	url = {https://besjournals.onlinelibrary.wiley.com/doi/10.1111/2041-210X.14123},
	doi = {10.1111/2041-210X.14123},
	abstract = {Abstract
            
              
                
                  Species distribution models (SDMs) are widely applied to understand the processes governing spatial and temporal variation in species abundance and distribution but often do not account for measurement errors such as false negatives and false positives.
                
                
                  
                    We describe
                    unmarked
                    , a package for the freely available and open‐source R software that provides a complete workflow for modelling species distribution and abundance while explicitly accounting for measurement errors. Here we focus on recent advances in
                    unmarked
                    functionality to support multi‐species, multi‐state, and multi‐season data, as well as support for fitting models with random effects.
                  
                
                
                  
                    For illustration, we present an analysis of Acadian Flycatcher
                    Empidonax virescens
                    abundance on Roanoke River National Wildlife Refuge, North Carolina, USA, over 18 years. We found that Acadian Flycatcher abundance was initially greater in hardwood plantation habitat relative to bottomland hardwood forest along river levees but that abundance declined over time in both habitats.
                  
                
                
                  
                    We plan for
                    unmarked
                    development to keep pace with advances in hierarchical modelling in ecology, including better handling of continuous‐time data from camera trap and automated recording units and integrated models for multiple data streams.},
	language = {en},
	number = {6},
	urldate = {2025-03-25},
	journal = {Methods in Ecology and Evolution},
	author = {Kellner, Kenneth F. and Smith, Adam D. and Royle, J. Andrew and Kéry, Marc and Belant, Jerrold L. and Chandler, Richard B.},
	month = jun,
	year = {2023},
	pages = {1408--1415},
	file = {Kellner et al. - 2023 - The unmarked R package Twelve years of advances in occurrence and abundance modelling in ecology.pdf:/Users/julietfleischer/Library/Mobile Documents/iCloud~md~obsidian/Documents/Studium/PDFs/kellner2023/Kellner et al. - 2023 - The unmarked R package Twelve years of advances in occurrence and abundance modelling in ecology.pdf:application/pdf},
}

@article{royle2004,
	title = {\textit{{N}} ‐{Mixture} {Models} for {Estimating} {Population} {Size} from {Spatially} {Replicated} {Counts}},
	volume = {60},
	copyright = {http://onlinelibrary.wiley.com/termsAndConditions\#vor},
	issn = {0006-341X, 1541-0420},
	url = {https://academic.oup.com/biometrics/article/60/1/108-115/7289296},
	doi = {10.1111/j.0006-341X.2004.00142.x},
	abstract = {Spatial replication is a common theme in count surveys of animals. Such surveys often generate sparse count data from which it is difficult to estimate population size while formally accounting for detection probability. In this article, I describe a class of models (N-mixture models) which allow for estimation of population size from such data. The key idea is to view site-specific population sizes, N, as independent random variables distributed according to some mixing distribution (e.g., Poisson). Prior parameters are estimated from the marginal likelihood of the data, having integrated over the prior distribution for N. Carroll and Lombard (1985, Journal of American Statistical Association 80, 423-426) proposed a class of estimators based on mixing over a prior distribution for detection probability. Their estimator can be applied in limited settings, but is sensitive to prior parameter values that are fixed a priori. Spatial replication provides additional information regarding the parameters of the prior distribution on N that is exploited by the N-mixture models and which leads to reasonable estimates of abundance from sparse data. A simulation study demonstrates superior operating characteristics (bias, confidence interval coverage) of the N-mixture estimator compared to the Caroll and Lombard estimator. Both estimators are applied to point count data on six species of birds illustrating the sensitivity to choice of prior on p and substantially different estimates of abundance as a consequence.},
	language = {en},
	number = {1},
	urldate = {2025-03-29},
	journal = {Biometrics},
	author = {Royle, J. Andrew},
	month = mar,
	year = {2004},
	pages = {108--115},
	file = {Royle - 2004 - N ‐Mixture Models for Estimating Population Size from Spatially Replicated Counts.pdf:/Users/julietfleischer/Library/Mobile Documents/iCloud~md~obsidian/Documents/Studium/PDFs/Royle - 2004 - N ‐Mixture Models for Estimating Population Size from Spatially Replicated Counts.pdf:application/pdf},
}

@article{dennis2015,
	title = {Computational aspects of {N}-mixture models},
	volume = {71},
	issn = {1541-0420},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/biom.12246},
	doi = {10.1111/biom.12246},
	abstract = {The N-mixture model is widely used to estimate the abundance of a population in the presence of unknown detection probability from only a set of counts subject to spatial and temporal replication (Royle, 2004, Biometrics 60, 105–115). We explain and exploit the equivalence of N-mixture and multivariate Poisson and negative-binomial models, which provides powerful new approaches for fitting these models. We show that particularly when detection probability and the number of sampling occasions are small, infinite estimates of abundance can arise. We propose a sample covariance as a diagnostic for this event, and demonstrate its good performance in the Poisson case. Infinite estimates may be missed in practice, due to numerical optimization procedures terminating at arbitrarily large values. It is shown that the use of a bound, K, for an infinite summation in the N-mixture likelihood can result in underestimation of abundance, so that default values of K in computer packages should be avoided. Instead we propose a simple automatic way to choose K. The methods are illustrated by analysis of data on Hermann's tortoise Testudo hermanni.},
	language = {en},
	number = {1},
	urldate = {2025-04-01},
	journal = {Biometrics},
	author = {Dennis, Emily B. and Morgan, Byron J.T. and Ridout, Martin S.},
	year = {2015},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/biom.12246},
	keywords = {Abundance estimation, Method of moments, Multivariate negative binomial, Multivariate Poisson, Optimal design, Sampling, Temporal replication},
	pages = {237--246},
	file = {Dennis et al. - 2015 - Computational aspects of N-mixture models.pdf:/Users/julietfleischer/Library/Mobile Documents/iCloud~md~obsidian/Documents/Studium/PDFs/Dennis et al. - 2015 - Computational aspects of N-mixture models.pdf:application/pdf;Snapshot:/Users/julietfleischer/Zotero/storage/8GFJ7YSB/biom.html:text/html},
}

@article{dennis2015a,
	title = {Computational {Aspects} of {N}-{Mixture} {Models}},
	volume = {71},
	copyright = {http://creativecommons.org/licenses/by/4.0/},
	issn = {0006-341X, 1541-0420},
	url = {https://academic.oup.com/biometrics/article/71/1/237-246/7511534},
	doi = {10.1111/biom.12246},
	abstract = {The N-mixture model is widely used to estimate the abundance of a population in the presence of unknown detection probability from only a set of counts subject to spatial and temporal replication (Royle, 2004, Biometrics 60, 105–115). We explain and exploit the equivalence of N-mixture and multivariate Poisson and negative-binomial models, which provides powerful new approaches for ﬁtting these models. We show that particularly when detection probability and the number of sampling occasions are small, inﬁnite estimates of abundance can arise. We propose a sample covariance as a diagnostic for this event, and demonstrate its good performance in the Poisson case. Inﬁnite estimates may be missed in practice, due to numerical optimization procedures terminating at arbitrarily large values. It is shown that the use of a bound, K, for an inﬁnite summation in the N-mixture likelihood can result in underestimation of abundance, so that default values of K in computer packages should be avoided. Instead we propose a simple automatic way to choose K. The methods are illustrated by analysis of data on Hermann’s tortoise Testudo hermanni.},
	language = {en},
	number = {1},
	urldate = {2025-04-01},
	journal = {Biometrics},
	author = {Dennis, Emily B. and Morgan, Byron J.T. and Ridout, Martin S.},
	month = mar,
	year = {2015},
	pages = {237--246},
	file = {Dennis et al. - 2015 - Computational Aspects of N-Mixture Models 1.pdf:/Users/julietfleischer/Library/Mobile Documents/iCloud~md~obsidian/Documents/Studium/PDFs/Dennis et al. - 2015 - Computational Aspects of N-Mixture Models 1.pdf:application/pdf},
}

@article{link2018,
	title = {On the robustness of {N}‐mixture models},
	volume = {99},
	issn = {0012-9658, 1939-9170},
	url = {https://esajournals.onlinelibrary.wiley.com/doi/10.1002/ecy.2362},
	doi = {10.1002/ecy.2362},
	abstract = {N-mixture models provide an appealing alternative to mark–recapture models, in that they allow for estimation of detection probability and population size from count data, without requiring that individual animals be identified. There is, however, a cost to using the N-mixture models: inference is very sensitive to the model’s assumptions. We consider the effects of three violations of assumptions that might reasonably be expected in practice: double counting, unmodeled variation in population size over time, and unmodeled variation in detection probability over time. These three examples show that small violations of assumptions can lead to large biases in estimation. The violations of assumptions we consider are not only small qualitatively, but are also small in the sense that they are unlikely to be detected using goodness-of-fit tests. In cases where reliable estimates of population size are needed, we encourage investigators to allocate resources to acquiring additional data, such as recaptures of marked individuals, for estimation of detection probabilities.},
	language = {en},
	number = {7},
	urldate = {2025-04-01},
	journal = {Ecology},
	author = {Link, William A. and Schofield, Matthew R. and Barker, Richard J. and Sauer, John R.},
	month = jul,
	year = {2018},
	pages = {1547--1551},
	file = {Link et al. - 2018 - On the robustness of N‐mixture models.pdf:/Users/julietfleischer/Library/Mobile Documents/iCloud~md~obsidian/Documents/Studium/PDFs/Link et al. - 2018 - On the robustness of N‐mixture models.pdf:application/pdf},
}

@article{veech2016,
	title = {Intrinsic heterogeneity in detection probability and its effect on \textit{ {\textless}span style="font-variant:small-caps;"{\textgreater}{N}{\textless}/span{\textgreater} } ‐mixture models},
	volume = {7},
	copyright = {http://onlinelibrary.wiley.com/termsAndConditions\#vor},
	issn = {2041-210X, 2041-210X},
	shorttitle = {Intrinsic heterogeneity in detection probability and its effect on \textit{ {\textless}span style="font-variant}},
	url = {https://besjournals.onlinelibrary.wiley.com/doi/10.1111/2041-210X.12566},
	doi = {10.1111/2041-210X.12566},
	abstract = {Summary
            
              
                
                  
                    Estimating the abundance or density of animal populations is often a fundamental task in ecological research and species conservation.
                    N
                    ‐mixture models are widely used to estimate the detection probability of individual organisms that thusly leads to more accurate estimates of a species' true abundance. However, individuals likely vary in their probabilities of being detected. During a survey, heterogeneity (variation) in individual detection probability might arise due to conditions of the surveying process; this form of
                    extrinsic
                    heterogeneity can be accounted for by the use of appropriate covariates in the models. In contrast,
                    intrinsic
                    heterogeneity in the detection probabilities of individuals arises when intraspecific variation in behaviour results in individual organisms differing in their latent (inherent) probabilities of being detected. This form of heterogeneity is not tractable by the use of covariates and its possible effects on model performance have not been investigated to date.
                  
                
                
                  
                    Using simulated data, we evaluated the performance of Poisson, negative binomial and zero‐inflated Poisson versions of
                    N
                    ‐mixture models under the conditions of intrinsic heterogeneity in individual detection probability.
                  
                
                
                  
                    Most versions of
                    N
                    ‐mixture models performed well in estimating abundance as indicated by relatively low root‐mean‐square‐error values (
                    RMSE
                     {\textless} 1). Error distributions indicated a lack of substantial bias and relatively high precision and accuracy when simulated detection probabilities of individuals were high ({\textgreater}0·5) and heterogeneity was random. Otherwise, with structured heterogeneity (particularly positive density dependence) and low detection probabilities ({\textless}0·5), model performance was reduced (
                    RMSE
                     {\textgreater} 2). The poorest performing model was the zero‐inflated Poisson version of
                    N
                    ‐mixture model applied to data from low survey effort.
                  
                
                
                  
                    Our results suggest that
                    N
                    ‐mixture models are robust to intrinsic heterogeneity in individual detection probabilities except when the detection probabilities are low. When model‐estimated detection probabilities are low ({\textless}0·5), model users should be aware that estimates of abundance could be erroneous if there was non‐random intrinsic heterogeneity in individual detection probabilities during the surveys. Remedying this situation might require redesigning the basic survey protocol such that it does not rely on behavioural traits (as cues to detection) that are intrinsically variable among individuals.},
	language = {en},
	number = {9},
	urldate = {2025-04-03},
	journal = {Methods in Ecology and Evolution},
	author = {Veech, Joseph A. and Ott, James R. and Troy, Jeff R.},
	editor = {Murrell, David},
	month = sep,
	year = {2016},
	pages = {1019--1028},
	file = {Veech et al. - 2016 - Intrinsic heterogeneity in detection probability and its effect on  span style=font-variantsma.pdf:/Users/julietfleischer/Library/Mobile Documents/iCloud~md~obsidian/Documents/Studium/PDFs/Veech et al. - 2016 - Intrinsic heterogeneity in detection probability and its effect on  span style=font-variantsma.pdf:application/pdf},
}

@article{knape2015,
	title = {Estimates from non‐replicated population surveys rely on critical assumptions},
	volume = {6},
	copyright = {http://onlinelibrary.wiley.com/termsAndConditions\#vor},
	issn = {2041-210X, 2041-210X},
	url = {https://besjournals.onlinelibrary.wiley.com/doi/10.1111/2041-210X.12329},
	doi = {10.1111/2041-210X.12329},
	abstract = {Summary
            
              
                
                  
                    N‐mixture and occupancy models are often used to account for non‐detections in population surveys. The consensus has been that the methods require data that are replicated in space, as well as within a short period of time while the population at each site remains closed, in order for parameters such as detection probabilities and expected abundances to be identifiable. The requirement of replication prohibits the use of N‐mixture and occupancy models for many surveys in practice. Recently, some studies have argued that N‐mixture and occupancy models for surveys with only one visit at each site are identifiable when covariates for both detection probabilities and expected abundances, with at least one distinct covariate for each, are available (
                    Journal of Plant Ecology
                    , 5, 2012, 22;
                    Environmetrics
                    , 23, 2012, 197).
                  
                
                
                  We investigate the reasons for why detection probabilities have traditionally been considered unestimable from non‐replicated counts and how the new methods sidestep these issues. We further use simulations to investigate properties of the new estimators.
                
                
                  We show that detection probabilities of the single‐visit models with covariates are non‐identifiable and that absolute abundances cannot be estimated when particular link functions are employed (log links for both expected abundance and detection probability). Further, assumptions about the range within which detection probabilities vary are necessary to render estimability. The possibility of estimating abundance from single‐visit surveys therefore implicitly hinges on knowledge about the link functions. Simulations show that estimates of abundance can be highly variable and sensitive to the choice of link function. We further show how a reduced parameterization of an N‐mixture model for surveys repeated over time, without replication under closure but where detection probabilities are constant over time, corresponds to a Poisson model.
                
                
                  Non‐robust estimation can result in misleading conclusions about population abundance. When estimating abundance from count data that are not replicated, it is therefore important to be aware of how imprecise estimators may be and how sensitive they are to model assumptions.},
	language = {en},
	number = {3},
	urldate = {2025-04-03},
	journal = {Methods in Ecology and Evolution},
	author = {Knape, Jonas and Korner‐Nievergelt, Fränzi},
	editor = {Yoccoz, Nigel},
	month = mar,
	year = {2015},
	pages = {298--306},
	file = {Knape und Korner‐Nievergelt - 2015 - Estimates from non‐replicated population surveys rely on critical assumptions.pdf:/Users/julietfleischer/Library/Mobile Documents/iCloud~md~obsidian/Documents/Studium/PDFs/Knape und Korner‐Nievergelt - 2015 - Estimates from non‐replicated population surveys rely on critical assumptions.pdf:application/pdf},
}

@article{yamaura2016,
	title = {Study of biological communities subject to imperfect detection: bias and precision of community \textit{{N}} ‐mixture abundance models in small‐sample situations},
	volume = {31},
	copyright = {http://creativecommons.org/licenses/by/4.0/},
	issn = {0912-3814, 1440-1703},
	shorttitle = {Study of biological communities subject to imperfect detection},
	url = {https://esj-journals.onlinelibrary.wiley.com/doi/10.1007/s11284-016-1340-4},
	doi = {10.1007/s11284-016-1340-4},
	abstract = {Community N-mixture abundance models for replicated counts provide a powerful and novel framework for drawing inferences related to species abundance within communities subject to imperfect detection. To assess the performance of these models, and to compare them to related community occupancy models in situations with marginal information, we used simulation to examine the eﬀects of mean abundance ðk: 0.1, 0.5, 1, 5), detection probability ðp: 0.1, 0.2, 0.5), and number of sampling sites (nsite: 10, 20, 40) and visits (nvisit: 2, 3, 4) on the bias and precision of species-level parameters (mean abundance and covariate eﬀect) and a community-level parameter (species richness). Bias and imprecision of estimates decreased when any of the four variables ðk, p, nsite, nvisit) increased. Detection probability p was most important for the estimates of mean abundance, while k was most inﬂuential for covariate eﬀect and species richness estimates. For all parameters, increasing nsite was more beneﬁcial than increasing nvisit.},
	language = {en},
	number = {3},
	urldate = {2025-04-03},
	journal = {Ecological Research},
	author = {Yamaura, Yuichi and Kéry, Marc and Andrew Royle, J.},
	month = may,
	year = {2016},
	pages = {289--305},
	file = {Yamaura et al. - 2016 - Study of biological communities subject to imperfect detection bias and precision of community N.pdf:/Users/julietfleischer/Library/Mobile Documents/iCloud~md~obsidian/Documents/Studium/PDFs/Yamaura et al. - 2016 - Study of biological communities subject to imperfect detection bias and precision of community N.pdf:application/pdf},
}

@article{knape2018,
	title = {Sensitivity of binomial {N}‐mixture models to overdispersion: {The} importance of assessing model fit},
	volume = {9},
	issn = {2041-210X, 2041-210X},
	shorttitle = {Sensitivity of binomial {N}‐mixture models to overdispersion},
	url = {https://besjournals.onlinelibrary.wiley.com/doi/10.1111/2041-210X.13062},
	doi = {10.1111/2041-210X.13062},
	abstract = {Abstract
            
              
                
                  Binomial N‐mixture models are commonly applied to analyse population survey data. By estimating detection probabilities, N‐mixture models aim at extracting information about abundances in terms of absolute and not just relative numbers. This separation of detection probability and abundance relies on parametric assumptions about the distribution of individuals among sites and of detections of individuals among repeat visits to sites. Current methods for checking assumptions are limited, and their computational complexity has hindered evaluations of their performance.
                
                
                  We use simulations and a case study to assess the sensitivity of binomial N‐mixture models to overdispersion in abundance and in detection, develop computationally efficient graphical goodness of fit checks to detect it, and evaluate the ability of the checks to identify overdispersion.
                
                
                  The simulations show that if the parametric assumptions are not exact the bias in estimated abundances can be severe: underestimation if there is overdispersion in abundance relative to the fitted model and overestimation if there is overdispersion in detection. Our goodness‐of‐fit checks performed well in detecting lack of fit when the abundance distribution was overdispersed, but struggled to detect lack of fit when detections were overdispersed. We show that the inability to detect lack of fit due to overdispersed detection is caused by a fundamental similarity between N‐mixture models with beta‐binomial detections and N‐mixture models with negative binomial abundances.
                
                
                  
                    The strong biases that can occur in the binomial N‐mixture model when the distribution of individuals among sites, or the detection model, is mis‐specified implies that checking goodness of fit is essential for sound inference about abundance. To check the assumptions we provide computationally efficient goodness of fit checks that are available in an R‐package
                    nmixgof
                    . However, even when a binomial N‐mixture model appears to fit the data well, estimates are not robust in the presence of overdispersion. We show that problems can occur even when estimated detection probabilities are high, and that previously reported problems with negative binomial models cannot always be diagnosed by checking the sensitivity of abundance estimates to numerical cutoff values used in likelihood computations.},
	language = {en},
	number = {10},
	urldate = {2025-04-04},
	journal = {Methods in Ecology and Evolution},
	author = {Knape, Jonas and Arlt, Debora and Barraquand, Frédéric and Berg, Åke and Chevalier, Mathieu and Pärt, Tomas and Ruete, Alejandro and Żmihorski, Michał},
	editor = {Isaac, Nick},
	month = oct,
	year = {2018},
	pages = {2102--2114},
	file = {Knape et al. - 2018 - Sensitivity of binomial N‐mixture models to overdispersion The importance of assessing model fit.pdf:/Users/julietfleischer/Library/Mobile Documents/iCloud~md~obsidian/Documents/Studium/PDFs/Knape et al. - 2018 - Sensitivity of binomial N‐mixture models to overdispersion The importance of assessing model fit.pdf:application/pdf},
}

@article{duarte2018,
	title = {Fitting {N}-mixture models to count data with unmodeled heterogeneity: {Bias}, diagnostics, and alternative approaches},
	volume = {374},
	issn = {03043800},
	shorttitle = {Fitting {N}-mixture models to count data with unmodeled heterogeneity},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0304380018300607},
	doi = {10.1016/j.ecolmodel.2018.02.007},
	abstract = {Monitoring animal populations is central to wildlife and ﬁsheries management, and the use of N-mixture models toward these eﬀorts has markedly increased in recent years. Nevertheless, relatively little work has evaluated estimator performance when basic assumptions are violated. Moreover, diagnostics to identify when bias in parameter estimates from N-mixture models is likely is largely unexplored. We simulated count data sets using 837 combinations of detection probability, number of sample units, number of survey occasions, and type and extent of heterogeneity in abundance or detectability. We ﬁt Poisson N-mixture models to these data, quantiﬁed the bias associated with each combination, and evaluated if the parametric bootstrap goodness-of-ﬁt (GOF) test can be used to indicate bias in parameter estimates. We also explored if assumption violations can be diagnosed prior to ﬁtting N-mixture models. In doing so, we propose a new model diagnostic, which we term the quasicoeﬃcient of variation (QCV). N-mixture models performed well when assumptions were met and detection probabilities were moderate (i.e., ≥0.3), and the performance of the estimator improved with increasing survey occasions and sample units. However, the magnitude of bias in estimated mean abundance with even slight amounts of unmodeled heterogeneity was substantial. The parametric bootstrap GOF test did not perform well as a diagnostic for bias in parameter estimates when detectability and sample sizes were low. The results indicate the QCV is useful to diagnose potential bias and that potential bias associated with unidirectional trends in abundance or detectability can be diagnosed using Poisson regression. This study represents the most thorough assessment to date of assumption violations and diagnostics when ﬁtting N-mixture models using the most commonly implemented error distribution. Unbiased estimates of population state variables are needed to properly inform management decision making. Therefore, we also discuss alternative approaches to yield unbiased estimates of population state variables using similar data types, and we stress that there is no substitute for an eﬀective sample design that is grounded upon well-deﬁned management objectives.},
	language = {en},
	urldate = {2025-04-04},
	journal = {Ecological Modelling},
	author = {Duarte, Adam and Adams, Michael J. and Peterson, James T.},
	month = apr,
	year = {2018},
	pages = {51--59},
	file = {Duarte et al. - 2018 - Fitting N-mixture models to count data with unmodeled heterogeneity Bias, diagnostics, and alternat.pdf:/Users/julietfleischer/Library/Mobile Documents/iCloud~md~obsidian/Documents/Studium/PDFs/Duarte et al. - 2018 - Fitting N-mixture models to count data with unmodeled heterogeneity Bias, diagnostics, and alternat.pdf:application/pdf},
}

@article{martin2011,
	title = {Accounting for non‐independent detection when estimating abundance of organisms with a {Bayesian} approach},
	volume = {2},
	copyright = {http://onlinelibrary.wiley.com/termsAndConditions\#vor},
	issn = {2041-210X, 2041-210X},
	url = {https://besjournals.onlinelibrary.wiley.com/doi/10.1111/j.2041-210X.2011.00113.x},
	doi = {10.1111/j.2041-210X.2011.00113.x},
	abstract = {Summary
            
              1.
               Binomial mixture models use repeated count data to estimate abundance. They are becoming increasingly popular because they provide a simple and cost‐effective way to account for imperfect detection. However, these models assume that individuals are detected independently of each other. This assumption may often be violated in the field. For instance, manatees (
              Trichechus manatus latirostris
              ) may surface in turbid water (i.e. become available for detection during aerial surveys) in a correlated manner (i.e. in groups). However, correlated behaviour, affecting the non‐independence of individual detections, may also be relevant in other systems (e.g. correlated patterns of singing in birds and amphibians).
            
            
              2.
               We extend binomial mixture models to account for correlated behaviour and therefore to account for non‐independent detection of individuals. We simulated correlated behaviour using beta‐binomial random variables. Our approach can be used to simultaneously estimate abundance, detection probability and a correlation parameter.
            
            
              3.
               Fitting binomial mixture models to data that followed a beta‐binomial distribution resulted in an overestimation of abundance even for moderate levels of correlation. In contrast, the beta‐binomial mixture model performed considerably better in our simulation scenarios. We also present a goodness‐of‐fit procedure to evaluate the fit of beta‐binomial mixture models.
            
            
              4.
               We illustrate our approach by fitting both binomial and beta‐binomial mixture models to aerial survey data of manatees in Florida. We found that the binomial mixture model did not fit the data, whereas there was no evidence of lack of fit for the beta‐binomial mixture model. This example helps illustrate the importance of using simulations and assessing goodness‐of‐fit when analysing ecological data with N‐mixture models. Indeed, both the simulations and the goodness‐of‐fit procedure highlighted the limitations of the standard binomial mixture model for aerial manatee surveys.
            
            
              5.
               Overestimation of abundance by binomial mixture models owing to non‐independent detections is problematic for ecological studies, but also for conservation. For example, in the case of endangered species, it could lead to inappropriate management decisions, such as downlisting. These issues will be increasingly relevant as more ecologists apply flexible N‐mixture models to ecological data.},
	language = {en},
	number = {6},
	urldate = {2025-04-04},
	journal = {Methods in Ecology and Evolution},
	author = {Martin, Julien and Royle, J. Andrew and Mackenzie, Darryl I. and Edwards, Holly H. and Kéry, Marc and Gardner, Beth},
	month = dec,
	year = {2011},
	pages = {595--601},
	file = {Martin et al. - 2011 - Accounting for non‐independent detection when estimating abundance of organisms with a Bayesian appr.pdf:/Users/julietfleischer/Library/Mobile Documents/iCloud~md~obsidian/Documents/Studium/PDFs/Martin et al. - 2011 - Accounting for non‐independent detection when estimating abundance of organisms with a Bayesian appr.pdf:application/pdf},
}

@article{barker2018,
	title = {On the {Reliability} of {N}-mixture {Models} for {Count} {Data}},
	volume = {74},
	copyright = {https://academic.oup.com/journals/pages/open\_access/funder\_policies/chorus/standard\_publication\_model},
	issn = {0006-341X, 1541-0420},
	url = {https://academic.oup.com/biometrics/article/74/1/369-377/7521438},
	doi = {10.1111/biom.12734},
	abstract = {N-mixture models describe count data replicated in time and across sites in terms of abundance N and detectability p. They are popular because they allow inference about N while controlling for factors that inﬂuence p without the need for marking animals. Using a capture–recapture perspective, we show that the loss of information that results from not marking animals is critical, making reliable statistical modeling of N and p problematic using just count data. One cannot reliably ﬁt a model in which the detection probabilities are distinct among repeat visits as this model is overspeciﬁed. This makes uncontrolled variation in p problematic. By counter example, we show that even if p is constant after adjusting for covariate eﬀects (the “constant p” assumption) scientiﬁcally plausible alternative models in which N (or its expectation) is non-identiﬁable or does not even exist as a parameter, lead to data that are practically indistinguishable from data generated under an N-mixture model. This is particularly the case for sparse data as is commonly seen in applications. We conclude that under the constant p assumption reliable inference is only possible for relative abundance in the absence of questionable and/or untestable assumptions or with better quality data than seen in typical applications. Relative abundance models for counts can be readily ﬁtted using Poisson regression in standard software such as R and are suﬃciently ﬂexible to allow controlling for p through the use covariates while simultaneously modeling variation in relative abundance. If users require estimates of absolute abundance, they should collect auxiliary data that help with estimation of p.},
	language = {en},
	number = {1},
	urldate = {2025-04-04},
	journal = {Biometrics},
	author = {Barker, Richard J. and Schofield, Matthew R. and Link, William A. and Sauer, John R.},
	month = mar,
	year = {2018},
	pages = {369--377},
	file = {Barker et al. - 2018 - On the Reliability of N-mixture Models for Count Data.pdf:/Users/julietfleischer/Library/Mobile Documents/iCloud~md~obsidian/Documents/Studium/PDFs/Barker et al. - 2018 - On the Reliability of N-mixture Models for Count Data.pdf:application/pdf},
}

@article{tang2024,
	title = {Predicting systemic financial risk with interpretable machine learning},
	volume = {71},
	issn = {10629408},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1062940824000123},
	doi = {10.1016/j.najef.2024.102088},
	abstract = {Predicting systemic financial risk is essential for understanding the financial system’s stability and early warning of financial crises. In this research, we use the financial stress index to measure systemic financial risk. We construct the stress index for five financial submarkets and composite stress index, employ the Markov regime switching model to identify the systemic financial risk stress state. On this basis, we use interpretable machine learning models to forecast systemic financial risk, analyze and compare the results of the intrinsic interpretable machine learning models and the post-hoc explainable methods. The results indicate that systemic financial risk can be effectively predicted using both the submarket stress index and the feature variables, with the submarket stress index as the independent variable providing relatively higher accuracy. There is a linearly positive relationship between the stress index of each submarket and systemic financial risk, with financial stress in the stock and money markets having the greatest impact on systemic financial risk. For each feature variable, stock–bond correlation coefficient, stock valuation risk, the maximum cumulative loss of the SSE Composite Index (SSE CMAX), and loan-deposit ratio have strong predictive power. Our research can provide reference for government to construct prediction model and indicator monitoring platform of systemic financial crisis.},
	language = {en},
	urldate = {2025-04-14},
	journal = {The North American Journal of Economics and Finance},
	author = {Tang, Pan and Tang, Tiantian and Lu, Chennuo},
	month = mar,
	year = {2024},
	pages = {102088},
	file = {Tang et al. - 2024 - Predicting systemic financial risk with interpretable machine learning.pdf:/Users/julietfleischer/Library/Mobile Documents/iCloud~md~obsidian/Documents/Studium/PDFs/Tang et al. - 2024 - Predicting systemic financial risk with interpretable machine learning.pdf:application/pdf},
}

@article{hu2025,
	title = {Interpretable {Machine} {Learning} {Based} on {Functional} {ANOVA} {Framework}: {Algorithms} and {Comparisons}},
	volume = {41},
	issn = {1524-1904, 1526-4025},
	shorttitle = {Interpretable {Machine} {Learning} {Based} on {Functional} {ANOVA} {Framework}},
	url = {https://onlinelibrary.wiley.com/doi/10.1002/asmb.2916},
	doi = {10.1002/asmb.2916},
	abstract = {In the early days of machine learning (ML), the emphasis was on developing complex algorithms to achieve best possible predictive performance. To understand and explain the model results, one had to rely on post hoc explainability techniques, which are known to have limitations. Recently, with the recognition in regulated industries that interpretability is also important, researchers are studying algorithms that compromise on small increases in predictive performance in favor of being more interpretable. While doing so, the ML community has rediscovered the use of low-order functional ANOVA (fANOVA) models that have been known in the statistical literature for some time. This paper starts with a description of challenges with post hoc explainability. This is followed by a brief review of the fANOVA framework with a focus on models with just main effects and second-order interactions (called generalized additive models with interactions or GAMI = GAM + Interactions). It then provides an overview of two recently developed GAMI techniques: Explainable Boosting Machines or EBM and GAMI-Net. The paper proposes a new algorithm that also uses trees, as in EBM, but does linear fits instead of piecewise constants within the partitions. We refer to this as GAMI-linear-tree (GAMI-Lin-T). There are many other differences, including the development of a new interaction filtering algorithm. The paper uses simulated and real datasets to compare the three fANOVA ML algorithms. The results show that GAMI-Lin-T and GAMI-Net have comparable performances, and both are generally better than EBM.},
	language = {en},
	number = {1},
	urldate = {2025-04-14},
	journal = {Applied Stochastic Models in Business and Industry},
	author = {Hu, Linwei and Nair, Vijayan N. and Sudjianto, Agus and Zhang, Aijun and Chen, Jie and Yang, Zebin},
	month = jan,
	year = {2025},
	keywords = {\#1 fANOVA ML models},
	pages = {e2916},
	file = {Hu et al. - 2025 - Interpretable Machine Learning Based on Functional ANOVA Framework Algorithms and Comparisons.pdf:/Users/julietfleischer/Library/Mobile Documents/iCloud~md~obsidian/Documents/Studium/PDFs/Hu et al. - 2025 - Interpretable Machine Learning Based on Functional ANOVA Framework Algorithms and Comparisons.pdf:application/pdf},
}

@article{hess,
	title = {Interpretable {Machine} {Learning} for {Earnings} {Forecasts}: {Leveraging} {High}-{Dimensional} {Financial} {Statement} {Data}},
	abstract = {We predict earnings for forecast horizons of up to five years by using the entire set of Compustat financial statement data as input and providing it to state-of-the-art machine learning models capable of approximating arbitrary functional forms. Our approach improves prediction one year ahead by an average of 11\% compared to the traditional linear approach that performs best. This superior performance is consistent across a variety of evaluation metrics as well as different firm subsamples and translates into more profitable investment strategies. Extensive model interpretation reveals that income statement variables, especially different definitions of earnings, are by far the most important predictors. Conversely, we find that while income statement variables decline in relevance, balance sheet information becomes more significant as the forecast horizon extends. Lastly, we show that the influence of interactions and nonlinearities on the machine learning forecast is modest, but substantial differences between firm subsamples exist.},
	language = {en},
	author = {Hess, Dieter and Simon, Frederik and Weibels, Sebastian},
	file = {Hess et al. - Interpretable Machine Learning for Earnings Forecasts Leveraging High-Dimensional Financial Stateme.pdf:/Users/julietfleischer/Library/Mobile Documents/iCloud~md~obsidian/Documents/Studium/PDFs/Hess et al. - Interpretable Machine Learning for Earnings Forecasts Leveraging High-Dimensional Financial Stateme.pdf:application/pdf},
}

@article{tang2025,
	title = {Forecasting {Bank} {Default} {Risk} with {Interpretable} {Machine} {Learning}: {The} {Study} of {Chinese} {Banks}},
	volume = {61},
	issn = {1540-496X, 1558-0938},
	shorttitle = {Forecasting {Bank} {Default} {Risk} with {Interpretable} {Machine} {Learning}},
	url = {https://www.tandfonline.com/doi/full/10.1080/1540496X.2024.2415337},
	doi = {10.1080/1540496X.2024.2415337},
	abstract = {Bank occupies an important position in the financial system. The stable operation of the banking industry is not only one of the important factors in achieving sustainable economic growth but also related to the stability of the entire financial system. This research collects data from 507 banks in China from 2000 to 2021, uses the non-performing loan ratio as the measurement indicator of bank risk, and selects indicators from five levels (macroeconomic environment, industry economic environment, economic policy uncertainty, financial openness and bank financial status) On this basis, we use interpretable machine learning models to predict the bank’s default risk, analyze and compare the interpretable machine learning model and the post-hoc explainable methods. The results indicate that Provision Coverage (PC), Loan Provision Coverage (LPC), Liquidity Ratio (LR), and KOF Financial Globalization Index (KOFFiGI) have strong predictive capability for bank default risk. Our research can provide a reference for banks, government and financial regulatory authorities to construct the prediction model and indicator monitoring platform for bank default risk.},
	language = {en},
	number = {6},
	urldate = {2025-04-14},
	journal = {Emerging Markets Finance and Trade},
	author = {Tang, Pan and Peng, Hongjuan and Luo, Sihang and Liu, Yangguang},
	month = may,
	year = {2025},
	pages = {1661--1683},
	file = {Tang et al. - 2025 - Forecasting Bank Default Risk with Interpretable Machine Learning The Study of Chinese Banks.pdf:/Users/julietfleischer/Library/Mobile Documents/iCloud~md~obsidian/Documents/Studium/PDFs/Tang et al. - 2025 - Forecasting Bank Default Risk with Interpretable Machine Learning The Study of Chinese Banks.pdf:application/pdf},
}

@article{molnar,
	title = {Model-{Agnostic} {Interpretable} {Machine} {Learning}},
	language = {en},
	author = {Molnar, Christoph},
	file = {Molnar - Model-Agnostic Interpretable Machine Learning.pdf:/Users/julietfleischer/Library/Mobile Documents/iCloud~md~obsidian/Documents/Studium/PDFs/Molnar - Model-Agnostic Interpretable Machine Learning.pdf:application/pdf},
}

@article{buckmann2022,
	title = {An {Interpretable} {Machine} {Learning} {Workflow} with {An} {Application} to {Economic} {Forecasting}},
	issn = {1556-5068},
	url = {https://www.ssrn.com/abstract=4130517},
	doi = {10.2139/ssrn.4130517},
	language = {en},
	urldate = {2025-04-14},
	journal = {SSRN Electronic Journal},
	author = {Buckmann, Marcus and Joseph, Andreas},
	year = {2022},
	file = {Buckmann und Joseph - 2022 - An Interpretable Machine Learning Workflow with An Application to Economic Forecasting.pdf:/Users/julietfleischer/Library/Mobile Documents/iCloud~md~obsidian/Documents/Studium/PDFs/Buckmann und Joseph - 2022 - An Interpretable Machine Learning Workflow with An Application to Economic Forecasting.pdf:application/pdf},
}

@article{walters2023,
	title = {How to {Open} a {Black} {Box} {Classifier} for {Tabular} {Data}},
	volume = {16},
	copyright = {https://creativecommons.org/licenses/by/4.0/},
	issn = {1999-4893},
	url = {https://www.mdpi.com/1999-4893/16/4/181},
	doi = {10.3390/a16040181},
	abstract = {A lack of transparency in machine learning models can limit their application. We show that analysis of variance (ANOVA) methods extract interpretable predictive models from them. This is possible because ANOVA decompositions represent multivariate functions as sums of functions of fewer variables. Retaining the terms in the ANOVA summation involving functions of only one or two variables provides an efﬁcient method to open black box classiﬁers. The proposed method builds generalised additive models (GAMs) by application of L1 regularised logistic regression to the component terms retained from the ANOVA decomposition of the logit function. The resulting GAMs are derived using two alternative measures, Dirac and Lebesgue. Both measures produce functions that are smooth and consistent. The term partial responses in structured models (PRiSM) describes the family of models that are derived from black box classiﬁers by application of ANOVA decompositions. We demonstrate their interpretability and performance for the multilayer perceptron, support vector machines and gradient-boosting machines applied to synthetic data and several real-world data sets, namely Pima Diabetes, German Credit Card, and Statlog Shuttle from the UCI repository. The GAMs are shown to be compliant with the basic principles of a formal framework for interpretability.},
	language = {en},
	number = {4},
	urldate = {2025-04-14},
	journal = {Algorithms},
	author = {Walters, Bradley and Ortega-Martorell, Sandra and Olier, Ivan and Lisboa, Paulo J. G.},
	month = mar,
	year = {2023},
	pages = {181},
	file = {Walters et al. - 2023 - How to Open a Black Box Classifier for Tabular Data.pdf:/Users/julietfleischer/Library/Mobile Documents/iCloud~md~obsidian/Documents/Studium/PDFs/Walters et al. - 2023 - How to Open a Black Box Classifier for Tabular Data.pdf:application/pdf},
}

@article{belle2021,
	title = {Principles and {Practice} of {Explainable} {Machine} {Learning}},
	volume = {4},
	issn = {2624-909X},
	url = {https://www.frontiersin.org/articles/10.3389/fdata.2021.688969/full},
	doi = {10.3389/fdata.2021.688969},
	abstract = {Artiﬁcial intelligence (AI) provides many opportunities to improve private and public life. Discovering patterns and structures in large troves of data in an automated manner is a core component of data science, and currently drives applications in diverse areas such as computational biology, law and ﬁnance. However, such a highly positive impact is coupled with a signiﬁcant challenge: how do we understand the decisions suggested by these systems in order that we can trust them? In this report, we focus speciﬁcally on data-driven methods—machine learning (ML) and pattern recognition models in particular—so as to survey and distill the results and observations from the literature. The purpose of this report can be especially appreciated by noting that ML models are increasingly deployed in a wide range of businesses. However, with the increasing prevalence and complexity of methods, business stakeholders in the very least have a growing number of concerns about the drawbacks of models, data-speciﬁc biases, and so on. Analogously, data science practitioners are often not aware about approaches emerging from the academic literature or may struggle to appreciate the differences between different methods, so end up using industry standards such as SHAP. Here, we have undertaken a survey to help industry practitioners (but also data scientists more broadly) understand the ﬁeld of explainable machine learning better and apply the right tools. Our latter sections build a narrative around a putative data scientist, and discuss how she might go about explaining her models by asking the right questions. From an organization viewpoint, after motivating the area broadly, we discuss the main developments, including the principles that allow us to study transparent models vs. opaque models, as well as model-speciﬁc or model-agnostic post-hoc explainability approaches. We also brieﬂy reﬂect on deep learning models, and conclude with a discussion about future research directions.},
	language = {en},
	urldate = {2025-04-14},
	journal = {Frontiers in Big Data},
	author = {Belle, Vaishak and Papantonis, Ioannis},
	month = jul,
	year = {2021},
	keywords = {XAI},
	pages = {688969},
	file = {Belle und Papantonis - 2021 - Principles and Practice of Explainable Machine Learning.pdf:/Users/julietfleischer/Library/Mobile Documents/iCloud~md~obsidian/Documents/Studium/PDFs/Belle und Papantonis - 2021 - Principles and Practice of Explainable Machine Learning.pdf:application/pdf},
}

@article{weber2024,
	title = {Applications of {Explainable} {Artificial} {Intelligence} in {Finance}—a systematic review of {Finance}, {Information} {Systems}, and {Computer} {Science} literature},
	volume = {74},
	issn = {2198-1620, 2198-1639},
	url = {https://link.springer.com/10.1007/s11301-023-00320-0},
	doi = {10.1007/s11301-023-00320-0},
	abstract = {Digitalization and technologization affect numerous domains, promising advantages but also entailing risks. Hence, when decision-makers in highly-regulated domains like Finance implement these technological advances—especially Artificial Intelligence—regulators prescribe high levels of transparency, assuring the traceability of decisions for third parties. Explainable Artificial Intelligence (XAI) is of tremendous importance in this context. We provide an overview of current research on XAI in Finance with a systematic literature review screening 2,022 articles from leading Finance, Information Systems, and Computer Science outlets. We identify a set of 60 relevant articles, classify them according to the used XAI methods and goals that they aim to achieve, and provide an overview of XAI methods used in different Finance areas. Areas like risk management, portfolio optimization, and applications around the stock market are well-researched, while anti-money laundering is understudied. Researchers implement both transparent models and post-hoc explainability, while they recently favored the latter.},
	language = {en},
	number = {2},
	urldate = {2025-04-14},
	journal = {Management Review Quarterly},
	author = {Weber, Patrick and Carl, K. Valerie and Hinz, Oliver},
	month = jun,
	year = {2024},
	pages = {867--907},
	file = {Weber et al. - 2024 - Applications of Explainable Artificial Intelligence in Finance—a systematic review of Finance, Infor.pdf:/Users/julietfleischer/Library/Mobile Documents/iCloud~md~obsidian/Documents/Studium/PDFs/Weber et al. - 2024 - Applications of Explainable Artificial Intelligence in Finance—a systematic review of Finance, Infor.pdf:application/pdf},
}

@inproceedings{lou2013,
	address = {Chicago Illinois USA},
	title = {Accurate intelligible models with pairwise interactions},
	isbn = {978-1-4503-2174-7},
	url = {https://dl.acm.org/doi/10.1145/2487575.2487579},
	doi = {10.1145/2487575.2487579},
	abstract = {Standard generalized additive models (GAMs) usually model the dependent variable as a sum of univariate models. Although previous studies have shown that standard GAMs can be interpreted by users, their accuracy is signiﬁcantly less than more complex models that permit interactions.},
	language = {en},
	urldate = {2025-04-14},
	booktitle = {Proceedings of the 19th {ACM} {SIGKDD} international conference on {Knowledge} discovery and data mining},
	publisher = {ACM},
	author = {Lou, Yin and Caruana, Rich and Gehrke, Johannes and Hooker, Giles},
	month = aug,
	year = {2013},
	pages = {623--631},
	file = {Lou et al. - 2013 - Accurate intelligible models with pairwise interactions.pdf:/Users/julietfleischer/Library/Mobile Documents/iCloud~md~obsidian/Documents/Studium/PDFs/Lou et al. - 2013 - Accurate intelligible models with pairwise interactions.pdf:application/pdf},
}

@inproceedings{lou2012,
	address = {Beijing China},
	title = {Intelligible models for classification and regression},
	isbn = {978-1-4503-1462-6},
	url = {https://dl.acm.org/doi/10.1145/2339530.2339556},
	doi = {10.1145/2339530.2339556},
	abstract = {Complex models for regression and classiﬁcation have high accuracy, but are unfortunately no longer interpretable by users. We study the performance of generalized additive models (GAMs), which combine single-feature models called shape functions through a linear function. Since the shape functions can be arbitrarily complex, GAMs are more accurate than simple linear models. But since they do not contain any interactions between features, they can be easily interpreted by users.},
	language = {en},
	urldate = {2025-04-14},
	booktitle = {Proceedings of the 18th {ACM} {SIGKDD} international conference on {Knowledge} discovery and data mining},
	publisher = {ACM},
	author = {Lou, Yin and Caruana, Rich and Gehrke, Johannes},
	month = aug,
	year = {2012},
	pages = {150--158},
}

@inproceedings{lengerich2020,
	title = {Purifying {Interaction} {Effects} with the {Functional} {ANOVA}: {An} {Efficient} {Algorithm} for {Recovering} {Identifiable} {Additive} {Models}},
	shorttitle = {Purifying {Interaction} {Effects} with the {Functional} {ANOVA}},
	url = {https://proceedings.mlr.press/v108/lengerich20a.html},
	abstract = {Models which estimate main effects of individual variables alongside interaction effects have an identifiability challenge: effects can be freely moved between main effects and interaction effects without changing the model prediction. This is a critical problem for interpretability because it permits “contradictory" models to represent the same function. To solve this problem, we propose pure interaction effects: variance in the outcome which cannot be represented by any subset of features. This definition has an equivalence with the Functional ANOVA decomposition. To compute this decomposition, we present a fast, exact algorithm that transforms any piecewise-constant function (such as a tree-based model) into a purified, canonical representation. We apply this algorithm to Generalized Additive Models with interactions trained on several datasets and show large disparity, including contradictions, between the apparent and the purified effects. These results underscore the need to specify data distributions and ensure identifiability before interpreting model parameters.},
	language = {en},
	urldate = {2025-04-14},
	booktitle = {Proceedings of the {Twenty} {Third} {International} {Conference} on {Artificial} {Intelligence} and {Statistics}},
	publisher = {PMLR},
	author = {Lengerich, Benjamin and Tan, Sarah and Chang, Chun-Hao and Hooker, Giles and Caruana, Rich},
	month = jun,
	year = {2020},
	note = {ISSN: 2640-3498},
	pages = {2402--2412},
	file = {Lengerich et al. - 2020 - Purifying Interaction Effects with the Functional ANOVA An Efficient Algorithm for Recovering Ident.pdf:/Users/julietfleischer/Library/Mobile Documents/iCloud~md~obsidian/Documents/Studium/PDFs/Lengerich et al. - 2020 - Purifying Interaction Effects with the Functional ANOVA An Efficient Algorithm for Recovering Ident.pdf:application/pdf},
}

@inproceedings{hooker2004,
	address = {Seattle WA USA},
	title = {Discovering additive structure in black box functions},
	isbn = {978-1-58113-888-7},
	url = {https://dl.acm.org/doi/10.1145/1014052.1014122},
	doi = {10.1145/1014052.1014122},
	abstract = {Many automated learning procedures lack interpretability, operating eﬀectively as a black box: providing a prediction tool but no explanation of the underlying dynamics that drive it. A common approach to interpretation is to plot the dependence of a learned function on one or two predictors. We present a method that seeks not to display the behavior of a function, but to evaluate the importance of nonadditive interactions within any set of variables. Should the function be close to a sum of low dimensional components, these components can be viewed and even modeled parametrically. Alternatively, the work here provides an indication of where intrinsically high-dimensional behavior takes place. The calculations used in this paper correspond closely with the functional ANOVA decomposition; a well-developed construction in Statistics. In particular, the proposed score of interaction importance measures the loss associated with the projection of the prediction function onto a space of additive models. The algorithm runs in linear time and we present displays of the output as a graphical model of the function for interpretation purposes.},
	language = {en},
	urldate = {2025-04-14},
	booktitle = {Proceedings of the tenth {ACM} {SIGKDD} international conference on {Knowledge} discovery and data mining},
	publisher = {ACM},
	author = {Hooker, Giles},
	month = aug,
	year = {2004},
	pages = {575--580},
	file = {Hooker - 2004 - Discovering additive structure in black box functions.pdf:/Users/julietfleischer/Library/Mobile Documents/iCloud~md~obsidian/Documents/Studium/PDFs/Hooker - 2004 - Discovering additive structure in black box functions.pdf:application/pdf},
}

@misc{tsang2021,
	title = {Interpretable {Artificial} {Intelligence} through the {Lens} of {Feature} {Interaction}},
	url = {http://arxiv.org/abs/2103.03103},
	doi = {10.48550/arXiv.2103.03103},
	abstract = {Interpretation of deep learning models is a very challenging problem because of their large number of parameters, complex connections between nodes, and unintelligible feature representations. Despite this, many view interpretability as a key solution to trustworthiness, fairness, and safety, especially as deep learning is applied to more critical decision tasks like credit approval, job screening, and recidivism prediction. There is an abundance of good research providing interpretability to deep learning models; however, many of the commonly used methods do not consider a phenomenon called "feature interaction." This work first explains the historical and modern importance of feature interactions and then surveys the modern interpretability methods which do explicitly consider feature interactions. This survey aims to bring to light the importance of feature interactions in the larger context of machine learning interpretability, especially in a modern context where deep learning models heavily rely on feature interactions.},
	urldate = {2025-04-14},
	publisher = {arXiv},
	author = {Tsang, Michael and Enouen, James and Liu, Yan},
	month = mar,
	year = {2021},
	note = {arXiv:2103.03103 [cs]},
	keywords = {Computer Science - Machine Learning},
	file = {Snapshot:/Users/julietfleischer/Zotero/storage/J9FLF4BN/2103.html:text/html;Tsang et al. - 2021 - Interpretable Artificial Intelligence through the Lens of Feature Interaction.pdf:/Users/julietfleischer/Library/Mobile Documents/iCloud~md~obsidian/Documents/Studium/PDFs/Tsang et al. - 2021 - Interpretable Artificial Intelligence through the Lens of Feature Interaction.pdf:application/pdf},
}

@inproceedings{sun2022,
	address = {Washington DC USA},
	title = {{pureGAM}: {Learning} an {Inherently} {Pure} {Additive} {Model}},
	isbn = {978-1-4503-9385-0},
	shorttitle = {{pureGAM}},
	url = {https://dl.acm.org/doi/10.1145/3534678.3539256},
	doi = {10.1145/3534678.3539256},
	abstract = {Including pairwise or higher-order interactions among predictors of a Generalized Additive Model (GAM) is gaining increasing attention in the literature. However, existing models face an identifiability challenge. In this paper, we propose pureGAM, an inherently pure additive model of both main effects and higher-order interactions. By imposing the pureness condition to constrain each component function, pureGAM is proved to be identifiable without compromising accuracy. Furthermore, the pureness condition introduces additional interpretability in terms of simplicity. Practically, pureGAM is a unified model to support both numerical and categorical features with a novel learning procedure to achieve optimal performance. Evaluations show that pureGAM outperforms other GAMs and has very competitive performance even compared with opaque models, and its interpretability remarkably outperforms competitors in terms of pureness. We also share a successful adoption of pureGAM in one real-world application.},
	language = {en},
	urldate = {2025-04-14},
	booktitle = {Proceedings of the 28th {ACM} {SIGKDD} {Conference} on {Knowledge} {Discovery} and {Data} {Mining}},
	publisher = {ACM},
	author = {Sun, Xingzhi and Wang, Ziyu and Ding, Rui and Han, Shi and Zhang, Dongmei},
	month = aug,
	year = {2022},
	pages = {1728--1738},
	file = {Sun et al. - 2022 - pureGAM Learning an Inherently Pure Additive Model.pdf:/Users/julietfleischer/Library/Mobile Documents/iCloud~md~obsidian/Documents/Studium/PDFs/Sun et al. - 2022 - pureGAM Learning an Inherently Pure Additive Model.pdf:application/pdf},
}

@article{bordt,
	title = {From {Shapley} {Values} to {Generalized} {Additive} {Models} and back},
	abstract = {In explainable machine learning, local posthoc explanation algorithms and inherently interpretable models are often seen as competing approaches. This work offers a partial reconciliation between the two by establishing a correspondence between Shapley Values and Generalized Additive Models (GAMs). We introduce n-Shapley Values, a parametric family of local post-hoc explanation algorithms that explain individual predictions with interaction terms up to order n. By varying the parameter n, we obtain a sequence of explanations that covers the entire range from Shapley Values up to a uniquely determined decomposition of the function we want to explain. The relationship between n-Shapley Values and this decomposition offers a functionally-grounded characterization of Shapley Values, which highlights their limitations. We then show that nShapley Values, as well as the Shapley Taylorand Faith-Shap interaction indices, recover GAMs with interaction terms up to order n. This implies that the original Shapely Values recover GAMs without variable interactions. Taken together, our results provide a precise characterization of Shapley Values as they are being used in explainable machine learning. They also offer a principled interpretation of partial dependence plots of Shapley Values in terms of the underlying functional decomposition. A package for the estimation of different interaction indices is available at https: //github.com/tml-tuebingen/nshap.},
	language = {en},
	author = {Bordt, Sebastian},
	file = {Bordt - From Shapley Values to Generalized Additive Models and back.pdf:/Users/julietfleischer/Library/Mobile Documents/iCloud~md~obsidian/Documents/Studium/PDFs/Bordt - From Shapley Values to Generalized Additive Models and back.pdf:application/pdf},
}

@inproceedings{sorokina2008,
	address = {New York, NY, USA},
	series = {{ICML} '08},
	title = {Detecting statistical interactions with additive groves of trees},
	isbn = {978-1-60558-205-4},
	url = {https://dl.acm.org/doi/10.1145/1390156.1390282},
	doi = {10.1145/1390156.1390282},
	abstract = {Discovering additive structure is an important step towards understanding a complex multi-dimensional function because it allows the function to be expressed as the sum of lower-dimensional components. When variables interact, however, their effects are not additive and must be modeled and interpreted simultaneously. We present a new approach for the problem of interaction detection. Our method is based on comparing the performance of unrestricted and restricted prediction models, where restricted models are prevented from modeling an interaction in question. We show that an additive model-based regression ensemble, Additive Groves, can be restricted appropriately for use with this framework, and thus has the right properties for accurately detecting variable interactions.},
	urldate = {2025-04-14},
	booktitle = {Proceedings of the 25th international conference on {Machine} learning},
	publisher = {Association for Computing Machinery},
	author = {Sorokina, Daria and Caruana, Rich and Riedewald, Mirek and Fink, Daniel},
	month = jul,
	year = {2008},
	pages = {1000--1007},
	file = {Sorokina et al. - 2008 - Detecting statistical interactions with additive groves of trees.pdf:/Users/julietfleischer/Library/Mobile Documents/iCloud~md~obsidian/Documents/Studium/PDFs/Sorokina et al. - 2008 - Detecting statistical interactions with additive groves of trees.pdf:application/pdf;Sorokina et al. - 2008 - Detecting statistical interactions with additive groves of trees.pdf:/Users/julietfleischer/Library/Mobile Documents/iCloud~md~obsidian/Documents/Studium/PDFs/sorokina2008/Sorokina et al. - 2008 - Detecting statistical interactions with additive groves of trees.pdf:application/pdf},
}

@article{liu2006,
	title = {Estimating {Mean} {Dimensionality} of {Analysis} of {Variance} {Decompositions}},
	volume = {101},
	issn = {0162-1459, 1537-274X},
	url = {https://www.tandfonline.com/doi/full/10.1198/016214505000001410},
	doi = {10.1198/016214505000001410},
	language = {en},
	number = {474},
	urldate = {2025-04-14},
	journal = {Journal of the American Statistical Association},
	author = {Liu, Ruixue and Owen, Art B},
	month = jun,
	year = {2006},
	pages = {712--721},
	file = {Liu und Owen - 2006 - Estimating Mean Dimensionality of Analysis of Variance Decompositions.pdf:/Users/julietfleischer/Library/Mobile Documents/iCloud~md~obsidian/Documents/Studium/PDFs/Liu und Owen - 2006 - Estimating Mean Dimensionality of Analysis of Variance Decompositions.pdf:application/pdf},
}

@article{borgonovo2022,
	title = {Global {Sensitivity} {Analysis} with {Mixtures}: {A} {Generalized} {Functional} {ANOVA} {Approach}},
	volume = {42},
	issn = {0272-4332, 1539-6924},
	shorttitle = {Global {Sensitivity} {Analysis} with {Mixtures}},
	url = {https://onlinelibrary.wiley.com/doi/10.1111/risa.13763},
	doi = {10.1111/risa.13763},
	abstract = {Abstract
            This work investigates aspects of the global sensitivity analysis of computer codes when alternative plausible distributions for the model inputs are available to the analyst. Analysts may decide to explore results under each distribution or to aggregate the distributions, assigning, for instance, a mixture. In the first case, we lose uniqueness of the sensitivity measures, and in the second case, we lose independence even if the model inputs are independent under each of the assigned distributions. Removing the unique distribution assumption impacts the mathematical properties at the basis of variance‐based sensitivity analysis and has consequences on result interpretation as well. We analyze in detail the technical aspects. From this investigation, we derive corresponding recommendations for the risk analyst. We show that an approach based on the generalized functional ANOVA expansion remains theoretically grounded in the presence of a mixture distribution. Numerically, we base the construction of the generalized function ANOVA effects on the diffeomorphic modulation under observable response preserving homotopy regression. Our application addresses the calculation of variance‐based sensitivity measures for the well‐known Nordhaus' DICE model, when its inputs are assigned a mixture distribution. A discussion of implications for the risk analyst and future research perspectives closes the work.},
	language = {en},
	number = {2},
	urldate = {2025-04-14},
	journal = {Risk Analysis},
	author = {Borgonovo, Emanuele and Li, Genyuan and Barr, John and Plischke, Elmar and Rabitz, Herschel},
	month = feb,
	year = {2022},
	pages = {304--333},
	file = {Borgonovo et al. - 2022 - Global Sensitivity Analysis with Mixtures A Generalized Functional ANOVA Approach.pdf:/Users/julietfleischer/Library/Mobile Documents/iCloud~md~obsidian/Documents/Studium/PDFs/Borgonovo et al. - 2022 - Global Sensitivity Analysis with Mixtures A Generalized Functional ANOVA Approach.pdf:application/pdf},
}

@article{dette2001,
	title = {Analysis of {Variance} in {Nonparametric} {Regression} {Models}},
	volume = {76},
	copyright = {https://www.elsevier.com/tdm/userlicense/1.0/},
	issn = {0047259X},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0047259X00919134},
	doi = {10.1006/jmva.2000.1913},
	language = {en},
	number = {1},
	urldate = {2025-04-16},
	journal = {Journal of Multivariate Analysis},
	author = {Dette, Holger and Derbort, Stephan},
	month = jan,
	year = {2001},
	pages = {110--137},
	file = {Dette und Derbort - 2001 - Analysis of Variance in Nonparametric Regression Models.pdf:/Users/julietfleischer/Library/Mobile Documents/iCloud~md~obsidian/Documents/Studium/PDFs/Dette und Derbort - 2001 - Analysis of Variance in Nonparametric Regression Models.pdf:application/pdf},
}

@book{cellier2020,
	address = {Cham},
	series = {Communications in {Computer} and {Information} {Science}},
	title = {Machine {Learning} and {Knowledge} {Discovery} in {Databases}: {International} {Workshops} of {ECML} {PKDD} 2019, {Würzburg}, {Germany}, {September} 16–20, 2019, {Proceedings}, {Part} {I}},
	volume = {1167},
	copyright = {https://creativecommons.org/licenses/by/4.0},
	isbn = {978-3-030-43822-7 978-3-030-43823-4},
	shorttitle = {Machine {Learning} and {Knowledge} {Discovery} in {Databases}},
	url = {https://link.springer.com/10.1007/978-3-030-43823-4},
	language = {en},
	urldate = {2025-04-16},
	publisher = {Springer International Publishing},
	editor = {Cellier, Peggy and Driessens, Kurt},
	year = {2020},
	doi = {10.1007/978-3-030-43823-4},
	file = {Cellier und Driessens - 2020 - Machine Learning and Knowledge Discovery in Databases International Workshops of ECML PKDD 2019, Wü.pdf:/Users/julietfleischer/Library/Mobile Documents/iCloud~md~obsidian/Documents/Studium/PDFs/Cellier und Driessens - 2020 - Machine Learning and Knowledge Discovery in Databases International Workshops of ECML PKDD 2019, Wü.pdf:application/pdf},
}

@article{wahba,
	title = {{THE} 1994 {NEYMAN} {MEMORIAL} {LECTURE}},
	language = {en},
	author = {Wahba, Grace and Wang, Yuedong and Gu, Chong and Klein, Ronald and Klein, Barbara},
	file = {Wahba et al. - THE 1994 NEYMAN MEMORIAL LECTURE.pdf:/Users/julietfleischer/Library/Mobile Documents/iCloud~md~obsidian/Documents/Studium/PDFs/Wahba et al. - THE 1994 NEYMAN MEMORIAL LECTURE.pdf:application/pdf},
}

@article{efron1981,
	title = {The {Jackknife} {Estimate} of {Variance}},
	volume = {The Annals of Statistic},
	language = {en},
	number = {Vol. 9, No. 3},
	author = {Efron, B and Stein, C},
	month = may,
	year = {1981},
	pages = {pp. 586--596},
	file = {The Jackknife Estimate of Variance.pdf:/Users/julietfleischer/Library/Mobile Documents/iCloud~md~obsidian/Documents/Studium/PDFs/The Jackknife Estimate of Variance.pdf:application/pdf},
}

@article{muehlenstaedt2012,
	title = {Data-driven {Kriging} models based on {FANOVA}-decomposition},
	volume = {22},
	copyright = {http://www.springer.com/tdm},
	issn = {0960-3174, 1573-1375},
	url = {http://link.springer.com/10.1007/s11222-011-9259-7},
	doi = {10.1007/s11222-011-9259-7},
	language = {en},
	number = {3},
	urldate = {2025-04-16},
	journal = {Statistics and Computing},
	author = {Muehlenstaedt, Thomas and Roustant, Olivier and Carraro, Laurent and Kuhnt, Sonja},
	month = may,
	year = {2012},
	pages = {723--738},
	file = {Muehlenstaedt et al. - 2012 - Data-driven Kriging models based on FANOVA-decomposition.pdf:/Users/julietfleischer/Library/Mobile Documents/iCloud~md~obsidian/Documents/Studium/PDFs/Muehlenstaedt et al. - 2012 - Data-driven Kriging models based on FANOVA-decomposition.pdf:application/pdf},
}

@article{sobol2001,
	title = {Global sensitivity indices for nonlinear mathematical models and their {Monte} {Carlo} estimates},
	volume = {55},
	copyright = {https://www.elsevier.com/tdm/userlicense/1.0/},
	issn = {03784754},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0378475400002706},
	doi = {10.1016/S0378-4754(00)00270-6},
	abstract = {Global sensitivity indices for rather complex mathematical models can be efﬁciently computed by Monte Carlo (or quasi-Monte Carlo) methods. These indices are used for estimating the inﬂuence of individual variables or groups of variables on the model output. © 2001 IMACS. Published by Elsevier Science B.V. All rights reserved.},
	language = {en},
	number = {1-3},
	urldate = {2025-04-20},
	journal = {Mathematics and Computers in Simulation},
	author = {Sobol, I.M},
	month = feb,
	year = {2001},
	pages = {271--280},
	file = {Sobol′ - 2001 - Global sensitivity indices for nonlinear mathematical models and their Monte Carlo estimates.pdf:/Users/julietfleischer/Library/Mobile Documents/iCloud~md~obsidian/Documents/Studium/PDFs/Sobol - 2001 - Global sensitivity indices for nonlinear mathematical models and their Monte Carlo estimates.pdf:application/pdf},
}

@misc{scholbeck2024,
	title = {Position {Paper}: {Bridging} the {Gap} {Between} {Machine} {Learning} and {Sensitivity} {Analysis}},
	shorttitle = {Position {Paper}},
	url = {http://arxiv.org/abs/2312.13234},
	doi = {10.48550/arXiv.2312.13234},
	abstract = {We argue that interpretations of machine learning (ML) models or the model-building process can be seen as a form of sensitivity analysis (SA), a general methodology used to explain complex systems in many fields such as environmental modeling, engineering, or economics. We address both researchers and practitioners, calling attention to the benefits of a unified SA-based view of explanations in ML and the necessity to fully credit related work. We bridge the gap between both fields by formally describing how (a) the ML process is a system suitable for SA, (b) how existing ML interpretation methods relate to this perspective, and (c) how other SA techniques could be applied to ML.},
	language = {en},
	urldate = {2025-04-20},
	publisher = {arXiv},
	author = {Scholbeck, Christian A. and Moosbauer, Julia and Casalicchio, Giuseppe and Gupta, Hoshin and Bischl, Bernd and Heumann, Christian},
	month = sep,
	year = {2024},
	note = {arXiv:2312.13234 [cs]},
	keywords = {Computer Science - Machine Learning},
}

@article{panigrahi2025,
	title = {On {Robustness} of the {Explanatory} {Power} of {Machine} {Learning} {Models}: {Insights} {From} a {New} {Explainable} {AI} {Approach} {Using} {Sensitivity} {Analysis}},
	volume = {61},
	issn = {0043-1397, 1944-7973},
	shorttitle = {On {Robustness} of the {Explanatory} {Power} of {Machine} {Learning} {Models}},
	url = {https://agupubs.onlinelibrary.wiley.com/doi/10.1029/2024WR037398},
	doi = {10.1029/2024WR037398},
	abstract = {Machine learning (ML) is increasingly considered the solution to environmental problems where limited or no physico‐chemical process understanding exists. But in supporting high‐stakes decisions, where the ability to explain possible solutions is key to their acceptability and legitimacy, ML can fall short. Here, we develop a method, rooted in formal sensitivity analysis, to uncover the primary drivers behind ML predictions. Unlike many methods for explainable artificial intelligence (XAI), this method (a) accounts for complex multivariate distributional properties of data, common in environmental systems, (b) offers a global assessment of the input‐output response surface formed by ML, rather than focusing solely on local regions around existing data points, and (c) is scalable and data‐size independent, ensuring computational efficiency with large data sets. We apply this method to a suite of ML models predicting various water quality variables in a pilot‐scale experimental pit lake. A critical finding is that subtle alterations in the design of some ML models (such as variations in random seed, functional class, hyperparameters, or data splitting) can lead to different interpretations of how outputs depend on inputs. Further, models from different ML families (decision trees, connectionists, or kernels) may focus on different aspects of the information provided by data, despite displaying similar predictive power. Overall, our results underscore the need to assess the explanatory robustness of ML models and advocate for using model ensembles to gain deeper insights into system drivers and improve prediction reliability.},
	language = {en},
	number = {3},
	urldate = {2025-04-20},
	journal = {Water Resources Research},
	author = {Panigrahi, Banamali and Razavi, Saman and Doig, Lorne E. and Cordell, Blanchard and Gupta, Hoshin V. and Liber, Karsten},
	month = mar,
	year = {2025},
	pages = {e2024WR037398},
	file = {Panigrahi et al. - 2025 - On Robustness of the Explanatory Power of Machine Learning Models Insights From a New Explainable A.pdf:/Users/julietfleischer/Library/Mobile Documents/iCloud~md~obsidian/Documents/Studium/PDFs/Panigrahi et al. - 2025 - On Robustness of the Explanatory Power of Machine Learning Models Insights From a New Explainable A.pdf:application/pdf},
}

@misc{fumagalli2025,
	title = {Unifying {Feature}-{Based} {Explanations} with {Functional} {ANOVA} and {Cooperative} {Game} {Theory}},
	url = {http://arxiv.org/abs/2412.17152},
	doi = {10.48550/arXiv.2412.17152},
	abstract = {Feature-based explanations, using perturbations or gradients, are a prevalent tool to understand decisions of black box machine learning models. Yet, differences between these methods still remain mostly unknown, which limits their applicability for practitioners. In this work, we introduce a unified framework for local and global feature-based explanations using two well-established concepts: functional ANOVA (fANOVA) from statistics, and the notion of value and interaction from cooperative game theory. We introduce three fANOVA decompositions that determine the influence of feature distributions, and use game-theoretic measures, such as the Shapley value and interactions, to specify the influence of higher-order interactions. Our framework combines these two dimensions to uncover similarities and differences between a wide range of explanation techniques for features and groups of features. We then empirically showcase the usefulness of our framework on synthetic and real-world datasets.},
	language = {en},
	urldate = {2025-04-20},
	publisher = {arXiv},
	author = {Fumagalli, Fabian and Muschalik, Maximilian and Hüllermeier, Eyke and Hammer, Barbara and Herbinger, Julia},
	month = apr,
	year = {2025},
	note = {arXiv:2412.17152 [cs]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{hoepner2021,
	title = {Significance, relevance and explainability in the machine learning age: an econometrics and financial data science perspective},
	volume = {27},
	issn = {1351-847X, 1466-4364},
	shorttitle = {Significance, relevance and explainability in the machine learning age},
	url = {https://www.tandfonline.com/doi/full/10.1080/1351847X.2020.1847725},
	doi = {10.1080/1351847X.2020.1847725},
	abstract = {Although machine learning is frequently associated with neural networks, it also comprises econometric regression approaches and other statistical techniques whose accuracy enhances with increasing observation. What constitutes high quality machine learning is yet unclear though. Proponents of deep learning (i.e. neural networks) value computational efficiency over human interpretability and tolerate the ‘black box’ appeal of their algorithms, whereas proponents of explainable artificial intelligence (xai) employ traceable ‘white box’ methods (e.g. regressions) to enhance explainability to human decision makers. We extend Brooks et al.’s [2019. ‘Financial Data Science: The Birth of a New Financial Research Paradigm Complementing Econometrics?’ European Journal of Finance 25 (17): 1627–36.] work on significance and relevance as assessment critieria in econometrics and financial data science to contribute to this debate. Specifically, we identify explainability as the Achilles heel of classic machine learning approaches such as neural networks, which are not fully replicable, lack transparency and traceability and therefore do not permit any attempts to establish causal inference. We conclude by suggesting routes for future research to advance the design and efficiency of ‘white box’ algorithms.},
	language = {en},
	number = {1-2},
	urldate = {2025-04-20},
	journal = {The European Journal of Finance},
	author = {Hoepner, Andreas G. F. and McMillan, David and Vivian, Andrew and Wese Simen, Chardin},
	month = jan,
	year = {2021},
	pages = {1--7},
	file = {Hoepner et al. - 2021 - Significance, relevance and explainability in the machine learning age an econometrics and financia.pdf:/Users/julietfleischer/Library/Mobile Documents/iCloud~md~obsidian/Documents/Studium/PDFs/Hoepner et al. - 2021 - Significance, relevance and explainability in the machine learning age an econometrics and financia.pdf:application/pdf},
}

@article{rane2023,
	title = {Explainable {Artificial} {Intelligence} ({XAI}) {Approaches} for {Transparency} and {Accountability} in {Financial} {Decision}-{Making}},
	issn = {1556-5068},
	url = {https://www.ssrn.com/abstract=4640316},
	doi = {10.2139/ssrn.4640316},
	abstract = {Recently, there has been a growing trend in incorporating Artificial Intelligence (AI) into financial decisionmaking, prompting concerns about the transparency and accountability of these intricate systems. This study investigates the impact of Explainable Artificial Intelligence (XAI) approaches in alleviating these concerns and improving transparency in financial decision-making processes. The paper commences by outlining the current landscape of AI applications in finance, underscoring the complex and opaque nature of advanced machine learning models. The lack of interpretability in these models presents a significant challenge, as stakeholders, regulators, and end-users often struggle to comprehend the reasoning behind AI-driven financial decisions. This opacity raises questions regarding accountability and trust, particularly in critical financial scenarios. The primary focus of the research centers on the analysis and implementation of XAI techniques to introduce transparency into financial AI systems. Various XAI methods, including rule-based systems, model-agnostic approaches, and interpretable machine learning models, are scrutinized for their effectiveness in producing understandable explanations for AI-driven financial decisions. The paper explores how these approaches can be tailored to meet the distinct requirements of the financial domain, where interpretability is essential for regulatory compliance and stakeholder confidence. Moreover, the research delves into the potential impact of XAI on accountability mechanisms within financial institutions. By offering interpretable explanations for model outputs, XAI not only enhances transparency but also empowers financial professionals to identify and rectify biases, errors, or unethical behaviour in AI algorithms. By promoting transparency and accountability, XAI not only addresses ethical concerns but also facilitates the responsible and trustworthy deployment of AI in the financial sector. This, in turn, contributes to the advancement of fair, reliable, and secure financial systems.},
	language = {en},
	urldate = {2025-04-20},
	journal = {SSRN Electronic Journal},
	author = {Rane, Nitin and Choudhary, Saurabh and Rane, Jayesh},
	year = {2023},
	file = {Rane et al. - 2023 - Explainable Artificial Intelligence (XAI) Approaches for Transparency and Accountability in Financia.pdf:/Users/julietfleischer/Library/Mobile Documents/iCloud~md~obsidian/Documents/Studium/PDFs/Rane et al. - 2023 - Explainable Artificial Intelligence (XAI) Approaches for Transparency and Accountability in Financia.pdf:application/pdf},
}

@article{cerneviciene2024,
	title = {Explainable artificial intelligence ({XAI}) in finance: a systematic literature review},
	volume = {57},
	issn = {1573-7462},
	shorttitle = {Explainable artificial intelligence ({XAI}) in finance},
	url = {https://link.springer.com/10.1007/s10462-024-10854-8},
	doi = {10.1007/s10462-024-10854-8},
	abstract = {As the range of decisions made by Artificial Intelligence (AI) expands, the need for Explainable AI (XAI) becomes increasingly critical. The reasoning behind the specific outcomes of complex and opaque financial models requires a thorough justification to improve risk assessment, minimise the loss of trust, and promote a more resilient and trustworthy financial ecosystem. This Systematic Literature Review (SLR) identifies 138 relevant articles from 2005 to 2022 and highlights empirical examples demonstrating XAI’s potential benefits in the financial industry. We classified the articles according to the financial tasks addressed by AI using XAI, the variation in XAI methods between applications and tasks, and the development and application of new XAI methods. The most popular financial tasks addressed by the AI using XAI were credit management, stock price predictions, and fraud detection. The three most commonly employed AI black-box techniques in finance whose explainability was evaluated were Artificial Neural Networks (ANN), Extreme Gradient Boosting (XGBoost), and Random Forest. Most of the examined publications utilise feature importance, Shapley additive explanations (SHAP), and rule-based methods. In addition, they employ explainability frameworks that integrate multiple XAI techniques. We also concisely define the existing challenges, requirements, and unresolved issues in applying XAI in the financial sector.},
	language = {en},
	number = {8},
	urldate = {2025-04-20},
	journal = {Artificial Intelligence Review},
	author = {Černevičienė, Jurgita and Kabašinskas, Audrius},
	month = jul,
	year = {2024},
	pages = {216},
	file = {Černevičienė und Kabašinskas - 2024 - Explainable artificial intelligence (XAI) in finance a systematic literature review.pdf:/Users/julietfleischer/Library/Mobile Documents/iCloud~md~obsidian/Documents/Studium/PDFs/Černevičienė und Kabašinskas - 2024 - Explainable artificial intelligence (XAI) in finance a systematic literature review.pdf:application/pdf},
}

@article{andrewniianang2024,
	title = {Explainable {AI} in financial technologies: {Balancing} innovation with regulatory compliance},
	volume = {13},
	issn = {25828185},
	shorttitle = {Explainable {AI} in financial technologies},
	url = {https://ijsra.net/node/5858},
	doi = {10.30574/ijsra.2024.13.1.1870},
	abstract = {As artificial intelligence (AI) technologies increasingly permeate the financial sector, their adoption raises significant challenges and opportunities regarding regulatory compliance and innovation. This paper explores the critical role of Explainable AI (XAI) in balancing these two aspects, particularly in applications such as fraud detection, credit scoring, and algorithmic trading. We highlight the necessity of XAI for financial institutions to meet regulatory requirements that demand transparency and accountability in AI-driven decisions. The discussion delves into the complexities faced by these institutions, including the inherent biases in algorithms that can compromise fairness and the ethical implications of opaque decision-making processes. Through case studies of successful XAI implementations, we illustrate how transparency can enhance consumer trust and promote a more robust regulatory environment. This examination underscores the importance of fostering innovation while adhering to compliance mandates, providing a roadmap for financial institutions striving to leverage AI responsibly. Ultimately, we advocate for the integration of XAI as a means to mitigate risks associated with algorithmic bias and enhance the integrity of financial technologies, thereby contributing to a more equitable financial landscape.},
	language = {en},
	number = {1},
	urldate = {2025-04-20},
	journal = {International Journal of Science and Research Archive},
	author = {{Andrew Nii Anang} and {Oluwatosin Esther Ajewumi} and {Tobi Sonubi} and {Kenneth Chukwujekwu Nwafor} and {John Babatope Arogundade} and {Itiade James Akinbi}},
	month = oct,
	year = {2024},
	pages = {1793--1806},
	file = {Andrew Nii Anang et al. - 2024 - Explainable AI in financial technologies Balancing innovation with regulatory compliance.pdf:/Users/julietfleischer/Library/Mobile Documents/iCloud~md~obsidian/Documents/Studium/PDFs/Andrew Nii Anang et al. - 2024 - Explainable AI in financial technologies Balancing innovation with regulatory compliance.pdf:application/pdf},
}

@article{yang2021,
	title = {{GAMI}-{Net}: {An} explainable neural network based on generalized additive models with structured interactions},
	volume = {120},
	issn = {00313203},
	shorttitle = {{GAMI}-{Net}},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0031320321003484},
	doi = {10.1016/j.patcog.2021.108192},
	abstract = {The lack of interpretability is an inevitable problem when using neural network models in real applications. In this paper, an explainable neural network based on generalized additive models with structured interactions (GAMI-Net) is proposed to pursue a good balance between prediction accuracy and model interpretability. GAMI-Net is a disentangled feedforward network with multiple additive subnetworks; each subnetwork consists of multiple hidden layers and is designed for capturing one main effect or one pairwise interaction. Three interpretability aspects are further considered, including a) sparsity, to select the most signiﬁcant effects for parsimonious representations; b) heredity, a pairwise interaction could only be included when at least one of its parent main effects exists; and c) marginal clarity, to make main effects and pairwise interactions mutually distinguishable. An adaptive training algorithm is developed, where main effects are ﬁrst trained and then pairwise interactions are ﬁtted to the residuals. Numerical experiments on both synthetic functions and real-world datasets show that the proposed model enjoys superior interpretability and it maintains competitive prediction accuracy in comparison to the explainable boosting machine and other classic machine learning models.},
	language = {en},
	urldate = {2025-04-21},
	journal = {Pattern Recognition},
	author = {Yang, Zebin and Zhang, Aijun and Sudjianto, Agus},
	month = dec,
	year = {2021},
	pages = {108192},
	file = {Yang et al. - 2021 - GAMI-Net An explainable neural network based on generalized additive models with structured interac.pdf:/Users/julietfleischer/Library/Mobile Documents/iCloud~md~obsidian/Documents/Studium/PDFs/Yang et al. - 2021 - GAMI-Net An explainable neural network based on generalized additive models with structured interac.pdf:application/pdf},
}

@book{gu2013,
	address = {New York, NY},
	series = {Springer {Series} in {Statistics}},
	title = {Smoothing {Spline} {ANOVA} {Models}},
	volume = {297},
	copyright = {https://www.springernature.com/gp/researchers/text-and-data-mining},
	isbn = {978-1-4614-5368-0 978-1-4614-5369-7},
	url = {https://link.springer.com/10.1007/978-1-4614-5369-7},
	language = {en},
	urldate = {2025-04-21},
	publisher = {Springer New York},
	author = {Gu, Chong},
	year = {2013},
	doi = {10.1007/978-1-4614-5369-7},
	file = {Gu - 2013 - Smoothing Spline ANOVA Models.pdf:/Users/julietfleischer/Library/Mobile Documents/iCloud~md~obsidian/Documents/Studium/PDFs/Gu - 2013 - Smoothing Spline ANOVA Models.pdf:application/pdf},
}

@article{choi2025,
	title = {Meta-anova: screening interactions for interpretable machine learning},
	issn = {1226-3192, 2005-2863},
	shorttitle = {Meta-anova},
	url = {https://link.springer.com/10.1007/s42952-024-00302-2},
	doi = {10.1007/s42952-024-00302-2},
	abstract = {There are two things to be considered when we evaluate predictive models. One is prediction accuracy, and the other is interpretability. Over the recent decades, many prediction models of high performance, such as ensemble-based models and deep neural networks, have been developed. However, these models are often too complex, making it difficult to intuitively interpret their predictions. This complexity in interpretation limits their use in many real-world fields that require accountability, such as medicine, finance, and college admissions. In this study, we develop a novel method called Meta-ANOVA to provide an interpretable model for any given prediction model. The basic idea of Meta-ANOVA is to transform a given blackbox prediction model to the functional ANOVA model. A novel technical contribution of Meta-ANOVA is a procedure of screening out unnecessary interactions before transforming a given black-box model to the functional ANOVA model. This screening procedure allows the inclusion of higher order interactions in the transformed functional ANOVA model without computational difficulties. We prove that the screening procedure is asymptotically consistent. Through various experiments with synthetic and real-world datasets, we empirically demonstrate the superiority of Meta-ANOVA.},
	language = {en},
	urldate = {2025-04-22},
	journal = {Journal of Korean Statistical Society},
	author = {Choi, Yongchan and Park, Seokhun and Park, Chanmoo and Kim, Dongha and Kim, Yongdai},
	month = jan,
	year = {2025},
	file = {Choi et al. - 2025 - Meta-anova screening interactions for interpretable machine learning.pdf:/Users/julietfleischer/Library/Mobile Documents/iCloud~md~obsidian/Documents/Studium/PDFs/Choi et al. - 2025 - Meta-anova screening interactions for interpretable machine learning.pdf:application/pdf},
}

@misc{konig2024,
	title = {Disentangling {Interactions} and {Dependencies} in {Feature} {Attribution}},
	url = {http://arxiv.org/abs/2410.23772},
	doi = {10.48550/arXiv.2410.23772},
	abstract = {In explainable machine learning, global feature importance methods try to determine how much each individual feature contributes to predicting the target variable, resulting in one importance score for each feature. But often, predicting the target variable requires interactions between several features (such as in the XOR function), and features might have complex statistical dependencies that allow to partially replace one feature with another one. In commonly used feature importance scores these cooperative effects are conflated with the features' individual contributions, making them prone to misinterpretations. In this work, we derive DIP, a new mathematical decomposition of individual feature importance scores that disentangles three components: the standalone contribution and the contributions stemming from interactions and dependencies. We prove that the DIP decomposition is unique and show how it can be estimated in practice. Based on these results, we propose a new visualization of feature importance scores that clearly illustrates the different contributions.},
	urldate = {2025-04-22},
	publisher = {arXiv},
	author = {König, Gunnar and Günther, Eric and Luxburg, Ulrike von},
	month = oct,
	year = {2024},
	note = {arXiv:2410.23772},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {König et al. - 2024 - Disentangling Interactions and Dependencies in Feature Attribution.pdf:/Users/julietfleischer/Library/Mobile Documents/iCloud~md~obsidian/Documents/Studium/PDFs/König et al. - 2024 - Disentangling Interactions and Dependencies in Feature Attribution.pdf:application/pdf;Snapshot:/Users/julietfleischer/Zotero/storage/7HHBWHWR/2410.html:text/html},
}

@article{guidotti2019,
	title = {A {Survey} of {Methods} for {Explaining} {Black} {Box} {Models}},
	volume = {51},
	issn = {0360-0300, 1557-7341},
	url = {https://dl.acm.org/doi/10.1145/3236009},
	doi = {10.1145/3236009},
	abstract = {In recent years, many accurate decision support systems have been constructed as black boxes, that is as systems that hide their internal logic to the user. This lack of explanation constitutes both a practical and an ethical issue. The literature reports many approaches aimed at overcoming this crucial weakness, sometimes at the cost of sacrificing accuracy for interpretability. The applications in which black box decision systems can be used are various, and each approach is typically developed to provide a solution for a specific problem and, as a consequence, it explicitly or implicitly delineates its own definition of interpretability and explanation. The aim of this article is to provide a classification of the main problems addressed in the literature with respect to the notion of explanation and the type of black box system. Given a problem definition, a black box type, and a desired explanation, this survey should help the researcher to find the proposals more useful for his own work. The proposed classification of approaches to open black box models should also be useful for putting the many research open questions in perspective.},
	language = {en},
	number = {5},
	urldate = {2025-04-22},
	journal = {ACM Computing Surveys},
	author = {Guidotti, Riccardo and Monreale, Anna and Ruggieri, Salvatore and Turini, Franco and Giannotti, Fosca and Pedreschi, Dino},
	month = sep,
	year = {2019},
	pages = {1--42},
	file = {Guidotti et al. - 2019 - A Survey of Methods for Explaining Black Box Models.pdf:/Users/julietfleischer/Library/Mobile Documents/iCloud~md~obsidian/Documents/Studium/PDFs/Guidotti et al. - 2019 - A Survey of Methods for Explaining Black Box Models.pdf:application/pdf},
}

@article{razavi2021,
	title = {The {Future} of {Sensitivity} {Analysis}: {An} essential discipline for systems modeling and policy support},
	volume = {137},
	issn = {13648152},
	shorttitle = {The {Future} of {Sensitivity} {Analysis}},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1364815220310112},
	doi = {10.1016/j.envsoft.2020.104954},
	abstract = {Sensitivity analysis (SA) is en route to becoming an integral part of mathematical modeling. The tremendous potential benefits of SA are, however, yet to be fully realized, both for advancing mechanistic and data-driven modeling of human and natural systems, and in support of decision making. In this perspective paper, a multidisciplinary group of researchers and practitioners revisit the current status of SA, and outline research challenges in regard to both theoretical frameworks and their applications to solve real-world problems. Six areas are discussed that warrant further attention, including (1) structuring and standardizing SA as a discipline, (2) realizing the untapped potential of SA for systems modeling, (3) addressing the computational burden of SA, (4) progressing SA in the context of machine learning, (5) clarifying the relationship and role of SA to uncertainty quantification, and (6) evolving the use of SA in support of decision making. An outlook for the future of SA is provided that underlines how SA must underpin a wide variety of activities to better serve science and society.},
	language = {en},
	urldate = {2025-04-22},
	journal = {Environmental Modelling \& Software},
	author = {Razavi, Saman and Jakeman, Anthony and Saltelli, Andrea and Prieur, Clémentine and Iooss, Bertrand and Borgonovo, Emanuele and Plischke, Elmar and Lo Piano, Samuele and Iwanaga, Takuya and Becker, William and Tarantola, Stefano and Guillaume, Joseph H.A. and Jakeman, John and Gupta, Hoshin and Melillo, Nicola and Rabitti, Giovanni and Chabridon, Vincent and Duan, Qingyun and Sun, Xifu and Smith, Stefán and Sheikholeslami, Razi and Hosseini, Nasim and Asadzadeh, Masoud and Puy, Arnald and Kucherenko, Sergei and Maier, Holger R.},
	month = mar,
	year = {2021},
	pages = {104954},
	file = {Razavi et al. - 2021 - The Future of Sensitivity Analysis An essential discipline for systems modeling and policy support.pdf:/Users/julietfleischer/Library/Mobile Documents/iCloud~md~obsidian/Documents/Studium/PDFs/Razavi et al. - 2021 - The Future of Sensitivity Analysis An essential discipline for systems modeling and policy support.pdf:application/pdf},
}

@book{steland2022,
	address = {Cham},
	title = {Artificial {Intelligence}, {Big} {Data} and {Data} {Science} in {Statistics}: {Challenges} and {Solutions} in {Environmetrics}, the {Natural} {Sciences} and {Technology} (from p. 155)},
	copyright = {https://www.springernature.com/gp/researchers/text-and-data-mining},
	isbn = {978-3-031-07154-6 978-3-031-07155-3},
	shorttitle = {Artificial {Intelligence}, {Big} {Data} and {Data} {Science} in {Statistics}},
	url = {https://link.springer.com/10.1007/978-3-031-07155-3},
	language = {en},
	urldate = {2025-04-22},
	publisher = {Springer International Publishing},
	editor = {Steland, Ansgar and Tsui, Kwok-Leung},
	year = {2022},
	doi = {10.1007/978-3-031-07155-3},
	file = {Steland und Tsui - 2022 - Artificial Intelligence, Big Data and Data Science in Statistics Challenges and Solutions in Enviro.pdf:/Users/julietfleischer/Library/Mobile Documents/iCloud~md~obsidian/Documents/Studium/PDFs/Steland und Tsui - 2022 - Artificial Intelligence, Big Data and Data Science in Statistics Challenges and Solutions in Enviro.pdf:application/pdf},
}

@article{hoeffding1948,
	title = {A {Class} of {Statistics} with {Asymptotically} {Normal} {Distribution}},
	volume = {19},
	issn = {0003-4851},
	url = {https://www.jstor.org/stable/2235637},
	abstract = {Let X1, ·, Xn be n independent random vectors, Xν = (X(1) ν, ⋯, X(r) ν), and Φ(x1, ⋯, xm) a function of m(≤ n) vectors \$x\_{\textbackslash}nu = (x{\textasciicircum}\{(1)\}\_{\textbackslash}nu, {\textbackslash}cdots, x{\textasciicircum}\{(r)\}\_{\textbackslash}nu)\$. A statistic of the form U = ∑"Φ(Xα 1, ⋯, Xαm )/n(n - 1) ⋯ (n - m + 1), where the sum ∑" is extended over all permutations (α1, ⋯, αm) of m different integers, 1 ≤ αi ≤ n, is called a U-statistic. If X1, ⋯, Xn have the same (cumulative) distribution function (d.f.) F(x), U is an unbiased estimate of the population characteristic θ(F) = ∫ ⋯ ∫Φ(x1, ⋯, xm) dF(x1) ⋯ dF(xm). θ(F) is called a regular functional of the d.f. F(x). Certain optimal properties of U-statistics as unbiased estimates of regular functionals have been established by Halmos [9] (cf. Section 4). The variance of a U-statistic as a function of the sample size n and of certain population characteristics is studied in Section 5. It is shown that if X1, ⋯, Xn have the same distribution and Φ(x1, ⋯, xm) is independent of n, the d.f. of \${\textbackslash}sqrt n(U - {\textbackslash}theta)\$ tends to a normal d.f. as n → ∞ under the sole condition of the existence of EΦ2(X1, ⋯, Xm). Similar results hold for the joint distribution of several U-statistics (Theorems 7.1 and 7.2), for statistics U' which, in a certain sense, are asymptotically equivalent to U (Theorems 7.3 and 7.4), for certain functions of statistics U or U' (Theorem 7.5) and, under certain additional assumptions, for the case of the Xν's having different distributions (Theorems 8.1 and 8.2). Results of a similar character, though under different assumptions, are contained in a recent paper by von Mises [18] (cf. Section 7). Examples of statistics of the form U or U' are the moments, Fisher's k-statistics, Gini's mean difference, and several rank correlation statistics such as Spearman's rank correlation and the difference sign correlation (cf. Section 9). Asymptotic power functions for the non-parametric tests of independence based on these rank statistics are obtained. They show that these tests are not unbiased in the limit (Section 9f). The asymptotic distribution of the coefficient of partial difference sign correlation which has been suggested by Kendall also is obtained (Section 9h).},
	number = {3},
	urldate = {2025-04-22},
	journal = {The Annals of Mathematical Statistics},
	author = {Hoeffding, Wassily},
	year = {1948},
	note = {Publisher: Institute of Mathematical Statistics},
	pages = {293--325},
	file = {Hoeffding - 1948 - A Class of Statistics with Asymptotically Normal Distribution.pdf:/Users/julietfleischer/Library/Mobile Documents/iCloud~md~obsidian/Documents/Studium/PDFs/Hoeffding - 1948 - A Class of Statistics with Asymptotically Normal Distribution.pdf:application/pdf},
}

@article{ilidrissi2025,
	title = {Hoeffding decomposition of functions of random dependent variables},
	volume = {208},
	issn = {0047259X},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0047259X25000399},
	doi = {10.1016/j.jmva.2025.105444},
	abstract = {Hoeffding’s functional decomposition is the cornerstone of many post-hoc interpretability methods. It entails decomposing arbitrary functions of mutually independent random variables as a sum of interactions. Many generalizations to dependent covariables have been proposed throughout the years, which rely on finding a set of suitable projectors. This paper characterizes such projectors under hierarchical orthogonality constraints and mild assumptions on the variable’s probabilistic structure. Our approach is deeply rooted in Hilbert space theory, giving intuitive insights on defining, identifying, and separating interactions from the effects due to the variables’ dependence structure. This new decomposition is then leveraged to define a new functional analysis of variance. Toy cases of functions of bivariate Bernoulli and Gaussian random variables are studied.},
	language = {en},
	urldate = {2025-04-22},
	journal = {Journal of Multivariate Analysis},
	author = {Il Idrissi, Marouane and Bousquet, Nicolas and Gamboa, Fabrice and Iooss, Bertrand and Loubes, Jean-Michel},
	month = jul,
	year = {2025},
	pages = {105444},
	file = {Il Idrissi et al. - 2025 - Hoeffding decomposition of functions of random dependent variables.pdf:/Users/julietfleischer/Library/Mobile Documents/iCloud~md~obsidian/Documents/Studium/PDFs/Il Idrissi et al. - 2025 - Hoeffding decomposition of functions of random dependent variables.pdf:application/pdf},
}

@article{stone1994,
	title = {The {Use} of {Polynomial} {Splines} and {Their} {Tensor} {Products} in {Multivariate} {Function} {Estimation}},
	volume = {22},
	issn = {0090-5364},
	url = {https://www.jstor.org/stable/2242446},
	abstract = {Let X$_{\textrm{1}}$, ..., X$_{\textrm{M}}$, Y$_{\textrm{1}}$,..., Y$_{\textrm{N}}$ be random variables, and set X = (X$_{\textrm{1}}$, ..., X$_{\textrm{M}}$) and Y = (Y$_{\textrm{1}}$, ..., Y$_{\textrm{N}}$). Let φ be the regression or logistic or Poisson regression function of Y on X(N = 1) or the logarithm of the density function of Y or the conditional density function of Y on X. Consider the approximation φ$^{\textrm{*}}$ to φ having a suitably defined form involving a specified sum of functions of at most d of the variables x$_{\textrm{1}}$, ..., x$_{\textrm{M}}$, y$_{\textrm{1}}$,..., y$_{\textrm{N}}$ and, subject to this form, selected to minimize the mean squared error of approximation or to maximize the expected log-likelihood or conditional log-likelihood, as appropriate, given the choice of φ. Let p be a suitably defined lower bound to the smoothness of the components of φ$^{\textrm{*}}$. Consider a random sample of size n from the joint distribution of X and Y. Under suitable conditions, the least squares or maximum likelihood method is applied to a model involving nonadaptively selected sums of tensor products of polynomial splines to construct estimates of φ$^{\textrm{*}}$ and its components having the L$_{\textrm{2}}$ rate of convergence n$^{\textrm{-p/(2p + d)}}$.},
	number = {1},
	urldate = {2025-04-23},
	journal = {The Annals of Statistics},
	author = {Stone, Charles J.},
	year = {1994},
	note = {Publisher: Institute of Mathematical Statistics},
	pages = {118--171},
	file = {Stone - 1994 - The Use of Polynomial Splines and Their Tensor Products in Multivariate Function Estimation.pdf:/Users/julietfleischer/Library/Mobile Documents/iCloud~md~obsidian/Documents/Studium/PDFs/Stone - 1994 - The Use of Polynomial Splines and Their Tensor Products in Multivariate Function Estimation.pdf:application/pdf},
}

@incollection{Weber2011,
	address = {Berlin, Heidelberg},
	title = {U-statistics},
	isbn = {978-3-642-04898-2},
	url = {https://doi.org/10.1007/978-3-642-04898-2_607},
	booktitle = {International encyclopedia of statistical science},
	publisher = {Springer Berlin Heidelberg},
	author = {Weber, Neville C.},
	editor = {Lovric, Miodrag},
	year = {2011},
	doi = {10.1007/978-3-642-04898-2_607},
	pages = {1634--1635},
}

@article{huang1998a,
	title = {Projection estimation in multiple regression with application to functional {ANOVA} models},
	volume = {26},
	issn = {0090-5364},
	url = {https://projecteuclid.org/journals/annals-of-statistics/volume-26/issue-1/Projection-estimation-in-multiple-regression-with-application-to-functional-ANOVA/10.1214/aos/1030563984.full},
	doi = {10.1214/aos/1030563984},
	language = {en},
	number = {1},
	urldate = {2025-04-23},
	journal = {The Annals of Statistics},
	author = {Huang, Jianhua Z.},
	month = feb,
	year = {1998},
	file = {Huang - 1998 - Projection estimation in multiple regression with application to functional ANOVA models 1.pdf:/Users/julietfleischer/Library/Mobile Documents/iCloud~md~obsidian/Documents/Studium/PDFs/Huang - 1998 - Projection estimation in multiple regression with application to functional ANOVA models 1.pdf:application/pdf},
}

@article{stone1997,
	title = {Polynomial {Splines} and their {Tensor} {Products} in {Extended} {Linear} {Modeling}},
	volume = {25},
	issn = {0090-5364},
	url = {https://www.jstor.org/stable/2959054},
	abstract = {Analysis of variance type models are considered for a regression function or for the logarithm of a probability function, conditional probability function, density function, conditional density function, hazard function, conditional hazard function or spectral density function. Polynomial splines are used to model the main effects, and their tensor products are used to model any interaction components that are included. In the special context of survival analysis, the baseline hazard function is modeled and nonproportionality is allowed. In general, the theory involves the \$L\_2\$ rate of convergence for the fitted model and its components. The methodology involves least squares and maximum likelihood estimation, stepwise addition of basis functions using Rao statistics, stepwise deletion using Wald statistics and model selection using the Bayesian information criterion, cross-validation or an independent test set. Publicly available software, written in C and interfaced to S/S-PLUS, is used to apply this methodology to real data.},
	number = {4},
	urldate = {2025-04-23},
	journal = {The Annals of Statistics},
	author = {Stone, Charles J. and Hansen, Mark H. and Kooperberg, Charles and Truong, Young K.},
	year = {1997},
	note = {Publisher: Institute of Mathematical Statistics},
	pages = {1371--1425},
	file = {Stone et al. - 1997 - Polynomial Splines and their Tensor Products in Extended Linear Modeling.pdf:/Users/julietfleischer/Library/Mobile Documents/iCloud~md~obsidian/Documents/Studium/PDFs/Stone et al. - 1997 - Polynomial Splines and their Tensor Products in Extended Linear Modeling.pdf:application/pdf},
}

@article{owen2013,
	title = {{Variance Components and Generalized Sobol' Indices}},
	volume = {1},
	url = {https://doi.org/10.1137/120876782},
	doi = {10.1137/120876782},
	abstract = {This paper introduces generalized Sobol' indices, compares strategies for their estimation, and makes a systematic search for efficient estimators. Of particular interest are contrasts, sums of squares, and indices of bilinear form which allow a reduced number of function evaluations compared to alternatives. The bilinear framework includes some efficient estimators from Saltelli [Comput. Phys. Comm., 145 (2002), pp. 280–297] and Mauntz [Global Sensitivity Analysis of General Nonlinear Systems, Master's thesis, Imperial College, London, 2002] as well as some new estimators for specific variance components and mean dimensions. This paper also provides a bias corrected version of the estimator of Janon et al. [Asymptotic Normality and Efficiency of Two Sobol' Index Estimators, technical report, INRIA, Rocquencourt, France] and extends the bias correction to generalized Sobol' indices. Some numerical comparisons are given.},
	number = {1},
	journal = {SIAM/ASA Journal on Uncertainty Quantification},
	author = {Owen, Art B.},
	year = {2013},
	note = {tex.eprint: https://doi.org/10.1137/120876782},
	pages = {19--41},
}

@article{rabitz1999,
	title = {General foundations of high‐dimensional model representations},
	volume = {25},
	issn = {1572-8897},
	url = {https://doi.org/10.1023/A:1019188517934},
	doi = {10.1023/A:1019188517934},
	abstract = {A family of multivariate representations is introduced to capture the input–output relationships of high‐dimensional physical systems with many input variables. A systematic mapping procedure between the inputs and outputs is prescribed to reveal the hierarchy of correlations amongst the input variables. It is argued that for most well‐defined physical systems, only relatively low‐order correlations of the input variables are expected to have an impact upon the output. The high‐dimensional model representations (HDMR) utilize this property to present an exact hierarchical representation of the physical system. At each new level of HDMR, higher‐order correlated effects of the input variables are introduced. Tests on several systems indicate that the few lowest‐order terms are often sufficient to represent the model in equivalent form to good accuracy. The input variables may be either finite‐dimensional (i.e., a vector of parameters chosen from the Euclidean space \$\${\textbackslash}mathcal\{R\}{\textasciicircum}n\$\$) or may be infinite‐dimensional as in the function space \$\$\{{\textbackslash}text\{C\}\}{\textasciicircum}n {\textbackslash}left[ \{0,1\} {\textbackslash}right]\$\$. Each hierarchical level of HDMR is obtained by applying a suitable projection operator to the output function and each of these levels are orthogonal to each other with respect to an appropriately defined inner product. A family of HDMRs may be generated with each having distinct character by the use of different choices of projection operators. Two types of HDMRs are illustrated in the paper: ANOVA‐HDMR is the same as the analysis of variance (ANOVA) decomposition used in statistics. Another cut‐HDMR will be shown to be computationally more efficient than the ANOVA decomposition. Application of the HDMR tools can dramatically reduce the computational effort needed in representing the input–output relationships of a physical system. In addition, the hierarchy of identified correlation functions can provide valuable insight into the model structure. The notion of a model in the paper also encompasses input–output relationships developed with laboratory experiments, and the HDMR concepts are equally applicable in this domain. HDMRs can be classified as non‐regressive, non‐parametric learning networks. Selected applications of the HDMR concept are presented along with a discussion of its general utility.},
	number = {2},
	journal = {Journal of Mathematical Chemistry},
	author = {Rabitz, Herschel and Aliş, Ömer F.},
	month = jun,
	year = {1999},
	pages = {197--233},
	file = {Rabitz und Aliş - 1999 - General foundations of high‐dimensional model representations.pdf:/Users/julietfleischer/Library/Mobile Documents/iCloud~md~obsidian/Documents/Studium/PDFs/rabitz1999/Rabitz und Aliş - 1999 - General foundations of high‐dimensional model representations.pdf:application/pdf},
}

@article{dekok2024,
	title = {Table 0; documenting the steps to go from clinical database to research dataset},
	volume = {170},
	issn = {08954356},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0895435624000970},
	doi = {10.1016/j.jclinepi.2024.111342},
	abstract = {Objectives: Data-driven decision support tools have been increasingly recognized to transform health care. However, such tools are often developed on predeﬁned research datasets without adequate knowledge of the origin of this data and how it was selected. How a dataset is extracted from a clinical database can profoundly impact the validity, interpretability and interoperability of the dataset, and downstream analyses, yet is rarely reported. Therefore, we present a case study illustrating how a deﬁnitive patient list was extracted from a clinical source database and how this can be reported. Study Design and Setting: A single-center observational study was performed at an academic hospital in the Netherlands to illustrate the impact of selecting a deﬁnitive patient list for research from a clinical source database, and the importance of documenting this process. All admissions from the critical care database admitted between January 1, 2013, and January 1, 2023, were used.
Results: An interdisciplinary team collaborated to identify and address potential sources of data insufﬁciency and uncertainty. We demonstrate a stepwise data preparation process, reducing the clinical source database of 54,218 admissions to a deﬁnitive patient list of 21,553 admissions. Transparent documentation of the data preparation process improves the quality of the deﬁnitive patient list before analysis of the corresponding patient data. This study generated seven important recommendations for preparing observational health-care data for research purposes.
Conclusion: Documenting data preparation is essential for understanding a research dataset originating from a clinical source database before analyzing health-care data. The ﬁndings contribute to establishing data standards and offer insights into the complexities of preparing health-care data for scientiﬁc investigation. Meticulous data preparation and documentation thereof will improve research validity and advance critical care. Ó 2024 The Author(s). Published by Elsevier Inc. This is an open access article under the CC BY license (http:// creativecommons.org/licenses/by/4.0/).},
	language = {en},
	urldate = {2025-04-24},
	journal = {Journal of Clinical Epidemiology},
	author = {De Kok, Jip W.T.M. and Van Bussel, Bas C.T. and Schnabel, Ronny and Van Herpt, Thijs T.W. and Driessen, Rob G.H. and Meijs, Daniek A.M. and Goossens, Joep A. and Mertens, Helen J.M.M. and Van Kuijk, Sander M.J. and Wynants, Laure and Van Der Horst, Iwan C.C. and Van Rosmalen, Frank},
	month = jun,
	year = {2024},
	pages = {111342},
	file = {De Kok et al. - 2024 - Table 0\; documenting the steps to go from clinical database to research dataset.pdf:/Users/julietfleischer/Library/Mobile Documents/iCloud~md~obsidian/Documents/Studium/PDFs/De Kok et al. - 2024 - Table 0\; documenting the steps to go from clinical database to research dataset.pdf:application/pdf},
}

@article{schmidt2021,
	title = {Facilitating harmonized data quality assessments. {A} data quality framework for observational health research data collections with software implementations in {R}},
	volume = {21},
	issn = {1471-2288},
	url = {https://bmcmedresmethodol.biomedcentral.com/articles/10.1186/s12874-021-01252-7},
	doi = {10.1186/s12874-021-01252-7},
	abstract = {Background: No standards exist for the handling and reporting of data quality in health research. This work introduces a data quality framework for observational health research data collections with supporting software implementations to facilitate harmonized data quality assessments.
Methods: Developments were guided by the evaluation of an existing data quality framework and literature reviews. Functions for the computation of data quality indicators were written in R. The concept and implementations are illustrated based on data from the population-based Study of Health in Pomerania (SHIP).
Results: The data quality framework comprises 34 data quality indicators. These target four aspects of data quality: compliance with pre-specified structural and technical requirements (integrity); presence of data values (completeness); inadmissible or uncertain data values and contradictions (consistency); unexpected distributions and associations (accuracy). R functions calculate data quality metrics based on the provided study data and metadata and R Markdown reports are generated. Guidance on the concept and tools is available through a dedicated website.
Conclusions: The presented data quality framework is the first of its kind for observational health research data collections that links a formal concept to implementations in R. The framework and tools facilitate harmonized data quality assessments in pursue of transparent and reproducible research. Application scenarios comprise data quality monitoring while a study is carried out as well as performing an initial data analysis before starting substantive scientific analyses but the developments are also of relevance beyond research.},
	language = {en},
	number = {1},
	urldate = {2025-04-24},
	journal = {BMC Medical Research Methodology},
	author = {Schmidt, Carsten Oliver and Struckmann, Stephan and Enzenbach, Cornelia and Reineke, Achim and Stausberg, Jürgen and Damerow, Stefan and Huebner, Marianne and Schmidt, Börge and Sauerbrei, Willi and Richter, Adrian},
	month = dec,
	year = {2021},
	pages = {63},
	file = {Schmidt et al. - 2021 - Facilitating harmonized data quality assessments. A data quality framework for observational health.pdf:/Users/julietfleischer/Library/Mobile Documents/iCloud~md~obsidian/Documents/Studium/PDFs/Schmidt et al. - 2021 - Facilitating harmonized data quality assessments. A data quality framework for observational health.pdf:application/pdf},
}

@article{huebner2018,
	title = {A {Contemporary} {Conceptual} {Framework} for {Initial} {Data} {Analysis}},
	volume = {4},
	issn = {2767-3324},
	url = {https://muse.jhu.edu/article/793379},
	doi = {10.1353/obs.2018.0014},
	abstract = {Initial data analyses (IDA) are often performed as part of studies with primary-data collection, where data are obtained to address a predeﬁned set of research questions, and with a clear plan of the intended statistical analyses. An informal or unstructured approach may have a large and non-transparent impact on results and conclusions presented in publications. Key principles for IDA are to avoid analyses that are part of the research question, and full documentation and transparency.},
	language = {en},
	number = {1},
	urldate = {2025-04-24},
	journal = {Observational Studies},
	author = {Huebner, Marianne and Le Cessie, Saskia and Schmidt, Carsten O. and Vach, Werner},
	year = {2018},
	pages = {171--192},
	file = {Huebner et al. - 2018 - A Contemporary Conceptual Framework for Initial Data Analysis.pdf:/Users/julietfleischer/Library/Mobile Documents/iCloud~md~obsidian/Documents/Studium/PDFs/Huebner et al. - 2018 - A Contemporary Conceptual Framework for Initial Data Analysis.pdf:application/pdf},
}

@article{baillie2022,
	title = {Ten simple rules for initial data analysis},
	volume = {18},
	issn = {1553-7358},
	url = {https://dx.plos.org/10.1371/journal.pcbi.1009819},
	doi = {10.1371/journal.pcbi.1009819},
	language = {en},
	number = {2},
	urldate = {2025-04-24},
	journal = {PLOS Computational Biology},
	author = {Baillie, Mark and Le Cessie, Saskia and Schmidt, Carsten Oliver and Lusa, Lara and Huebner, Marianne and {for the Topic Group “Initial Data Analysis” of the STRATOS Initiative}},
	month = feb,
	year = {2022},
	pages = {e1009819},
	file = {Baillie et al. - 2022 - Ten simple rules for initial data analysis.pdf:/Users/julietfleischer/Library/Mobile Documents/iCloud~md~obsidian/Documents/Studium/PDFs/Baillie et al. - 2022 - Ten simple rules for initial data analysis.pdf:application/pdf},
}

@article{huebner2016,
	title = {A systematic approach to initial data analysis is good research practice},
	volume = {151},
	copyright = {https://www.elsevier.com/tdm/userlicense/1.0/},
	issn = {00225223},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0022522315017948},
	doi = {10.1016/j.jtcvs.2015.09.085},
	abstract = {Initial data analysis is conducted independently of the analysis needed to address the research questions. Shortcomings in these ﬁrst steps may result in inappropriate statistical methods or incorrect conclusions. We outline a framework for initial data analysis and illustrate the impact of initial data analysis on research studies. Examples of reporting of initial data analysis in publications are given. A systematic and careful approach to initial data analysis is needed as good research practice. (J Thorac Cardiovasc Surg 2016;151:25-7) The framework for initial data analysis as an integral part of the research process.},
	language = {en},
	number = {1},
	urldate = {2025-04-24},
	journal = {The Journal of Thoracic and Cardiovascular Surgery},
	author = {Huebner, Marianne and Vach, Werner and Le Cessie, Saskia},
	month = jan,
	year = {2016},
	pages = {25--27},
	file = {Huebner et al. - 2016 - A systematic approach to initial data analysis is good research practice.pdf:/Users/julietfleischer/Library/Mobile Documents/iCloud~md~obsidian/Documents/Studium/PDFs/Huebner et al. - 2016 - A systematic approach to initial data analysis is good research practice.pdf:application/pdf},
}

@article{bienzeisler2025,
	title = {Implementation report on pioneering federated data access for the {German} {National} {Emergency} {Department} {Data} {Registry}},
	volume = {8},
	issn = {2398-6352},
	url = {https://www.nature.com/articles/s41746-025-01481-w},
	doi = {10.1038/s41746-025-01481-w},
	abstract = {Abstract
            Continuous access to electronic health records will fuel the digital transformation of medicine. For data-sharing initiatives, the challenge lies in ensuring data access aligns with the interests of data holders. Federated data access authorization, where data remains controlled locally, may offer a solution to balance these interests. This paper reports on a digital health implementation of the federated data access authorization system used in the German National Emergency Department Data Registry. Using data from 2017 to 2024, we analyzed the system’s effectiveness in managing data access in a nationwide research network of 58 emergency departments. Facilitating access to more than 7.9 million records, 75\% of data access queries were authorized within 15 days. The system also supports periodic queries, enabling recurring real-time access. Query volumes grew from 15 to over 23,000 by 2024, with completion rates of 86\%. The system may thus serve as a blueprint for data-sharing initiatives worldwide.},
	language = {en},
	number = {1},
	urldate = {2025-04-24},
	journal = {npj Digital Medicine},
	author = {Bienzeisler, Jonas and Kombeiz, Alexander and Ehrentreich, Saskia and Otto, Ronny and Schirrmeister, Wiebke and Pegoraro, Marco and Brammen, Dominik and Puladi, Behrus and Röhrig, Rainer and W Majeed, Raphael},
	month = feb,
	year = {2025},
	pages = {94},
	file = {Bienzeisler et al. - 2025 - Implementation report on pioneering federated data access for the German National Emergency Departme.pdf:/Users/julietfleischer/Library/Mobile Documents/iCloud~md~obsidian/Documents/Studium/PDFs/Bienzeisler et al. - 2025 - Implementation report on pioneering federated data access for the German National Emergency Departme.pdf:application/pdf},
}

@article{hoffmann,
	title = {Retrospective\_studies},
	language = {en},
	author = {Hoffmann, Sabine and Morris, Tim and Herrmann, Moritz and Heinze, Georg and Wynants, Laure and Van, Ben and Bischl, Bernd and Schmid, Matthias and Shaw, Pamela A and Niethammer, Mona and Bakhtiary, Farhad and Leistner, David and Schulze, Christian P and Lurz, Philipp and Rassaf, Tienush and Kelm, Malte and Baldus, Stephan and Bauersachs, Johann and Nickenig, Georg and Thiele, Holger and Lüsebrink, Enzo},
	file = {Hoffmann et al. - Retrospective_studies.pdf:/Users/julietfleischer/Library/Mobile Documents/iCloud~md~obsidian/Documents/Studium/PDFs/Hoffmann et al. - Retrospective_studies.pdf:application/pdf},
}

@article{raab2023,
	title = {Federated electronic health records for the {European} {Health} {Data} {Space}},
	volume = {5},
	issn = {25897500},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S2589750023001565},
	doi = {10.1016/S2589-7500(23)00156-5},
	language = {en},
	number = {11},
	urldate = {2025-04-24},
	journal = {The Lancet Digital Health},
	author = {Raab, René and Küderle, Arne and Zakreuskaya, Anastasiya and Stern, Ariel D and Klucken, Jochen and Kaissis, Georgios and Rueckert, Daniel and Boll, Susanne and Eils, Roland and Wagener, Harald and Eskofier, Bjoern M},
	month = nov,
	year = {2023},
	pages = {e840--e847},
	file = {Raab et al. - 2023 - Federated electronic health records for the European Health Data Space.pdf:/Users/julietfleischer/Library/Mobile Documents/iCloud~md~obsidian/Documents/Studium/PDFs/Raab et al. - 2023 - Federated electronic health records for the European Health Data Space.pdf:application/pdf},
}

@article{onbehalfofthetopicgroupinitialdataanalysisofthestratosinitiativestrengtheninganalyticalthinkingforobservationalstudieshttp://www.stratos-initiative.org2020a,
	title = {Hidden analyses: a review of reporting practice and recommendations for more transparent reporting of initial data analyses},
	volume = {20},
	issn = {1471-2288},
	shorttitle = {Hidden analyses},
	url = {https://bmcmedresmethodol.biomedcentral.com/articles/10.1186/s12874-020-00942-y},
	doi = {10.1186/s12874-020-00942-y},
	abstract = {Conclusion: Reporting of initial data analyses were sparse, and statements on IDA were located throughout the research articles. There is a lack of systematic reporting of IDA. We conclude the article with recommendations on how to overcome shortcomings in the practice of IDA reporting in observational studies.},
	language = {en},
	number = {1},
	urldate = {2025-05-02},
	journal = {BMC Medical Research Methodology},
	author = {{on behalf of the Topic Group “Initial Data Analysis” of the STRATOS Initiative (STRengthening Analytical Thinking for Observational Studies, http://www.stratos-initiative.org)} and Huebner, Marianne and Vach, Werner and Le Cessie, Saskia and Schmidt, Carsten Oliver and Lusa, Lara},
	month = dec,
	year = {2020},
	pages = {61},
	file = {on behalf of the Topic Group “Initial Data Analysis” of the STRATOS Initiative (STRengthening Analytical Thinking for Observational Studies, httpwww.stratos-initiative.org) et al. - 2020 - Hidden analyses a review of reporting practice and recomme.pdf:/Users/julietfleischer/Library/Mobile Documents/iCloud~md~obsidian/Documents/Studium/PDFs/onbehalfofthetopicgroupinitialdataanalysisofthestratosinitiativestrengtheninganalyticalthinkingforobservationalstudieshttp_/www.stratos-initiative.org2020a/on behalf of the Topic Group “Initial Data Analysis” of the STRATOS Initiative (STRengthening Analytical Thinking for Observational Studies, httpwww.stratos-initiative.org) et al. - 2020 - Hidden analyses a review of reporting practice and recomme.pdf:application/pdf},
}

@article{takemura1983,
	title = {Tensor {Analysis} of {ANOVA} {Decomposition}},
	volume = {78},
	issn = {0162-1459},
	url = {https://www.jstor.org/stable/2288201},
	doi = {10.2307/2288201},
	abstract = {The analogy between ANOVA for general n-factor crossed layouts and the ANOVA-type decomposition of square integrable statistics is demonstrated using the notions and notations of tensor analysis and multilinear algebra. A theory of tensors is developed in such a way that (a) it can be immediately applied in computer programs, and (b) it can be easily generalized to L$^{\textrm{2}}$ spaces.},
	number = {384},
	urldate = {2025-05-04},
	journal = {Journal of the American Statistical Association},
	author = {Takemura, Akimichi},
	year = {1983},
	note = {Publisher: [American Statistical Association, Taylor \& Francis, Ltd.]},
	pages = {894--900},
	file = {Takemura - 1983 - Tensor Analysis of ANOVA Decomposition.pdf:/Users/julietfleischer/Library/Mobile Documents/iCloud~md~obsidian/Documents/Studium/PDFs/takemura1983/Takemura - 1983 - Tensor Analysis of ANOVA Decomposition.pdf:application/pdf},
}

@article{sobol2005,
	title = {Global sensitivity indices for nonlinear mathematical models. {Review}},
	volume = {2005},
	copyright = {http://doi.wiley.com/10.1002/tdm\_license\_1},
	issn = {15406962, 15418286},
	url = {http://doi.wiley.com/10.1002/wilm.42820050114},
	doi = {10.1002/wilm.42820050114},
	abstract = {This is a review of global sensitivity indices that were introduced in I.M. Sobol’ (1990). These indices allow to analyze numerically the structure of a nonlinear function defined analytically or by a “black box”. As an example the Brownian bridge is considered and an example of the application of global sensitivity indices in finance is presented.},
	language = {en},
	number = {1},
	urldate = {2025-05-07},
	journal = {Wilmott},
	author = {Sobol, I. M. and Kucherenko, S. S.},
	month = jan,
	year = {2005},
	pages = {56--61},
	file = {Sobol und Kucherenko - 2005 - Global sensitivity indices for nonlinear mathematical models. Review.pdf:/Users/julietfleischer/Library/Mobile Documents/iCloud~md~obsidian/Documents/Studium/PDFs/sobol2005/Sobol und Kucherenko - 2005 - Global sensitivity indices for nonlinear mathematical models. Review.pdf:application/pdf},
}

@article{friedman2001,
	title = {Greedy function approximation: {A} gradient boosting machine.},
	volume = {29},
	issn = {0090-5364, 2168-8966},
	shorttitle = {Greedy function approximation},
	url = {https://projecteuclid.org/journals/annals-of-statistics/volume-29/issue-5/Greedy-function-approximation-A-gradient-boosting-machine/10.1214/aos/1013203451.full},
	doi = {10.1214/aos/1013203451},
	abstract = {Function estimation/approximation is viewed from the perspective of numerical optimization in function space, rather than parameter space. A connection is made between stagewise additive expansions and steepest-descent minimization. A general gradient descent “boosting” paradigm is developed for additive expansions based on any fitting criterion.Specific algorithms are presented for least-squares, least absolute deviation, and Huber-M loss functions for regression, and multiclass logistic likelihood for classification. Special enhancements are derived for the particular case where the individual additive components are regression trees, and tools for interpreting such “TreeBoost” models are presented. Gradient boosting of regression trees produces competitive, highly robust, interpretable procedures for both regression and classification, especially appropriate for mining less than clean data. Connections between this approach and the boosting methods of Freund and Shapire and Friedman, Hastie and Tibshirani are discussed.},
	number = {5},
	urldate = {2025-05-19},
	journal = {The Annals of Statistics},
	author = {Friedman, Jerome H.},
	month = oct,
	year = {2001},
	note = {Publisher: Institute of Mathematical Statistics},
	keywords = {62-02, 62-07, 62-08, 62G08, 62H30, 68T10, boosting, decision trees, Function estimation, robust nonparametric regression},
	pages = {1189--1232},
	file = {Friedman - 2001 - Greedy function approximation A gradient boosting machine..pdf:/Users/julietfleischer/Library/Mobile Documents/iCloud~md~obsidian/Documents/Studium/PDFs/friedman2001/Friedman - 2001 - Greedy function approximation A gradient boosting machine..pdf:application/pdf},
}
